<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.91.2" />
<title>Basics of Markov Chains | Erick C. Jones Jr.</title>








  
    
  
<meta name="description" content="The personal and lab website for Erick C. Jones Jr..">


<meta property="og:site_name" content="Erick C. Jones Jr.">
<meta property="og:title" content="Basics of Markov Chains | Erick C. Jones Jr.">
<meta property="og:description" content="The personal and lab website for Erick C. Jones Jr.." />
<meta property="og:type" content="page" />
<meta property="og:url" content="/blog/orie/markovchains/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="/blog/sidebar-listing.jpg" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="/blog/sidebar-listing.jpg" >
    
    
  <meta itemprop="name" content="Basics of Markov Chains">
<meta itemprop="description" content="This post explores how to markov chains work and how to visulaize them in R.I use a R package specifically designed to visualize markov chains.I also represent these markov chains using tables.This is a reproducible example if you have R Studio just make sure you have installed the correct packages.
library(markovchain)## Warning: package &#39;markovchain&#39; was built under R version 4.0.2library(diagram)#Allows the use of exponential operators in matrixlibrary(expm)## Warning: package &#39;expm&#39; was built under R version 4."><meta itemprop="datePublished" content="2020-01-04T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-01-04T00:00:00+00:00" />
<meta itemprop="wordCount" content="1756">
<meta itemprop="keywords" content="R Markdown,Stochastic Processes,Markov Chains,Statistical Testing," />
  
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/favicon1.ico" type="image/x-icon">
  <link rel="icon" href="/img/favicon1.ico" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.5477c20f89738a32763391bbc2f43dbdfc2db0e7faba550c86cac92c99efa6b6.css" integrity="sha256-VHfCD4lzijJ2M5G7wvQ9vfwtsOf6ulUMhsrJLJnvprY=" media="screen">
  
  
  <script src="/panelset.min.078a92db9bd3228df502db3d9e0453c3cf3d910abe3f8deca0ad196c7071ad41.js" type="text/javascript"></script>
  
  
  <script src="/main.min.2e8249bbdd5d578b176fda15faa5570d1164bf672531c811ea0fe65e5f4ac87a.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="/" title="Home">
      <img src="/img/SApic.jpg" class="dib db-l h2 w-auto" alt="Erick C. Jones Jr.">
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/about/" title="About">About</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/project/" title="Project Portfolio">Projects</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/publication/" title="Publications">Publications</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/courses/" title="Courses">Courses</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/lab/" title="Lab">Lab</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/blog/" title="Posts">Posts</a>
      
      
    </div>
  </nav>
</header>

<main class="page-main pa4" role="main">
  <section class="page-content mw7 center">
    <article class="post-content pa0 ph4-l">
      <header class="post-header">
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">Basics of Markov Chains</h1>
        
        <p class="f6 measure lh-copy mv1">By Erick Jones in <a href="/categories/orie-basics">ORIE Basics</a> </p>
        <p class="f7 db mv0 ttu">January 4, 2020</p>

      

      </header>
      <section class="post-body pt5 pb4">
        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>This post explores how to markov chains work and how to visulaize them in R.
I use a R package specifically designed to visualize markov chains.
I also represent these markov chains using tables.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.</p>
<pre class="r"><code>library(markovchain)</code></pre>
<pre><code>## Warning: package &#39;markovchain&#39; was built under R version 4.0.2</code></pre>
<pre class="r"><code>library(diagram)
#Allows the use of exponential operators in matrix
library(expm)</code></pre>
<pre><code>## Warning: package &#39;expm&#39; was built under R version 4.0.2</code></pre>
<pre class="r"><code>#library(matlib)</code></pre>
<pre class="r"><code># A good article about Markov Chain Monte Carlo Methods https://towardsdatascience.com/a-zero-math-introduction-to-markov-chain-monte-carlo-methods-dcba889e0c50

# A Simple Example from https://www.analyticsvidhya.com/blog/2014/07/markov-chain-simplified/
# Creating a transition matrix
trans_mat &lt;- matrix(c(0.7,0.3,0.1,0.9),nrow = 2, byrow = TRUE)
trans_mat</code></pre>
<pre><code>##      [,1] [,2]
## [1,]  0.7  0.3
## [2,]  0.1  0.9</code></pre>
<pre class="r"><code># create the Discrete Time Markov Chain
disc_trans &lt;- new(&quot;markovchain&quot;,transitionMatrix=trans_mat, states=c(&quot;Pepsi&quot;,&quot;Coke&quot;), name=&quot;MC 1&quot;) 
mcDF &lt;- as(disc_trans,&quot;data.frame&quot;)
mcDF</code></pre>
<pre><code>##      t0    t1 prob
## 1 Pepsi Pepsi  0.7
## 2 Pepsi  Coke  0.3
## 3  Coke Pepsi  0.1
## 4  Coke  Coke  0.9</code></pre>
<pre class="r"><code>disc_trans</code></pre>
<pre><code>## MC 1 
##  A  2 - dimensional discrete Markov Chain defined by the following states: 
##  Pepsi, Coke 
##  The transition matrix  (by rows)  is defined as follows: 
##       Pepsi Coke
## Pepsi   0.7  0.3
## Coke    0.1  0.9</code></pre>
<pre class="r"><code>plot(disc_trans)</code></pre>
<p><img src="/post/ORIE/markovchains_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>#Market Share after one month
Current_state &lt;- c(0.55,0.45)
steps &lt;- 1
finalState &lt;- Current_state*disc_trans^steps #using power operator
finalState</code></pre>
<pre><code>##      Pepsi Coke
## [1,]  0.43 0.57</code></pre>
<pre class="r"><code>#Market Share after two month
Current_state &lt;- c(0.55,0.45)
steps &lt;- 2
finalState &lt;- Current_state*disc_trans^steps #using power operator
finalState</code></pre>
<pre><code>##      Pepsi  Coke
## [1,] 0.358 0.642</code></pre>
<pre class="r"><code>#Markov Chain Statistical Operations
steadyStates(disc_trans)</code></pre>
<pre><code>##      Pepsi Coke
## [1,]  0.25 0.75</code></pre>
<pre class="r"><code>meanFirstPassageTime(disc_trans)</code></pre>
<pre><code>##       Pepsi     Coke
## Pepsi     0 3.333333
## Coke     10 0.000000</code></pre>
<pre class="r"><code>meanRecurrenceTime(disc_trans)</code></pre>
<pre><code>##    Pepsi     Coke 
## 4.000000 1.333333</code></pre>
<pre class="r"><code>hittingProbabilities(disc_trans)</code></pre>
<pre><code>##       Pepsi Coke
## Pepsi     1    1
## Coke      1    1</code></pre>
<pre class="r"><code>meanAbsorptionTime(disc_trans)</code></pre>
<pre><code>## named numeric(0)</code></pre>
<pre class="r"><code>#absorptionProbabilities(disc_trans)
period(disc_trans)</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>summary(disc_trans)</code></pre>
<pre><code>## MC 1  Markov chain that is composed by: 
## Closed classes: 
## Pepsi Coke 
## Recurrent classes: 
## {Pepsi,Coke}
## Transient classes: 
## NONE 
## The Markov chain is irreducible 
## The absorbing states are: NONE</code></pre>
<pre class="r"><code>#Manually Calculating Markov Chains
#https://www.probabilitycourse.com/chapter11/11_2_1_introduction.php

#Chapman-Kolmogorov Equation P^(n) = P^n
#p_ij^(m+n) = P(X_m+n = j | X_0 = i) = sum(p_ik^(m)*p_kj^(n))

#Probabilty Space after 5 steps
steps &lt;- 5

Current_state%*%(trans_mat%^%steps)</code></pre>
<pre><code>##          [,1]     [,2]
## [1,] 0.273328 0.726672</code></pre>
<pre class="r"><code>#Mean Return and Mean Hitting Times using Recursive Equations
#r_l = 1 + sum(t_k*p_lk)
#t_l = 0; t_k = 1 + sum(t_j*p_kj)

#Given X_0 = Coke time until pepsi first time, t_pepsi = 0
# t_coke = 1 + 1/10*t_pepsi + 9/10t_coke
t_coke &lt;- solve(1/10,1)
#r_pepsi = 1 + 7/10*t_pepsi + 3/10*t_coke
r_pepsi &lt;- 1 + 3/10*t_coke

meanFirstPassageTime(disc_trans)</code></pre>
<pre><code>##       Pepsi     Coke
## Pepsi     0 3.333333
## Coke     10 0.000000</code></pre>
<pre class="r"><code>t_coke</code></pre>
<pre><code>## [1] 10</code></pre>
<pre class="r"><code>meanRecurrenceTime(disc_trans)</code></pre>
<pre><code>##    Pepsi     Coke 
## 4.000000 1.333333</code></pre>
<pre class="r"><code>r_pepsi</code></pre>
<pre><code>## [1] 4</code></pre>
<pre class="r"><code>#Steady State
#Stationary Distribtution pi = pi*P, sum(pi) = 1 and if irreducible and aperiodic pi_j = lim(n&gt;inf)P(X_n =j | X_0 = i)
#pi_p = 7/10pi_p+1/10pi_c; pi_c = 3/10pi_p + 9/10pi_c, pi_c+pi_p =1
A &lt;- matrix(c(-3/10,1/10,3/10,-1/10,1,1), nrow =3, byrow = TRUE )
B &lt;- c(0,0,1)
steadyStates(disc_trans)</code></pre>
<pre><code>##      Pepsi Coke
## [1,]  0.25 0.75</code></pre>
<pre class="r"><code># Solve(A,B)




#rm(Current_state, disc_trans, finalState,steps,trans_mat)</code></pre>
<pre class="r"><code>#Continous Time Markov Chains

energyStates &lt;- c(&quot;sigma&quot;, &quot;sigma_star&quot;)
#Must produce generator matrix from a transistion probablity matrix
Q &lt;- expm::logm(disc_trans@transitionMatrix,method=&#39;Eigen&#39;)

gen &lt;- matrix(data = c(-3, 3, 1, -1), nrow = 2, byrow = TRUE, dimnames = list(energyStates, energyStates))

molecularCTMC &lt;- new(&quot;ctmc&quot;, states = energyStates, byrow = TRUE, generator = gen, name = &quot;Molecular Transition Model&quot;)

statesDist &lt;- c(0.8, 0.2)
rctmc(n = 3, ctmc = molecularCTMC, initDist = statesDist, out.type = &quot;df&quot;, include.T0 = FALSE, T = 4)</code></pre>
<pre><code>##       states              time
## 1      sigma 0.490779113024473
## 2 sigma_star 0.893907884742721
## 3      sigma  1.83824493102602</code></pre>
<pre class="r"><code>steadyStates(molecularCTMC)</code></pre>
<pre><code>##      sigma sigma_star
## [1,]  0.25       0.75</code></pre>
<pre class="r"><code>#Q-Learning with Liars Dice
#http://gradientdescending.com/q-learning-example-with-liars-dice-in-r/

# play a round of liars dice
liars.dice.round &lt;- function(players, control, player.dice.count, agents, game.states, reward, Q.mat, a = 1, verbose = 1){
  
  # set array for recording results
  y.ctrl = c(); y.state = c(); y.action = c()
  
  # roll the dice for each player
  if(verbose &gt; 0) cat(&quot;\n\n&quot;)
  rolls &lt;- lapply(1:players, function(x) sort(sample(1:6, player.dice.count[[x]], replace = TRUE)))
  if(verbose &gt; 1) lapply(rolls, function(x) cat(&quot;dice: &quot;, x, &quot;\n&quot;))
  total.dice &lt;- sum(unlist(player.dice.count))
  
  # set penalty
  penalty &lt;- sapply(1:players, function(x) 0, simplify = FALSE)
  
  # print dice blocks
  if(verbose &gt; 0) Dice(rolls[[1]])
  
  # set up roll table
  roll.table &lt;- roll.table.fn(rolls)
  
  # initial bid
  if(verbose &gt; 0) cat(&quot;place first bid\nPlayer&quot;, control, &quot;has control\n&quot;)
  if(control == a){
    
    dice.value &lt;- set.dice.value(&quot;dice value: &quot;, 6)
    dice.quantity &lt;- set.dice.value(&quot;quantity; &quot;, sum(roll.table))
    
  }else{
    
    # agent plays
    p1.state &lt;- which(game.states$total == total.dice &amp; game.states$p1 == player.dice.count[[1]] &amp; game.states$prob_cat == total.dice)
    pars &lt;- list(dice = rolls[[control]], total.dice = total.dice, dice.value = NULL, dice.quantity = 0, p1.state = p1.state)
    agent.action &lt;- agents[[control]](pars = pars, Q.mat = Q.mat)
    dice.value &lt;- agent.action$dice.value
    dice.quantity &lt;- agent.action$dice.quantity
    
  }
  
  
  # calculate probability cat and determine the game state
  # action set to raise because you can&#39;t call without an initial bid
  # this could be a 3rd action (initial bid) but it&#39;s not really necessary
  player.dice.qty &lt;- table(rolls[[1]])[as.character(dice.value)]
  player.dice.qty &lt;- ifelse(is.na(player.dice.qty), 0, player.dice.qty) %&gt;% unname
  prob.cat &lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
  p1.state &lt;- which(game.states$total == total.dice &amp; game.states$p1 == player.dice.count[[1]] &amp; game.states$prob_cat == prob.cat)
  p1.action &lt;- &quot;raise&quot;
  
  # storing states for Q iteration
  y.ctrl = c(); y.state = c(); y.action = c()
  
  # moving control to the next player
  # storing the previous player since if the next player calls the previous player could lose a die
  prev &lt;- control
  control &lt;- control %% players + 1
  if(verbose &gt; 0) cat(&quot;dice value &quot;, dice.value, &quot;; dice quantity &quot;, dice.quantity, &quot;\n&quot;)
  
  
  # loop through each player and continue until there is a winner and loser
  called &lt;- FALSE
  while(!called){
    
    # check if the player with control is still in the game - if not skip
    if(player.dice.count[[control]] &gt; 0){
      if(control == a){
        
        action &lt;- readline(&quot;raise or call (r/c)? &quot;)
        
      }else{
        
        # the agent makes a decision
        pars &lt;- list(dice = rolls[[control]], total.dice = total.dice, dice.value = dice.value, dice.quantity = dice.quantity, p1.state = p1.state)
        agent.action &lt;- agents[[control]](pars = pars, Q.mat = Q.mat)
        action &lt;- agent.action$action
        
      }
      
      
      # storing states for reward iteration
      if(control == 1 &amp; !is.null(agent.action$action)){
        player.dice.qty &lt;- table(rolls[[1]])[as.character(dice.value)]
        player.dice.qty &lt;- ifelse(is.na(player.dice.qty), 0, player.dice.qty) %&gt;% unname
        
        p1.action &lt;- agent.action$action
        prob.cat &lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &lt;- which(game.states$total == total.dice &amp; game.states$p1 == player.dice.count[[1]] &amp; game.states$prob_cat == prob.cat)
      }
      
      
      # called
      if(action %in% c(&quot;call&quot;, &quot;c&quot;)){
        
        if(verbose &gt; 0) {
          cat(&quot;player&quot;, control, &quot;called\nRoll table\n&quot;)
          print(roll.table)
        }
        
        # dice are reavealed
        
        # check if the quantity of dice value is less or more than the total in the pool
        # if more control loses otherwise control-1 win
        if(dice.quantity &gt; roll.table[dice.value]){
          
          penalty[[prev]] &lt;- penalty[[prev]] - 1
          if(verbose &gt; 0) cat(&quot;player&quot;, prev, &quot;lost a die\n&quot;)
          
        }else{
          
          penalty[[control]] &lt;- penalty[[control]] - 1
          if(verbose &gt; 0) cat(&quot;player&quot;, control, &quot;lost a die\n&quot;)
          
        }
        
        # for Q iteration
        y.ctrl &lt;- c(y.ctrl, control); y.state &lt;- c(y.state, p1.state); y.action &lt;- c(y.action, p1.action)
        
        # if called use the penalty array to change states
        prob.cat &lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &lt;- which(game.states$total == total.dice-1 &amp; game.states$p1 == player.dice.count[[1]]+penalty[[1]] &amp; game.states$prob_cat == prob.cat)
        
        # break the loop
        called &lt;- TRUE
        
      }else{
        
        if(verbose &gt; 0) cat(&quot;player&quot;, control, &quot;raised\n&quot;)
        
        if(control == a){
          
          # player sets next dice value
          dice.value &lt;- set.dice.value(&quot;dice value: &quot;, 6)
          dice.quantity &lt;- set.dice.value(&quot;quantity; &quot;, sum(roll.table))
          
        }else{
          
          dice.value &lt;- agent.action$dice.value
          dice.quantity &lt;- agent.action$dice.quantity
        }
        
        # p1 state after the raise
        prob.cat &lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &lt;- which(game.states$total == total.dice &amp; game.states$p1 == player.dice.count[[1]] &amp; game.states$prob_cat == prob.cat)
        if(verbose &gt; 0) cat(&quot;dice value&quot;, dice.value, &quot;; dice quantity&quot;, dice.quantity, &quot;\n&quot;)
      }
      
      # store info for Q update
      y.ctrl &lt;- c(y.ctrl, control); y.state &lt;- c(y.state, p1.state); y.action &lt;- c(y.action, p1.action)
      
      # set the control player to now be the previous player
      prev &lt;- control
    }
    
    # next player has control
    control &lt;- control %% players + 1
  }
  
  # play results and return
  play &lt;- data.frame(y.ctrl, y.state, y.action)
  return(list(penalty = penalty, play = play))
}








# play a full game of liars dice
play.liars.dice &lt;- function(players = 4, num.dice = 6, auto = FALSE, verbose = 1, agents, Q.mat = NULL, train = FALSE, print.trans = FALSE){
  
  # begin!
  if(verbose &gt; 0) liars.dice.title()
  
  # setting the number of dice each player has
  ndice &lt;- sapply(rep(num.dice, players), function(x) x, simplify = FALSE)
  players.left &lt;- sum(unlist(ndice) &gt; 0)
  
  # setting game states matrix
  game.states &lt;- generate.game.states(players, num.dice)
  
  # set up reward matrix
  reward &lt;- generate.reward.matrix(game.states)
  reward &lt;- list(raise = reward, call = reward)
  
  # set Q matrix if null
  if(is.null(Q.mat)) Q.mat &lt;- matrix(0, nrow = nrow(reward$raise), ncol = length(reward), dimnames = list(c(), names(reward)))
  
  # while there is at least 2 left in the game
  # who has control
  ctrl &lt;- sample(1:players, 1)
  play.df &lt;- data.frame()
  while(players.left &gt; 1){
    
    # play a round
    results &lt;- liars.dice.round(
      players = players, 
      control = ctrl,
      player.dice.count = ndice, 
      game.states = game.states,
      reward = reward,
      Q.mat = Q.mat,
      agents = agents,
      a = as.numeric(!auto),
      verbose = verbose
    )
    
    # update how many dice the players are left with given the 
    # outcomes of the round
    for(k in seq_along(ndice)){
      ndice[[k]] &lt;- ndice[[k]] + results$penalty[[k]]
      if(ndice[[k]] == 0 &amp; results$penalty[[k]] == -1){
        if(verbose &gt; 0) cat(&quot;player&quot;, k, &quot;is out of the game\n&quot;)
      }
      
      # update who has control so they can start the bidding
      if(results$penalty[[k]] == -1){
        ctrl &lt;- k
        while(ndice[[ctrl]] == 0){
          ctrl &lt;- ctrl %% players + 1
        }
      }
    }
    
    # checking how many are left and if anyone won the game
    players.left &lt;- sum(unlist(ndice) &gt; 0)
    if(players.left == 1){
      if(verbose &gt; 0) cat(&quot;player&quot;, which(unlist(ndice) &gt; 0), &quot;won the game\n&quot;)
    }
    
    # appending play
    play.df &lt;- rbind(play.df, results$play)
  }
  
  if(print.trans) print(play.df)
  
  # update Q
  # rather than training after each action, training at the 
  # end of each game in bulk
  # just easier this way
  if(train) Q.mat &lt;- update.Q(play.df, Q.mat, reward)
  
  # return the winner and Q matrix
  return(list(winner = which(unlist(ndice) &gt; 0), Q.mat = Q.mat))
}</code></pre>
<pre class="r"><code>#Other Stochastic Processes
#Martingales http://gradientdescending.com/martingale-strategies-dont-work-but-we-knew-that-simulation-analysis-in-r/
#https://github.com/doehm/martingale

#Bayesian Networks http://gradientdescending.com/simulating-data-with-bayesian-networks/

#Other Q Learning https://www.r-bloggers.com/a-simple-intro-to-q-learning-in-r-floor-plan-navigation/
#https://dataaspirant.com/2018/02/05/reinforcement-learning-r/</code></pre>
<p>Add a new chunk by clicking the <em>Insert Chunk</em> button on the toolbar or by pressing <em>Ctrl+Alt+I</em>.</p>
<p>When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the <em>Preview</em> button or press <em>Ctrl+Shift+K</em> to preview the HTML file).</p>
<p>The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike <em>Knit</em>, <em>Preview</em> does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.</p>

        
        <details closed class="f6 fw7 input-reset">
  <dl class="f6 lh-copy">
    <dt class="fw7">Posted on:</dt>
    <dd class="fw5 ml0">January 4, 2020</dd>
  </dl>
  <dl class="f6 lh-copy">
    <dt class="fw7">Length:</dt>
    <dd class="fw5 ml0">9 minute read, 1756 words</dd>
  </dl>
  
  <dl class="f6 lh-copy">
    <dt class="fw7">Categories:</dt>
    <dd class="fw5 ml0"> <a href="/categories/orie-basics">ORIE Basics</a> </dd>
  </dl>
  
  
  
  <dl class="f6 lh-copy">
    <dt class="fw7">Tags:</dt>
    <dd class="fw5 ml0"> <a href="/tags/r-markdown">R Markdown</a>  <a href="/tags/stochastic-processes">Stochastic Processes</a>  <a href="/tags/markov-chains">Markov Chains</a>  <a href="/tags/statistical-testing">Statistical Testing</a> </dd>
  </dl>
  
  <dl class="f6 lh-copy">
    <dt class="fw7">See Also:</dt>
    
    <dd class="fw5 ml0"><a href="/blog/orie/decompo_algs/">Decompositions Algorithms Broken Down and Explained</a></dd>
    
    <dd class="fw5 ml0"><a href="/blog/orie/benders/">Benders Decomposition Algorithm Explained</a></dd>
    
    <dd class="fw5 ml0"><a href="/blog/orie/qp_algorithms/">Quadratic Programming Examples and Algorithms</a></dd>
    
  </dl>
</details>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
    <a class="prev dtc pr2 tl v-top fw6"
    href="/blog/orie/gurobi_examples/">&larr; Gurobi Basic LP/MIP Examples</a>
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="/blog/orie/lp_algorithms/">Linear Programming Examples and Applications &rarr;</a>
  
</div>

      </footer>
    </article>
    
      
<div class="post-comments pa0 pa4-l mt4">
  
  <script src="https://utteranc.es/client.js"
          repo="apreshill/apero"
          issue-term="pathname"
          theme="boxy-light"
          label="comments :crystal_ball:"
          crossorigin="anonymous"
          async
          type="text/javascript">
  </script>
  
</div>

    
  </section>
</main>
<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2022 Erick Jones, Texas
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo Ap√©ro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
