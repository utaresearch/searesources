<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistical Testing | Erick Jones</title>
    <link>/tag/statistical-testing/</link>
      <atom:link href="/tag/statistical-testing/index.xml" rel="self" type="application/rss+xml" />
    <description>Statistical Testing</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>&amp;copy Erick Jones {2020}</copyright><lastBuildDate>Sat, 04 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Statistical Testing</title>
      <link>/tag/statistical-testing/</link>
    </image>
    
    <item>
      <title>Basics of Markov Chains</title>
      <link>/post/orie/markovchains/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/orie/markovchains/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post explores how to markov chains work and how to visulaize them in R.
I use a R package specifically designed to visualize markov chains.
I also represent these markov chains using tables.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(markovchain)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;markovchain&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(diagram)
#Allows the use of exponential operators in matrix
library(expm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;expm&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#library(matlib)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A good article about Markov Chain Monte Carlo Methods https://towardsdatascience.com/a-zero-math-introduction-to-markov-chain-monte-carlo-methods-dcba889e0c50

# A Simple Example from https://www.analyticsvidhya.com/blog/2014/07/markov-chain-simplified/
# Creating a transition matrix
trans_mat &amp;lt;- matrix(c(0.7,0.3,0.1,0.9),nrow = 2, byrow = TRUE)
trans_mat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]  0.7  0.3
## [2,]  0.1  0.9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create the Discrete Time Markov Chain
disc_trans &amp;lt;- new(&amp;quot;markovchain&amp;quot;,transitionMatrix=trans_mat, states=c(&amp;quot;Pepsi&amp;quot;,&amp;quot;Coke&amp;quot;), name=&amp;quot;MC 1&amp;quot;) 
mcDF &amp;lt;- as(disc_trans,&amp;quot;data.frame&amp;quot;)
mcDF&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      t0    t1 prob
## 1 Pepsi Pepsi  0.7
## 2 Pepsi  Coke  0.3
## 3  Coke Pepsi  0.1
## 4  Coke  Coke  0.9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;disc_trans&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## MC 1 
##  A  2 - dimensional discrete Markov Chain defined by the following states: 
##  Pepsi, Coke 
##  The transition matrix  (by rows)  is defined as follows: 
##       Pepsi Coke
## Pepsi   0.7  0.3
## Coke    0.1  0.9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/markovchains_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Market Share after one month
Current_state &amp;lt;- c(0.55,0.45)
steps &amp;lt;- 1
finalState &amp;lt;- Current_state*disc_trans^steps #using power operator
finalState&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Pepsi Coke
## [1,]  0.43 0.57&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Market Share after two month
Current_state &amp;lt;- c(0.55,0.45)
steps &amp;lt;- 2
finalState &amp;lt;- Current_state*disc_trans^steps #using power operator
finalState&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Pepsi  Coke
## [1,] 0.358 0.642&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Markov Chain Statistical Operations
steadyStates(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Pepsi Coke
## [1,]  0.25 0.75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meanFirstPassageTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Pepsi     Coke
## Pepsi     0 3.333333
## Coke     10 0.000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meanRecurrenceTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Pepsi     Coke 
## 4.000000 1.333333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hittingProbabilities(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Pepsi Coke
## Pepsi     1    1
## Coke      1    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meanAbsorptionTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## named numeric(0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#absorptionProbabilities(disc_trans)
period(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## MC 1  Markov chain that is composed by: 
## Closed classes: 
## Pepsi Coke 
## Recurrent classes: 
## {Pepsi,Coke}
## Transient classes: 
## NONE 
## The Markov chain is irreducible 
## The absorbing states are: NONE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Manually Calculating Markov Chains
#https://www.probabilitycourse.com/chapter11/11_2_1_introduction.php

#Chapman-Kolmogorov Equation P^(n) = P^n
#p_ij^(m+n) = P(X_m+n = j | X_0 = i) = sum(p_ik^(m)*p_kj^(n))

#Probabilty Space after 5 steps
steps &amp;lt;- 5

Current_state%*%(trans_mat%^%steps)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          [,1]     [,2]
## [1,] 0.273328 0.726672&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Mean Return and Mean Hitting Times using Recursive Equations
#r_l = 1 + sum(t_k*p_lk)
#t_l = 0; t_k = 1 + sum(t_j*p_kj)

#Given X_0 = Coke time until pepsi first time, t_pepsi = 0
# t_coke = 1 + 1/10*t_pepsi + 9/10t_coke
t_coke &amp;lt;- solve(1/10,1)
#r_pepsi = 1 + 7/10*t_pepsi + 3/10*t_coke
r_pepsi &amp;lt;- 1 + 3/10*t_coke

meanFirstPassageTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Pepsi     Coke
## Pepsi     0 3.333333
## Coke     10 0.000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_coke&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meanRecurrenceTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Pepsi     Coke 
## 4.000000 1.333333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_pepsi&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Steady State
#Stationary Distribtution pi = pi*P, sum(pi) = 1 and if irreducible and aperiodic pi_j = lim(n&amp;gt;inf)P(X_n =j | X_0 = i)
#pi_p = 7/10pi_p+1/10pi_c; pi_c = 3/10pi_p + 9/10pi_c, pi_c+pi_p =1
A &amp;lt;- matrix(c(-3/10,1/10,3/10,-1/10,1,1), nrow =3, byrow = TRUE )
B &amp;lt;- c(0,0,1)
steadyStates(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Pepsi Coke
## [1,]  0.25 0.75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Solve(A,B)




#rm(Current_state, disc_trans, finalState,steps,trans_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Continous Time Markov Chains

energyStates &amp;lt;- c(&amp;quot;sigma&amp;quot;, &amp;quot;sigma_star&amp;quot;)
#Must produce generator matrix from a transistion probablity matrix
Q &amp;lt;- expm::logm(disc_trans@transitionMatrix,method=&amp;#39;Eigen&amp;#39;)

gen &amp;lt;- matrix(data = c(-3, 3, 1, -1), nrow = 2, byrow = TRUE, dimnames = list(energyStates, energyStates))

molecularCTMC &amp;lt;- new(&amp;quot;ctmc&amp;quot;, states = energyStates, byrow = TRUE, generator = gen, name = &amp;quot;Molecular Transition Model&amp;quot;)

statesDist &amp;lt;- c(0.8, 0.2)
rctmc(n = 3, ctmc = molecularCTMC, initDist = statesDist, out.type = &amp;quot;df&amp;quot;, include.T0 = FALSE, T = 4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       states              time
## 1      sigma 0.490779113024473
## 2 sigma_star 0.893907884742721
## 3      sigma  1.83824493102602&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steadyStates(molecularCTMC)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      sigma sigma_star
## [1,]  0.25       0.75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Q-Learning with Liars Dice
#http://gradientdescending.com/q-learning-example-with-liars-dice-in-r/

# play a round of liars dice
liars.dice.round &amp;lt;- function(players, control, player.dice.count, agents, game.states, reward, Q.mat, a = 1, verbose = 1){
  
  # set array for recording results
  y.ctrl = c(); y.state = c(); y.action = c()
  
  # roll the dice for each player
  if(verbose &amp;gt; 0) cat(&amp;quot;\n\n&amp;quot;)
  rolls &amp;lt;- lapply(1:players, function(x) sort(sample(1:6, player.dice.count[[x]], replace = TRUE)))
  if(verbose &amp;gt; 1) lapply(rolls, function(x) cat(&amp;quot;dice: &amp;quot;, x, &amp;quot;\n&amp;quot;))
  total.dice &amp;lt;- sum(unlist(player.dice.count))
  
  # set penalty
  penalty &amp;lt;- sapply(1:players, function(x) 0, simplify = FALSE)
  
  # print dice blocks
  if(verbose &amp;gt; 0) Dice(rolls[[1]])
  
  # set up roll table
  roll.table &amp;lt;- roll.table.fn(rolls)
  
  # initial bid
  if(verbose &amp;gt; 0) cat(&amp;quot;place first bid\nPlayer&amp;quot;, control, &amp;quot;has control\n&amp;quot;)
  if(control == a){
    
    dice.value &amp;lt;- set.dice.value(&amp;quot;dice value: &amp;quot;, 6)
    dice.quantity &amp;lt;- set.dice.value(&amp;quot;quantity; &amp;quot;, sum(roll.table))
    
  }else{
    
    # agent plays
    p1.state &amp;lt;- which(game.states$total == total.dice &amp;amp; game.states$p1 == player.dice.count[[1]] &amp;amp; game.states$prob_cat == total.dice)
    pars &amp;lt;- list(dice = rolls[[control]], total.dice = total.dice, dice.value = NULL, dice.quantity = 0, p1.state = p1.state)
    agent.action &amp;lt;- agents[[control]](pars = pars, Q.mat = Q.mat)
    dice.value &amp;lt;- agent.action$dice.value
    dice.quantity &amp;lt;- agent.action$dice.quantity
    
  }
  
  
  # calculate probability cat and determine the game state
  # action set to raise because you can&amp;#39;t call without an initial bid
  # this could be a 3rd action (initial bid) but it&amp;#39;s not really necessary
  player.dice.qty &amp;lt;- table(rolls[[1]])[as.character(dice.value)]
  player.dice.qty &amp;lt;- ifelse(is.na(player.dice.qty), 0, player.dice.qty) %&amp;gt;% unname
  prob.cat &amp;lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
  p1.state &amp;lt;- which(game.states$total == total.dice &amp;amp; game.states$p1 == player.dice.count[[1]] &amp;amp; game.states$prob_cat == prob.cat)
  p1.action &amp;lt;- &amp;quot;raise&amp;quot;
  
  # storing states for Q iteration
  y.ctrl = c(); y.state = c(); y.action = c()
  
  # moving control to the next player
  # storing the previous player since if the next player calls the previous player could lose a die
  prev &amp;lt;- control
  control &amp;lt;- control %% players + 1
  if(verbose &amp;gt; 0) cat(&amp;quot;dice value &amp;quot;, dice.value, &amp;quot;; dice quantity &amp;quot;, dice.quantity, &amp;quot;\n&amp;quot;)
  
  
  # loop through each player and continue until there is a winner and loser
  called &amp;lt;- FALSE
  while(!called){
    
    # check if the player with control is still in the game - if not skip
    if(player.dice.count[[control]] &amp;gt; 0){
      if(control == a){
        
        action &amp;lt;- readline(&amp;quot;raise or call (r/c)? &amp;quot;)
        
      }else{
        
        # the agent makes a decision
        pars &amp;lt;- list(dice = rolls[[control]], total.dice = total.dice, dice.value = dice.value, dice.quantity = dice.quantity, p1.state = p1.state)
        agent.action &amp;lt;- agents[[control]](pars = pars, Q.mat = Q.mat)
        action &amp;lt;- agent.action$action
        
      }
      
      
      # storing states for reward iteration
      if(control == 1 &amp;amp; !is.null(agent.action$action)){
        player.dice.qty &amp;lt;- table(rolls[[1]])[as.character(dice.value)]
        player.dice.qty &amp;lt;- ifelse(is.na(player.dice.qty), 0, player.dice.qty) %&amp;gt;% unname
        
        p1.action &amp;lt;- agent.action$action
        prob.cat &amp;lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &amp;lt;- which(game.states$total == total.dice &amp;amp; game.states$p1 == player.dice.count[[1]] &amp;amp; game.states$prob_cat == prob.cat)
      }
      
      
      # called
      if(action %in% c(&amp;quot;call&amp;quot;, &amp;quot;c&amp;quot;)){
        
        if(verbose &amp;gt; 0) {
          cat(&amp;quot;player&amp;quot;, control, &amp;quot;called\nRoll table\n&amp;quot;)
          print(roll.table)
        }
        
        # dice are reavealed
        
        # check if the quantity of dice value is less or more than the total in the pool
        # if more control loses otherwise control-1 win
        if(dice.quantity &amp;gt; roll.table[dice.value]){
          
          penalty[[prev]] &amp;lt;- penalty[[prev]] - 1
          if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, prev, &amp;quot;lost a die\n&amp;quot;)
          
        }else{
          
          penalty[[control]] &amp;lt;- penalty[[control]] - 1
          if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, control, &amp;quot;lost a die\n&amp;quot;)
          
        }
        
        # for Q iteration
        y.ctrl &amp;lt;- c(y.ctrl, control); y.state &amp;lt;- c(y.state, p1.state); y.action &amp;lt;- c(y.action, p1.action)
        
        # if called use the penalty array to change states
        prob.cat &amp;lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &amp;lt;- which(game.states$total == total.dice-1 &amp;amp; game.states$p1 == player.dice.count[[1]]+penalty[[1]] &amp;amp; game.states$prob_cat == prob.cat)
        
        # break the loop
        called &amp;lt;- TRUE
        
      }else{
        
        if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, control, &amp;quot;raised\n&amp;quot;)
        
        if(control == a){
          
          # player sets next dice value
          dice.value &amp;lt;- set.dice.value(&amp;quot;dice value: &amp;quot;, 6)
          dice.quantity &amp;lt;- set.dice.value(&amp;quot;quantity; &amp;quot;, sum(roll.table))
          
        }else{
          
          dice.value &amp;lt;- agent.action$dice.value
          dice.quantity &amp;lt;- agent.action$dice.quantity
        }
        
        # p1 state after the raise
        prob.cat &amp;lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &amp;lt;- which(game.states$total == total.dice &amp;amp; game.states$p1 == player.dice.count[[1]] &amp;amp; game.states$prob_cat == prob.cat)
        if(verbose &amp;gt; 0) cat(&amp;quot;dice value&amp;quot;, dice.value, &amp;quot;; dice quantity&amp;quot;, dice.quantity, &amp;quot;\n&amp;quot;)
      }
      
      # store info for Q update
      y.ctrl &amp;lt;- c(y.ctrl, control); y.state &amp;lt;- c(y.state, p1.state); y.action &amp;lt;- c(y.action, p1.action)
      
      # set the control player to now be the previous player
      prev &amp;lt;- control
    }
    
    # next player has control
    control &amp;lt;- control %% players + 1
  }
  
  # play results and return
  play &amp;lt;- data.frame(y.ctrl, y.state, y.action)
  return(list(penalty = penalty, play = play))
}








# play a full game of liars dice
play.liars.dice &amp;lt;- function(players = 4, num.dice = 6, auto = FALSE, verbose = 1, agents, Q.mat = NULL, train = FALSE, print.trans = FALSE){
  
  # begin!
  if(verbose &amp;gt; 0) liars.dice.title()
  
  # setting the number of dice each player has
  ndice &amp;lt;- sapply(rep(num.dice, players), function(x) x, simplify = FALSE)
  players.left &amp;lt;- sum(unlist(ndice) &amp;gt; 0)
  
  # setting game states matrix
  game.states &amp;lt;- generate.game.states(players, num.dice)
  
  # set up reward matrix
  reward &amp;lt;- generate.reward.matrix(game.states)
  reward &amp;lt;- list(raise = reward, call = reward)
  
  # set Q matrix if null
  if(is.null(Q.mat)) Q.mat &amp;lt;- matrix(0, nrow = nrow(reward$raise), ncol = length(reward), dimnames = list(c(), names(reward)))
  
  # while there is at least 2 left in the game
  # who has control
  ctrl &amp;lt;- sample(1:players, 1)
  play.df &amp;lt;- data.frame()
  while(players.left &amp;gt; 1){
    
    # play a round
    results &amp;lt;- liars.dice.round(
      players = players, 
      control = ctrl,
      player.dice.count = ndice, 
      game.states = game.states,
      reward = reward,
      Q.mat = Q.mat,
      agents = agents,
      a = as.numeric(!auto),
      verbose = verbose
    )
    
    # update how many dice the players are left with given the 
    # outcomes of the round
    for(k in seq_along(ndice)){
      ndice[[k]] &amp;lt;- ndice[[k]] + results$penalty[[k]]
      if(ndice[[k]] == 0 &amp;amp; results$penalty[[k]] == -1){
        if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, k, &amp;quot;is out of the game\n&amp;quot;)
      }
      
      # update who has control so they can start the bidding
      if(results$penalty[[k]] == -1){
        ctrl &amp;lt;- k
        while(ndice[[ctrl]] == 0){
          ctrl &amp;lt;- ctrl %% players + 1
        }
      }
    }
    
    # checking how many are left and if anyone won the game
    players.left &amp;lt;- sum(unlist(ndice) &amp;gt; 0)
    if(players.left == 1){
      if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, which(unlist(ndice) &amp;gt; 0), &amp;quot;won the game\n&amp;quot;)
    }
    
    # appending play
    play.df &amp;lt;- rbind(play.df, results$play)
  }
  
  if(print.trans) print(play.df)
  
  # update Q
  # rather than training after each action, training at the 
  # end of each game in bulk
  # just easier this way
  if(train) Q.mat &amp;lt;- update.Q(play.df, Q.mat, reward)
  
  # return the winner and Q matrix
  return(list(winner = which(unlist(ndice) &amp;gt; 0), Q.mat = Q.mat))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Other Stochastic Processes
#Martingales http://gradientdescending.com/martingale-strategies-dont-work-but-we-knew-that-simulation-analysis-in-r/
#https://github.com/doehm/martingale

#Bayesian Networks http://gradientdescending.com/simulating-data-with-bayesian-networks/

#Other Q Learning https://www.r-bloggers.com/a-simple-intro-to-q-learning-in-r-floor-plan-navigation/
#https://dataaspirant.com/2018/02/05/reinforcement-learning-r/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Basics of Simulation</title>
      <link>/post/orie/simulation_basics/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/orie/simulation_basics/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post explores some of the basic concepts of simulation.
I mostly explore these concepts using basic probablity and the built in distribution functions.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Ideas from Probablity Course https://www.probabilitycourse.com/chapter13/chapter13.php


set.seed(123)
p &amp;lt;- 0.5
n &amp;lt;- 1000
U &amp;lt;- runif(n)

toss &amp;lt;- as.integer(U &amp;lt; p)

#cumalative number of heads 
a &amp;lt;- numeric(n+1)
#running average of heads
avg &amp;lt;- numeric(n)

for(i in 2:n+1){
  a[i] &amp;lt;- a[i-1] + toss[i-1]
  avg[i-1] &amp;lt;- a[i]/(i-1)
}

plot(1:n, avg, type = &amp;quot;l&amp;quot;, lwd = 5, col = &amp;quot;blue&amp;quot;, ylab = &amp;quot;ProportionofHeads&amp;quot;,
xlab = &amp;quot;CoinTossNumber&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(p,n,U,toss,a,avg, i)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
p &amp;lt;- 0.2
n &amp;lt;- 1000
U &amp;lt;- runif(n)
#The function U &amp;lt; p creates Bernouli Random variables with probablity p, 1 if U &amp;lt; p 0 otherwise
#the sum of Bernouli variables is a Binomial of (n,p) so X is a Binomial(1000,0.2)

X &amp;lt;- sum(as.integer(U &amp;lt; p))
X&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 198&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#The built in function for binomial (number of observations, number of trials, probablity)
rbinom(1,n,p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 196&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Arbitrary Distribution
#P(X =1) = 0.35, P(X = 2) = 0.15, P(X=3) = 0.4, P(X=4) = 0.1
#P(X=xi) = P(U element Ai) = pi
P &amp;lt;- c(0.35,0.5,0.9,1)
X &amp;lt;- c(1,2,3,4)
i &amp;lt;- 1
r &amp;lt;- runif(1)

while(r &amp;gt; P[i]){
  i &amp;lt;- i + 1
}

X[i]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Create RV with density f(x) = 2.5*x*sqrt(x) = x^5/2
#Using inverse X^5/2 = U &amp;gt;&amp;gt; X = U^2/5

U &amp;lt;- runif(1)
X &amp;lt;- U^(2/5)
print(paste(&amp;#39;Distrubution with density f(x) = X^(5/2):&amp;#39;,X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Distrubution with density f(x) = X^(5/2): 0.938571171721709&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Generate RV with density function Beta(2,4), g(x) =1 0&amp;lt;x&amp;lt;1
#f(x) = 20x(1-x)^3, g(x) = 1, f(x)/g(x) = 20x(1-x)^3
#Find smallest c such that f(x)/g(x) &amp;lt;= c
#Using differention d(f(x)/g(x))/dx &amp;gt;&amp;gt;&amp;gt; x = 1/4 &amp;gt;&amp;gt;&amp;gt; f(x)/g(x) &amp;lt;= 135/64 &amp;gt;&amp;gt;&amp;gt; f(x)/(c*g(x)) = 256x(1-x)^3

#This code keeps looping until U2 (which is f(x)/c*g(x)) dips below its bound. Hence it rejects higher values

n &amp;lt;- 1
rejects &amp;lt;- 0
while(n == 1){
  U1 &amp;lt;- runif(1)
  U2 &amp;lt;- runif(1)
  rejects &amp;lt;- rejects + 1
  if(U2 &amp;lt;= 256/27*U1*(1-U1)^3){
    X &amp;lt;- U1
    n &amp;lt;- 0
  }
}

print(paste(&amp;#39;Total Number of Rejections:&amp;#39;, rejects))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Total Number of Rejections: 3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;Beta RV:&amp;#39;, X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Beta RV: 0.0656281118281186&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Beta:&amp;#39;, rbeta(1,2,4, ncp = 0)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Beta: 0.281731495984851&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(i,n,p,P,r,U,X, rejects)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Transformations of Uniform Distribution to other distrubtions

set.seed(123)
#Inverse Transformation to Exponential
#F(x) = 1 - e^-x
#X = F-1(U) = - ln(1-U) &amp;gt;&amp;gt;&amp;gt; - ln(U)

lambda &amp;lt;- 1
U &amp;lt;- runif(1)
X &amp;lt;- (-1/lambda)*log(U)
print(paste(&amp;#39;Exponential RV:&amp;#39;,X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Exponential RV: 1.24626281987372&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Exponential RV:&amp;#39;,rexp(1,lambda)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Exponential RV: 0.576610270887613&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Using sums to create Gamma(n,lambda) from exp(lambda) Gamma(n,lambda) = sum_n(Exponential(lambda))
n &amp;lt;- 20
X &amp;lt;- (-1/lambda)*sum(log(U))
print(paste(&amp;#39;Gamma RV:&amp;#39;,X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Gamma RV: 1.24626281987372&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Gamma RV:&amp;#39;, rgamma(1,n,lambda)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Gamma RV: 18.4968091472022&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(n,lambda,X)

#Create Poisson Distribution which is the number of exponential arrivals in a given time period
#Ti = 1/lambdaln(Ui)

set.seed(123)

lambda &amp;lt;- 2
i &amp;lt;- 0
U &amp;lt;- runif(1)
Y &amp;lt;- -1/lambda*log(U)
sum &amp;lt;- Y
while(sum &amp;lt; 1){
  U &amp;lt;- runif(1)
  Y &amp;lt;- -1/lambda*log(U)
  sum &amp;lt;- sum + Y
  i &amp;lt;- i+1
}
X &amp;lt;- i
print(paste(&amp;#39;Poisson RV:&amp;#39;,X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Poisson RV: 2&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Poisson RV:&amp;#39;, rpois(1,lambda)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Poisson RV: 4&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Creating Normals with the Box Mueller Method (inefficient because of the sqrt, cos, and sine functions)
#Z1 = sqrt(-2ln(U1)cos(2*pi*U2))
#Z2 = sqrt(-2ln(U1)sin(2*pi*U2))

n &amp;lt;- 5000
U1 &amp;lt;- runif(n)
U2 &amp;lt;- runif(n)

Z1 &amp;lt;- sqrt(-2*log(U1))*cos(2*pi*U2)
Z2 &amp;lt;- sqrt(-2*log(U1))*sin(2*pi*U2)

#Created Via R Function
Z3 &amp;lt;- rnorm(5000)
hist(Z1,col = &amp;#39;wheat&amp;#39;, label = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(Z3,col = &amp;#39;wheat&amp;#39;, label = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Geometric Function - Loops Bernoulis until first success
# K &amp;lt;- number of failures plust 1 success 

K &amp;lt;- 1
p &amp;lt;- 0.2

while(runif(1) &amp;gt; p){
  K &amp;lt;- K +1
}
print(paste(&amp;#39;Geometric RV:&amp;#39;, K))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Geometric RV: 8&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Geometric RV:&amp;#39;,rgeom(1,p)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Geometric RV: 1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Negative Binomial Method - Number of Geometric trials needed to get r success NegBin(1,r,p)

K &amp;lt;- 1
p &amp;lt;- 0.2
r &amp;lt;- 2
success &amp;lt;- 0

while(success &amp;lt; r){
  if(runif(1) &amp;gt; p){
    K &amp;lt;- K + 1
    #failure
  }else{
    success &amp;lt;- success + 1
  }
}

print(paste(&amp;#39;Negative Binomial RV:&amp;#39;, K+r-1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Negative Binomial RV: 6&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Negative Binomial:&amp;#39;, rnbinom(1,r,p)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Negative Binomial: 6&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rt(1,1,1) #number of variables, df, ncp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.06314223&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Typical metrics for Queueing that can be extended to all types of simulations:&lt;/p&gt;
&lt;p&gt;• L: average number of jobs in the system
• W: average time spent in the system (cycle time)
• Q: average number of jobs in queue
• d: average time in queue
• system utilization
• system throughput
• distribution of waiting time
• distribution of system size
• distribution of queue size&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#M/M/1 Queue Simulation

#Source for this code http://web02.gonzaga.edu/faculty/burchn/R_files/Miscellaneous/queueing_theory_MM1.html

#variable saying how many arrivals per time period
lambda = .3
#saying the average departures per time period
mu = 1
#How long the simulation runs note not a number of events
time = 500
t = 0
#the length of a queue after a number of events. Aka Q_history[500] = 5 says the queue is 5 people long after 500 events it isn&amp;#39;t a sum.
#It updates after for n during event n
Q_hist = 0
#Think this is the sum of all the queues 
s = 0
#exponential distb with mean 1/rate T1 is time uuntil next event rate lamba + mu if there is something in queue otherwise just an arrival
T1 = rexp(1,rate=lambda)
#Initializing parameter
Q = 1
#Time until first event is T1
event_times = T1
#The time of the first event is T1
t = T1
#Same reasoning
num_event = 1

i &amp;lt;- 1
sims &amp;lt;- 10
#Busy time simulation 1:10
B &amp;lt;- c(1:10)
BT &amp;lt;- c(1:10)
#Average length of queue for simulation 1:10
L &amp;lt;- c(1:10)
#Average time customer spends in line
W &amp;lt;- c(1:10)

while (i &amp;lt;= sims){
  print(i)
  while (t&amp;lt;time) {
  num_event = num_event+1
  if(Q&amp;gt;0) {
    # we checked to make sure queue was not empty
    #odds someone arrives or leaves the queue
    T1 = rexp(1,rate=lambda+mu)
    #use p as random number to determine if next even is an arrival or a departure
    p = runif(1,0,1)
    Q_hist[num_event] = Q
    #if p is less than lambda/(lamda+mu) it is an arrival otherwise it is a departure
    Q = ifelse(p&amp;lt;lambda/(lambda+mu),Q+1,Q-1)
    } else {
      # here, the queue was empty, so only arrivals are possible
      T1 = rexp(1,rate=lambda)
      Q_hist[num_event] = Q
      Q = 1
          }
  #new time is the original t plus the time to the next event
  t = t+T1
  #A vector that shows how long it is to the next event
  event_times[num_event] = T1
  s = s+T1*Q_hist[num_event]
  }
#Time system is busy
BT[i] &amp;lt;- sum(event_times)-sum(event_times[which(Q_hist %in% 0)])
num_cust &amp;lt;- lambda*time
B[i] &amp;lt;- BT[i]/length(which(Q_hist %in% 0))

#Average queue length in the system
L[i] &amp;lt;- s/t

#Average time customer spends in line
W[i] &amp;lt;- L[i] / lambda

time = 500
t = 0
Q_hist = 0
s = 0
T1 = rexp(1,rate=lambda)
Q = 1
event_times = T1
t = T1
num_event = 1

i &amp;lt;- i + 1
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1
## [1] 2
## [1] 3
## [1] 4
## [1] 5
## [1] 6
## [1] 7
## [1] 8
## [1] 9
## [1] 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#rho/(1-rho) [.4285, 9, -11]
avg_num &amp;lt;- mean(L) 

#rho/(1-rho)^2 [.6122, 90, 110]
variance &amp;lt;- var(L) 

Sd2 &amp;lt;- sum((L-avg_num)^2 / (sims - 1))

# 1/(mu-lambda) [1.42, 10, -10]
busy_time &amp;lt;- mean(B)

avg_num&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4417826&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;variance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.003876663&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Sd2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.003876663&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;busy_time&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.452299&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A quick Monte Carlo Simulation to estimate the value of the integral &lt;span class=&#34;math inline&#34;&gt;\(\int_{0.01}^1x^{-0.5}\,dx\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;#&lt;a href=&#34;https://stackoverflow.com/questions/22001977/monte-carlo-integration-in-r-getting-the-wrong-answer-using-hit-or-miss&#34; class=&#34;uri&#34;&gt;https://stackoverflow.com/questions/22001977/monte-carlo-integration-in-r-getting-the-wrong-answer-using-hit-or-miss&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s &amp;lt;- NULL

m &amp;lt;- 1000
a &amp;lt;- 0.01
b &amp;lt;- 1
set.seed(5)
x &amp;lt;- runif(m,a,b)
y &amp;lt;- 10*runif(m,0,1)

for (i in 1:m){
    if(y[i]&amp;lt;(x[i]^(-0.5))){
        s[i] &amp;lt;- 1
    }
    else{
        s[i] &amp;lt;-0
    }
}

nn&amp;lt;- sum(s)*(b-a)/m*10 #note that the addition of the area of the rectangle
print(nn)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.683&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(x,y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f2 &amp;lt;- function(x)   sqrt(1-x^2)

s &amp;lt;- seq(-1 , 1 ,by=0.001)
plot(s,f2(s))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get the max value of function within the range
c &amp;lt;- ceiling(max(f2(s)))
# [1] 1

n &amp;lt;- 1000000
a &amp;lt;- -1
b &amp;lt;- 1

set.seed(5)
x &amp;lt;- runif(n,a,b)
y &amp;lt;- c*runif(n,0,1)
R &amp;lt;- sum(y &amp;lt; f2(x))/n

(b-a)*c*R&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.57063&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#[1] 1.57063 # multiply it by 2 to get full area

pi/2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.570796&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#[1] 1.570796&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sim HW2 does a good job showing confidence intervals and convergence of normals, exponentials, and lognormals.&lt;/p&gt;
&lt;p&gt;Sim HW4 shows how to run 5 tests for independance (Runs, Autocorrelation), uniformity (Chi-Squared and KS), or both (Serial)&lt;/p&gt;
&lt;p&gt;Sim HW5 shows how to generate RVs recurseively until they drop below a certain variance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#CLT Basics https://stats.stackexchange.com/questions/22557/central-limit-theorem-versus-law-of-large-numbers
#https://www.probabilitycourse.com/chapter7/7_2_4_convergence_in_distribution.php
#https://www.analyticsvidhya.com/blog/2019/05/statistics-101-introduction-central-limit-theorem/

#LLN (WLLN - convergence in prob) (SLLN - almost sure convergence) (CLT - convergence in distribution)
#WLLN https://www.probabilitycourse.com/chapter7/7_2_5_convergence_in_probability.php
#SLLN and continous mapping theroem https://www.probabilitycourse.com/chapter7/7_2_7_almost_sure_convergence.php

#Probability Basics
#https://daviddalpiaz.github.io/r4sl/probability-review.html&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Statistic Basics and Linear Regression</title>
      <link>/post/orie/stat_basics/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/orie/stat_basics/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post explores some of the basic concepts of statistics.
I mostly explore these concepts using linear regression.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#http://r-statistics.co/Linear-Regression.html
#https://www.statmethods.net/stats/regression.html
#http://r-statistics.co/Statistical-Tests-in-R.html
#http://www.sthda.com/english/articles/40-regression-analysis/166-predict-in-r-model-predictions-and-confidence-intervals/


#Dr. Sager Utexas datasets

data &amp;lt;- read.table(&amp;#39;AustinApartmentRents1.txt&amp;#39;, header = TRUE)
summary(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Rent             Area     
##  Min.   : 399.0   Min.   : 474  
##  1st Qu.: 470.0   1st Qu.: 666  
##  Median : 535.0   Median : 755  
##  Mean   : 572.3   Mean   : 816  
##  3rd Qu.: 638.8   3rd Qu.: 925  
##  Max.   :1050.0   Max.   :1864&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(data$Rent, data$Area)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8740597&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- lm(Rent ~ Area, data = data)

summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Rent ~ Area, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -154.659  -50.882    8.189   54.874  148.207 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 160.18706   31.36081   5.108  3.8e-06 ***
## Area          0.50497    0.03685  13.702  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 68.86 on 58 degrees of freedom
## Multiple R-squared:  0.764,  Adjusted R-squared:  0.7599 
## F-statistic: 187.7 on 1 and 58 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test.Areas &amp;lt;- data.frame(Area = c (500,1000))
predict(model, newdata = test.Areas)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2 
## 412.6713 665.1556&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data1 &amp;lt;- read.table(&amp;#39;AustinApartmentRents2.txt&amp;#39;, header = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#A convient tool to see a lot of the initial data exploration
#https://towardsdatascience.com/simple-fast-exploratory-data-analysis-in-r-with-dataexplorer-package-e055348d9619

library(DataExplorer)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;DataExplorer&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_str(data1)
plot_missing(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_histogram(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_density(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_correlation(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_bar(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create_report(data1) #This creates an HTML report of all the above information and more&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Confidence intervals around indivudual values
pred.int &amp;lt;- predict(model, interval = &amp;#39;prediction&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in predict.lm(model, interval = &amp;quot;prediction&amp;quot;): predictions on current data refer to _future_ responses&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Confidence intervals around means
pred.conf &amp;lt;- predict(model, interval = &amp;#39;confidence&amp;#39;)

cbind(data,pred.int,pred.conf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Rent Area       fit      lwr       upr       fit       lwr       upr
## 1   519  725  526.2893 387.1539  665.4247  526.2893  507.2700  545.3085
## 2   765  995  662.6308 523.0320  802.2296  662.6308  640.4747  684.7868
## 3   475  481  403.0769 261.9228  544.2310  403.0769  372.6213  433.5326
## 4   575  925  627.2830 488.0776  766.4884  627.2830  607.7583  646.8077
## 5   415  600  463.1682 323.2840  603.0524  463.1682  439.2801  487.0563
## 6   530  668  497.5061 358.1044  636.9078  497.5061  476.6278  518.3843
## 7   580  725  526.2893 387.1539  665.4247  526.2893  507.2700  545.3085
## 8   995 1421  877.7474 731.7844 1023.7104  877.7474  829.7031  925.7917
## 9   565  672  499.5259 360.1470  638.9048  499.5259  478.8005  520.2514
## 10  620 1025  677.7799 537.9544  817.6053  677.7799  654.2379  701.3218
## 11  450  781  554.5675 415.5703  693.5648  554.5675  536.5869  572.5481
## 12  520  800  564.1619 425.1837  703.1402  564.1619  546.3289  581.9950
## 13  495  870  599.5097 460.4795  738.5399  599.5097  581.2764  617.7431
## 14  420  700  513.6651 374.4284  652.9017  513.6651  493.9190  533.4112
## 15  575  800  564.1619 425.1837  703.1402  564.1619  546.3289  581.9950
## 16  425  620  473.2676 333.5438  612.9913  473.2676  450.3375  496.1977
## 17  770 1040  685.3544 545.4026  825.3061  685.3544  661.0735  709.6352
## 18  445  520  422.7707 282.0919  563.4495  422.7707  394.5998  450.9416
## 19  510  880  604.5594 465.5062  743.6127  604.5594  586.1509  622.9679
## 20  635  832  580.3209 441.3427  719.2991  580.3209  562.4884  598.1535
## 21  470  545  435.3949 294.9906  575.7993  435.3949  408.6285  462.1614
## 22  700  921  625.2631 486.0744  764.4518  625.2631  605.8580  644.6682
## 23  450  577  451.5539 311.4663  591.6416  451.5539  426.5018  476.6060
## 24  785 1080  705.5531 565.2224  845.8838  705.5531  679.1757  731.9306
## 25  485  710  518.7147 379.5215  657.9080  518.7147  499.2771  538.1524
## 26  415  605  465.6930 325.8504  605.5357  465.6930  442.0494  489.3367
## 27  399  680  503.5657 364.2305  642.9008  503.5657  483.1366  523.9948
## 28  585  730  528.8141 389.6960  667.9322  528.8141  509.9220  547.7063
## 29  525  687  507.1005 367.8016  646.3994  507.1005  486.9201  527.2809
## 30  495  703  515.1800 375.9568  654.4032  515.1800  495.5288  534.8311
## 31  505  672  499.5259 360.1470  638.9048  499.5259  478.8005  520.2514
## 32  445  660  493.4663 354.0171  632.9155  493.4663  472.2734  514.6593
## 33  565  755  541.4383 402.3922  680.4845  541.4383  523.0835  559.7931
## 34  650  810  569.2116 430.2377  708.1855  569.2116  551.4123  587.0109
## 35  515  611  468.7229 328.9288  608.5169  468.7229  445.3683  492.0774
## 36  470  705  516.1899 376.9755  655.4044  516.1899  496.6009  535.7789
## 37  470  564  444.9893 304.7778  585.2009  444.9893  419.2531  470.7255
## 38  700 1250  791.3978 648.7851  934.0105  791.3978  754.7720  828.0235
## 39  455  512  418.7310 277.9593  559.5026  418.7310  390.1001  447.3618
## 40  550  630  478.3173 338.6680  617.9666  478.3173  455.8452  500.7893
## 41  625  850  589.4103 450.4146  728.4061  589.4103  571.4413  607.3794
## 42  745 1156  743.9307 602.7129  885.1486  743.9307  713.1810  774.6805
## 43  540  932  630.8178 491.5816  770.0540  630.8178  611.0749  650.5607
## 44  650  755  541.4383 402.3922  680.4845  541.4383  523.0835  559.7931
## 45  595 1093  712.1177 571.6507  852.5847  712.1177  685.0246  739.2108
## 46  470  751  539.4185 400.3624  678.4745  539.4185  520.9890  557.8479
## 47  480  608  467.2080 327.3898  607.0261  467.2080  443.7095  490.7064
## 48  460  900  614.6588 475.5477  753.7699  614.6588  595.8181  633.4994
## 49  600  860  594.4600 455.4490  733.4711  594.4600  576.3734  612.5467
## 50  575  925  627.2830 488.0776  766.4884  627.2830  607.7583  646.8077
## 51  659  944  636.8774 497.5840  776.1708  636.8774  616.7351  657.0197
## 52  650  940  634.8575 495.5838  774.1312  634.8575  614.8518  654.8632
## 53  750 1048  689.3941 549.3715  829.4168  689.3941  664.7079  714.0803
## 54  455  474  399.5422 258.2967  540.7876  399.5422  368.6660  430.4184
## 55  430  700  513.6651 374.4284  652.9017  513.6651  493.9190  533.4112
## 56  605  921  625.2631 486.0744  764.4518  625.2631  605.8580  644.6682
## 57  929 1229  780.7934 638.5205  923.0664  780.7934  745.5138  816.0731
## 58  695  896  612.6389 473.5406  751.7372  612.6389  593.8932  631.3846
## 59  455  630  478.3173 338.6680  617.9666  478.3173  455.8452  500.7893
## 60 1050 1864 1101.4485 942.4198 1260.4772 1101.4485 1022.1188 1180.7782&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 2. Regression line + confidence intervals
library(&amp;quot;ggplot2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;ggplot2&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mydata &amp;lt;- cbind(data, pred.int)
p &amp;lt;- ggplot(mydata, aes(Area, Rent)) +
  geom_point() +
  stat_smooth(method = lm)
# 3. Add prediction intervals
p + geom_line(aes(y = lwr), color = &amp;quot;red&amp;quot;, linetype = &amp;quot;dashed&amp;quot;)+
    geom_line(aes(y = upr), color = &amp;quot;red&amp;quot;, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#T Test for samples
library(dplyr)

sample1 &amp;lt;- sample_n(data,40)

model1 &amp;lt;- lm(Rent ~ Area, data = data)

p1 &amp;lt;- predict(model1, interval = &amp;#39;confidence&amp;#39;, level = 0.95)

summary(p1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       fit              lwr              upr        
##  Min.   : 399.5   Min.   : 368.7   Min.   : 430.4  
##  1st Qu.: 496.5   1st Qu.: 475.5   1st Qu.: 517.5  
##  Median : 541.4   Median : 523.1   Median : 559.8  
##  Mean   : 572.3   Mean   : 548.8   Mean   : 595.7  
##  3rd Qu.: 627.3   3rd Qu.: 607.8   3rd Qu.: 646.8  
##  Max.   :1101.4   Max.   :1022.1   Max.   :1180.8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(p1, mu = 550)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  One Sample t-test
## 
## data:  p1
## t = 2.4118, df = 179, p-value = 0.01688
## alternative hypothesis: true mean is not equal to 550
## 95 percent confidence interval:
##  554.0485 590.4849
## sample estimates:
## mean of x 
##  572.2667&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#MultiVariable Linear Regression


summary(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Rent             Area         Bedrooms       Bathrooms   
##  Min.   : 399.0   Min.   : 474   Min.   :1.000   Min.   :1.00  
##  1st Qu.: 470.0   1st Qu.: 666   1st Qu.:1.000   1st Qu.:1.00  
##  Median : 535.0   Median : 755   Median :1.000   Median :1.00  
##  Mean   : 572.3   Mean   : 816   Mean   :1.517   Mean   :1.25  
##  3rd Qu.: 638.8   3rd Qu.: 925   3rd Qu.:2.000   3rd Qu.:1.25  
##  Max.   :1050.0   Max.   :1864   Max.   :5.000   Max.   :2.00  
##     Security         Parking          Distance         Shuttle      
##  Min.   :0.0000   Min.   :0.0000   Min.   : 1.100   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 5.000   1st Qu.:1.0000  
##  Median :0.0000   Median :0.0000   Median : 6.000   Median :1.0000  
##  Mean   :0.1667   Mean   :0.1333   Mean   : 5.935   Mean   :0.8667  
##  3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.: 7.000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :10.500   Max.   :1.0000  
##       Age       
##  Min.   : 1.00  
##  1st Qu.:10.00  
##  Median :16.50  
##  Mean   :16.33  
##  3rd Qu.:22.25  
##  Max.   :32.00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model2 &amp;lt;- lm(Rent ~ Area + Bathrooms, data = data1)
summary(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Rent ~ Area + Bathrooms, data = data1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -152.02  -45.45   10.38   39.91  129.28 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 143.66927   29.51345   4.868 9.31e-06 ***
## Area          0.38746    0.04982   7.777 1.61e-10 ***
## Bathrooms    89.92902   27.75071   3.241  0.00199 ** 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 63.83 on 57 degrees of freedom
## Multiple R-squared:  0.8007, Adjusted R-squared:  0.7937 
## F-statistic: 114.5 on 2 and 57 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test.bathrooms &amp;lt;- data.frame(Area = c(500,1000), Bathrooms = c(1,2))

p2a &amp;lt;- predict(model2, newdata = test.bathrooms, interval =  &amp;#39;confidence&amp;#39;)


p2 &amp;lt;- as.data.frame(predict(model2, interval = &amp;#39;confidence&amp;#39;, level = 0.95))

cbind(p2, data1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          fit      lwr       upr Rent Area Bedrooms Bathrooms Security Parking
## 1   514.5062 495.4259  533.5866  519  725        1         1        0       0
## 2   709.0493 673.7669  744.3316  765  995        2         2        0       0
## 3   419.9662 389.8581  450.0743  475  481        1         1        0       0
## 4   681.9271 643.6132  720.2411  575  925        2         2        0       1
## 5   466.0738 443.8498  488.2979  415  600        1         1        0       0
## 6   492.4211 472.8074  512.0348  530  668        1         1        0       0
## 7   514.5062 495.4259  533.5866  580  725        1         1        0       0
## 8   874.1069 829.4987  918.7151  995 1421        2         2        0       1
## 9   493.9709 474.4481  513.4937  565  672        1         1        0       0
## 10  630.7440 594.3939  667.0941  620 1025        2         1        1       0
## 11  536.2040 516.0356  556.3724  450  781        1         1        1       0
## 12  543.5657 522.6986  564.4328  520  800        2         1        0       0
## 13  570.6878 546.1304  595.2452  495  870        2         1        0       0
## 14  504.8198 485.7109  523.9287  420  700        1         1        0       0
## 15  543.5657 522.6986  564.4328  575  800        1         1        0       0
## 16  473.8230 452.5572  495.0888  425  620        1         1        0       0
## 17  726.4849 692.5303  760.4395  770 1040        2         2        0       1
## 18  435.0771 407.8700  462.2843  445  520        1         1        0       0
## 19  574.5624 549.3637  599.7611  510  880        2         1        0       1
## 20  555.9644 533.6045  578.3243  635  832        1         1        0       0
## 21  444.7636 419.2769  470.2502  470  545        1         1        0       0
## 22  680.3773 641.8590  718.8955  700  921        2         2        0       0
## 23  457.1623 433.6744  480.6501  450  577        1         1        0       0
## 24  741.9833 708.7412  775.2254  785 1080        2         2        0       0
## 25  508.6944 489.6360  527.7527  485  710        1         1        0       0
## 26  468.0111 446.0397  489.9826  415  605        1         1        0       0
## 27  497.0706 477.7062  516.4349  399  680        1         1        0       1
## 28  516.4435 497.3298  535.5573  585  730        2         1        0       0
## 29  499.7828 480.5310  519.0346  525  687        1         1        0       0
## 30  505.9821 486.8939  525.0704  495  703        1         1        0       0
## 31  493.9709 474.4481  513.4937  505  672        1         1        1       0
## 32  489.3214 469.5030  509.1398  445  660        1         1        0       0
## 33  526.1300 506.6576  545.6024  565  755        2         1        0       0
## 34  547.4403 526.1468  568.7337  650  810        2         1        0       0
## 35  470.3359 448.6563  492.0154  515  611        1         1        0       0
## 36  506.7571 487.6799  525.8342  470  705        1         1        0       0
## 37  452.1253 427.8562  476.3944  470  564        1         1        0       0
## 38  807.8514 772.3992  843.3035  700 1250        3         2        0       1
## 39  431.9774 404.1949  459.7599  455  512        1         1        1       0
## 40  477.6976 456.8558  498.5395  550  630        1         1        0       0
## 41  562.9387 539.5887  586.2886  625  850        2         1        1       0
## 42  771.4302 738.2367  804.6237  745 1156        3         2        0       0
## 43  594.7103 565.8488  623.5718  540  932        2         1        0       0
## 44  526.1300 506.6576  545.6024  650  755        1         1        1       1
## 45  747.0203 713.9093  780.1312  595 1093        2         2        1       0
## 46  524.5802 505.1862  543.9741  470  751        1         1        1       0
## 47  469.1735 447.3496  490.9974  480  608        1         1        0       0
## 48  582.3116 555.7642  608.8590  460  900        1         1        0       1
## 49  566.8132 542.8728  590.7537  600  860        2         1        0       0
## 50  591.9981 563.6574  620.3388  575  925        2         1        0       0
## 51  689.2888 651.9023  726.6754  659  944        2         2        0       0
## 52  687.7390 650.1632  725.3148  650  940        2         2        0       0
## 53  729.5846 695.8090  763.3602  750 1048        2         2        0       0
## 54  417.2540 386.6020  447.9060  455  474        1         1        0       0
## 55  504.8198 485.7109  523.9287  430  700        1         1        0       0
## 56  590.4483 562.4017  618.4949  605  921        1         1        0       0
## 57  799.7147 764.9734  834.4561  929 1229        2         2        1       0
## 58  670.6908 630.8290  710.5526  695  896        2         2        0       0
## 59  477.6976 456.8558  498.5395  455  630        1         1        1       0
## 60 1045.7513 964.5360 1126.9667 1050 1864        5         2        0       0
##    Distance Shuttle Age
## 1      10.5       1   9
## 2       6.5       1  17
## 3       6.5       1  17
## 4       4.0       1   9
## 5       5.0       1  30
## 6       6.5       1  19
## 7       7.0       1  17
## 8       6.5       1  16
## 9       7.0       1  17
## 10      5.0       1   3
## 11      5.5       1   3
## 12      6.0       1  20
## 13      5.0       1  27
## 14      6.0       1  22
## 15      7.0       1  10
## 16      8.0       0  27
## 17      6.5       1  16
## 18      3.0       1  12
## 19      7.0       0  25
## 20      6.0       1  13
## 21      6.5       1   9
## 22      3.0       1  26
## 23      8.0       1  18
## 24      5.0       1  10
## 25      6.0       1  25
## 26      6.0       1  22
## 27      7.0       0  25
## 28      6.5       1  19
## 29      7.0       1  15
## 30      6.5       1  14
## 31      6.5       1   9
## 32      6.0       1  25
## 33      3.0       1  12
## 34      2.0       1  32
## 35      6.5       1  17
## 36      7.5       0  13
## 37      5.0       1  10
## 38      4.0       1   9
## 39     10.0       0  10
## 40      2.0       1  32
## 41      7.0       1   1
## 42      7.5       0  13
## 43      6.0       1  22
## 44      1.1       1  26
## 45      5.5       1   3
## 46      5.0       1   3
## 47      6.0       1  15
## 48      4.0       1   9
## 49      6.0       1  25
## 50      6.0       1  23
## 51      7.0       1  25
## 52      8.0       0  27
## 53      7.0       1   3
## 54      5.0       1  10
## 55      6.0       1  20
## 56      7.5       0  13
## 57      5.0       1  11
## 58      6.5       1  19
## 59      5.5       1   9
## 60      6.0       1  22&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        fit      lwr      upr
## 1 427.3279 398.6624 455.9935
## 2 710.9866 675.8776 746.0955&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model3 &amp;lt;- lm(Rent ~ Area + Bathrooms + Security + Parking + Distance, data = data1)
summary(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Rent ~ Area + Bathrooms + Security + Parking + Distance, 
##     data = data1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -163.199  -37.278    4.548   38.345  149.276 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 167.45045   43.12346   3.883 0.000283 ***
## Area          0.39647    0.05084   7.798 2.09e-10 ***
## Bathrooms    92.60040   28.01804   3.305 0.001691 ** 
## Security     -0.67875   22.42818  -0.030 0.975969    
## Parking     -38.26531   25.89638  -1.478 0.145316    
## Distance     -4.92937    5.05014  -0.976 0.333374    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 64.02 on 54 degrees of freedom
## Multiple R-squared:   0.81,  Adjusted R-squared:  0.7925 
## F-statistic: 46.06 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model4 &amp;lt;- lm(Rent ~ Distance + Parking + Security + Bathrooms + Area, data = data1)
summary(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Rent ~ Distance + Parking + Security + Bathrooms + 
##     Area, data = data1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -163.199  -37.278    4.548   38.345  149.276 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 167.45045   43.12346   3.883 0.000283 ***
## Distance     -4.92937    5.05014  -0.976 0.333374    
## Parking     -38.26531   25.89638  -1.478 0.145316    
## Security     -0.67875   22.42818  -0.030 0.975969    
## Bathrooms    92.60040   28.01804   3.305 0.001691 ** 
## Area          0.39647    0.05084   7.798 2.09e-10 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 64.02 on 54 degrees of freedom
## Multiple R-squared:   0.81,  Adjusted R-squared:  0.7925 
## F-statistic: 46.06 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Multicollinearity
#http://www.sthda.com/english/articles/39-regression-model-diagnostics/160-multicollinearity-essentials-and-vif-in-r/
library(caret)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;caret&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)

y &amp;lt;- runif(50,min=0, max =100)
x1 &amp;lt;- runif(50, min = 0, max = 100)
x2 &amp;lt;- runif(50, min = 0, max = 100)
z1 &amp;lt;- x1+x2
z2 &amp;lt;- x1 + x2 + 0.005*runif(50,min=0, max =100)



list &amp;lt;- cbind(y,x1,x2,z1,z2)
list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                y        x1        x2        z1        z2
##  [1,] 11.3703411  7.377988  3.545673  10.92366  11.14318
##  [2,] 62.2299405 30.968660 56.507611  87.47627  87.59057
##  [3,] 60.9274733 71.727174 28.025778  99.75295  99.79403
##  [4,] 62.3379442 50.454591 20.419632  70.87422  71.29936
##  [5,] 86.0915384 15.299896 13.373890  28.67379  28.79112
##  [6,] 64.0310605 50.393349 32.568192  82.96154  83.45562
##  [7,]  0.9495756 49.396092 15.506197  64.90229  65.20324
##  [8,] 23.2550506 75.120020 12.996214  88.11623  88.61560
##  [9,] 66.6083758 17.464982 43.553106  61.01809  61.20589
## [10,] 51.4251141 84.839241  3.864265  88.70351  88.98107
## [11,] 69.3591292 86.483383 71.330156 157.81354 158.02826
## [12,] 54.4974836  4.185728 10.076904  14.26263  14.55057
## [13,] 28.2733584 31.718216 95.030494 126.74871 126.96496
## [14,] 92.3433484  1.374994 12.181776  13.55677  13.66919
## [15,] 29.2315840 23.902573 21.965662  45.86823  45.91073
## [16,] 83.7295628 70.649462 91.308777 161.95824 162.27689
## [17,] 28.6223285 30.809476 94.585312 125.39479 125.61030
## [18,] 26.6820780 50.854757 27.915622  78.77038  78.80674
## [19,] 18.6722790  5.164662 12.347109  17.51177  17.91297
## [20,] 23.2225911 56.456984 79.716046 136.17303 136.33567
## [21,] 31.6612455 12.148019 74.427722  86.57574  86.95438
## [22,] 30.2693371 89.283638 91.597422 180.88106 181.17320
## [23,] 15.9046003  1.462726 99.459825 100.92255 101.27697
## [24,]  3.9995918 78.312110 94.236072 172.54818 172.76167
## [25,] 21.8799541  8.996133 48.613541  57.60967  57.78146
## [26,] 81.0598552 51.918998 28.345954  80.26495  80.64451
## [27,] 52.5697547 38.426669 25.154570  63.58124  63.79325
## [28,] 91.4658166  7.005250 50.325517  57.33077  57.61121
## [29,] 83.1345047 32.064442 49.696617  81.76106  81.81913
## [30,]  4.5770263 66.849540 31.844581  98.69412  98.84563
## [31,] 45.6091482 92.640048 96.222283 188.86233 189.10173
## [32,] 26.5186672 47.190972 63.409937 110.60091 110.77332
## [33,] 30.4672203 14.261534 12.743340  27.00487  27.30523
## [34,] 50.7306870 54.426976 42.304699  96.73167  96.76972
## [35,] 18.1096208 19.617465 91.431691 111.04916 111.52715
## [36,] 75.9670635 89.858049 46.779233 136.63728 136.64839
## [37,] 20.1248038 38.949978 90.816915 129.76689 130.18775
## [38,] 25.8809819 31.087078 59.774328  90.86141  91.17763
## [39,] 99.2150418 16.002866 63.174282  79.17715  79.33219
## [40,] 80.7352340 89.618585 86.915832 176.53442 176.90570
## [41,] 55.3333591 16.639378 50.274982  66.91436  67.23382
## [42,] 64.6406094 90.042460 98.363511 188.40597 188.90223
## [43,] 31.1824307 13.407820 32.438603  45.84642  45.91056
## [44,] 62.1819198 13.161413 48.137495  61.29891  61.74053
## [45,] 32.9770176 10.528750 35.698708  46.22746  46.63250
## [46,] 50.1997473 51.158358 62.747768 113.90613 114.31705
## [47,] 67.7094527 30.019905 74.160019 104.17992 104.59728
## [48,] 48.4991239  2.671690 56.596682  59.26837  59.63474
## [49,] 24.3928827 30.964743 98.078651 129.04339 129.53492
## [50,] 76.5459788 74.211966 57.681274 131.89324 132.21284&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(list)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                y         x1          x2            z1            z2
## y   1.0000000000 0.07758827 -0.07522322 -0.0005374415 -0.0008533985
## x1  0.0775882672 1.00000000  0.25313221  0.7815275201  0.7811302343
## x2 -0.0752232228 0.25313221  1.00000000  0.8013821453  0.8017562132
## z1 -0.0005374415 0.78152752  0.80138215  1.0000000000  0.9999955888
## z2 -0.0008533985 0.78113023  0.80175621  0.9999955888  1.0000000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#model catches exact multicollinearity easily
mcmodel1 &amp;lt;- lm(y ~ x1+x2+z1+z2)
summary(mcmodel1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x1 + x2 + z1 + z2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -48.767 -21.484  -2.126  19.999  53.375 
## 
## Coefficients: (1 not defined because of singularities)
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)    51.22      10.53   4.865 1.38e-05 ***
## x1             15.81      28.05   0.563    0.576    
## x2             15.65      28.09   0.557    0.580    
## z1                NA         NA      NA       NA    
## z2            -15.72      28.06  -0.560    0.578    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 26.93 on 46 degrees of freedom
## Multiple R-squared:  0.0223, Adjusted R-squared:  -0.04146 
## F-statistic: 0.3498 on 3 and 46 DF,  p-value: 0.7895&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#has a harder time catching near multicollinearity useful to use VIF or tolerance
mcmodel2 &amp;lt;- lm(y ~ x1+x2+z2)
summary(mcmodel2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x1 + x2 + z2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -48.767 -21.484  -2.126  19.999  53.375 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)    51.22      10.53   4.865 1.38e-05 ***
## x1             15.81      28.05   0.563    0.576    
## x2             15.65      28.09   0.557    0.580    
## z2            -15.72      28.06  -0.560    0.578    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 26.93 on 46 degrees of freedom
## Multiple R-squared:  0.0223, Adjusted R-squared:  -0.04146 
## F-statistic: 0.3498 on 3 and 46 DF,  p-value: 0.7895&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;car::vif(mcmodel2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        x1        x2        z2 
##  45305.13  49446.24 118711.40&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Can drop the collinear term
mcmodel3 &amp;lt;- lm(y ~ x1+x2)
summary(mcmodel3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -50.044 -19.925  -0.354  19.215  55.525 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 47.74591    8.44508   5.654 8.96e-07 ***
## x1           0.09332    0.13522   0.690    0.493    
## x2          -0.08784    0.12964  -0.678    0.501    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 26.73 on 47 degrees of freedom
## Multiple R-squared:  0.01564,    Adjusted R-squared:  -0.02625 
## F-statistic: 0.3733 on 2 and 47 DF,  p-value: 0.6905&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;car::vif(mcmodel3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       x1       x2 
## 1.068463 1.068463&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Or drop the other one
mcmodel4 &amp;lt;- lm(y ~ x1+z2)
summary(mcmodel4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x1 + z2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -50.050 -19.928  -0.363  19.217  55.519 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 47.77939    8.46296   5.646 9.21e-07 ***
## x1           0.18145    0.20950   0.866    0.391    
## z2          -0.08807    0.12948  -0.680    0.500    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 26.73 on 47 degrees of freedom
## Multiple R-squared:  0.01571,    Adjusted R-squared:  -0.02618 
## F-statistic: 0.3751 on 2 and 47 DF,  p-value: 0.6893&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;car::vif(mcmodel4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       x1       z2 
## 2.565184 2.565184&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#normality check
#https://www.statmethods.net/stats/regression.html


nmodel &amp;lt;- summary(model2)
nmodel$residuals&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6 
##    4.493754   55.950733   55.033809 -106.927120  -51.073841   37.578930 
##           7           8           9          10          11          12 
##   65.493754  120.893095   71.029094  -10.744020  -86.203964  -23.565690 
##          13          14          15          16          17          18 
##  -75.687837  -84.819765   31.434310  -48.823026   43.515067    9.922899 
##          19          20          21          22          23          24 
##  -64.562429   79.035614   25.236418   19.622717   -7.162278   43.016698 
##          25          26          27          28          29          30 
##  -23.694358  -53.011137  -98.070580   68.556457   25.217205  -10.982143 
##          31          32          33          34          35          36 
##   11.029094  -44.321396   38.869976  102.559718   44.664107  -36.757062 
##          37          38          39          40          41          42 
##   17.874692 -107.851374   23.022573   72.302382   62.061348  -26.430205 
##          43          44          45          46          47          48 
##  -54.710310  123.869976 -152.020273  -54.580187   10.826485 -122.311614 
##          49          50          51          52          53          54 
##   33.186756  -16.998095  -30.288845  -37.739008   20.415393   37.746024 
##          55          56          57          58          59          60 
##  -74.819765   14.551742  129.285270   24.309199  -22.697618    4.248650&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(nmodel$residuals)

#Runs different tests for normality run from the predicted values for rent

p3 &amp;lt;- predict(model2)
summary(p3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   417.3   491.6   526.1   572.3   640.7  1045.8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(p3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 125.7441&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#H0: from normal distribution p &amp;lt; 0.05 reject
shapiro.test(p3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Shapiro-Wilk normality test
## 
## data:  p3
## W = 0.86842, p-value = 1.114e-05&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#compares if two samples are from same distribution so comparing to a normal distribution H0: from different distributions p &amp;lt; 0.05 reject
ks.test(p3, rnorm(60,572.3,125.7441))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in ks.test(p3, rnorm(60, 572.3, 125.7441)): cannot compute exact p-value
## with ties&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  p3 and rnorm(60, 572.3, 125.7441)
## D = 0.18333, p-value = 0.2656
## alternative hypothesis: two-sided&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Linearity Test
#https://bookdown.org/ccolonescu/RPoE4/further-inference-in-multiple-regression.html
#http://r-statistics.co/Statistical-Tests-in-R.html

library(lmtest)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;lmtest&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Ramsey RESET test test whether higher order polynomials are necessary H0: no higher order polynomials are necssary
resettest(model3, power = 2:3, type = &amp;#39;fitted&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  RESET test
## 
## data:  model3
## RESET = 1.3333, df1 = 2, df2 = 52, p-value = 0.2725&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resettest(model3, power = 2:3, type = &amp;#39;regressor&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  RESET test
## 
## data:  model3
## RESET = 2.0443, df1 = 10, df2 = 44, p-value = 0.05111&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Heteroscedasticity
#Put simply, heteroscedasticity (also spelled heteroskedasticity) refers to the circumstance in which the variability of a variable is unequal across the range of values of a second variable that predicts it.
#http://www.statsmakemecry.com/smmctheblog/confusing-stats-terms-explained-heteroscedasticity-heteroske.html

#Fisher Test can be used to tell if two samples have the same variance H0: ratio of variances is 1 aka they are the same p &amp;lt; 0.05 reject H0
var.test(sample(35,p3, replace = TRUE),sample(35,p3, replace = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  F test to compare two variances
## 
## data:  sample(35, p3, replace = TRUE) and sample(35, p3, replace = TRUE)
## F = 0.91901, num df = 513, denom df = 513, p-value = 0.3391
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.7728094 1.0928623
## sample estimates:
## ratio of variances 
##          0.9190072&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Independance 

#Chi square tests if two caterogical variables are dependant on each other H0: variables are independant p &amp;lt; 0.05 reject H0
chisq.test(table(data1$Bedrooms,data1$Bathrooms))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in chisq.test(table(data1$Bedrooms, data1$Bathrooms)): Chi-squared
## approximation may be incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s Chi-squared test
## 
## data:  table(data1$Bedrooms, data1$Bathrooms)
## X-squared = 29.391, df = 3, p-value = 1.853e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(table(data1$Bedrooms,data1$Bathrooms))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of cases in table: 60 
## Number of factors: 2 
## Test for independence of all factors:
##  Chisq = 29.391, df = 3, p-value = 1.853e-06
##  Chi-squared approximation may be incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Correlation test between two continuous variables H0: correlation is 0 aka they are independant p &amp;lt; 0.05 reject H0

#All show some correlation
cor.test(data1$Rent, data1$Area)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Rent and data1$Area
## t = 13.702, df = 58, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7970327 0.9231055
## sample estimates:
##       cor 
## 0.8740597&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor.test(data1$Bedrooms, data1$Area)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Bedrooms and data1$Area
## t = 12.811, df = 58, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7747757 0.9140118
## sample estimates:
##       cor 
## 0.8595894&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor.test(data1$Bedrooms, data1$Bathrooms)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Bedrooms and data1$Bathrooms
## t = 6.6217, df = 58, p-value = 1.262e-08
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.4826241 0.7800925
## sample estimates:
##       cor 
## 0.6561389&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor.test(data1$Bedrooms, data1$Bathrooms)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Bedrooms and data1$Bathrooms
## t = 6.6217, df = 58, p-value = 1.262e-08
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.4826241 0.7800925
## sample estimates:
##       cor 
## 0.6561389&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Are uncorrelated
cor.test(data1$Area, data1$Distance)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Area and data1$Distance
## t = -0.4492, df = 58, p-value = 0.655
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.3081967  0.1980052
## sample estimates:
##         cor 
## -0.05887988&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Both of these tests use log parameters as well as lag and leads to determine if the variance changes or if the predictors are truly independant of each other&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Other helpful Stat and R learning
#http://faculty.marshall.usc.edu/gareth-james/ISL/index.html
#https://web.stanford.edu/~hastie/ElemStatLearn/

#Essentials of Machine Learning https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/

#CLT and Stat Basics https://www.analyticsvidhya.com/blog/2019/05/statistics-101-introduction-central-limit-theorem/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
