<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ORIE Basics | Erick Jones</title>
    <link>/category/orie-basics/</link>
      <atom:link href="/category/orie-basics/index.xml" rel="self" type="application/rss+xml" />
    <description>ORIE Basics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>&amp;copy Erick Jones {2020}</copyright><lastBuildDate>Sun, 05 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>ORIE Basics</title>
      <link>/category/orie-basics/</link>
    </image>
    
    <item>
      <title>Gurobi Basic LP/MIP Examples</title>
      <link>/post/orie/gurobi_examples/</link>
      <pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/orie/gurobi_examples/</guid>
      <description> 

&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post explores how to use Gurobi to solve LPs and MIPs.
I have written these using Gurobi as a solver and as the mathematical formulation software.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gurobi)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;gurobi&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Matrix)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This example formulates and solves the following simple LP model:
&lt;span class=&#34;math inline&#34;&gt;\(max: x + 2y + 3z\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;subject to
&lt;span class=&#34;math inline&#34;&gt;\(x + y \leq 1\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(y + z \leq 1\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- list()

model$A          &amp;lt;- matrix(c(1,1,0,0,1,1), nrow=2, byrow=T)
model$obj        &amp;lt;- c(1,2,3)
model$modelsense &amp;lt;- &amp;#39;max&amp;#39;
model$rhs        &amp;lt;- c(1,1)
model$sense      &amp;lt;- c(&amp;#39;&amp;lt;&amp;#39;, &amp;#39;&amp;lt;&amp;#39;)

result &amp;lt;- gurobi(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 2 rows, 3 columns and 4 nonzeros
## Model fingerprint: 0x39e2cde3
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [1e+00, 3e+00]
##   Bounds range     [0e+00, 0e+00]
##   RHS range        [1e+00, 1e+00]
## Presolve removed 2 rows and 3 columns
## Presolve time: 0.00s
## Presolve: All rows and columns removed
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    4.0000000e+00   0.000000e+00   0.000000e+00      0s
## 
## Solved in 0 iterations and 0.00 seconds
## Optimal objective  4.000000000e+00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(result$objval)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(result$x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 0 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Second option for A - as a sparseMatrix (using the Matrix package)...

model$A &amp;lt;- spMatrix(2, 3, c(1, 1, 2, 2), c(1, 2, 2, 3), c(1, 1, 1, 1))

params &amp;lt;- list(Method=2, TimeLimit=100)

result &amp;lt;- gurobi(model, params)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 2 rows, 3 columns and 4 nonzeros
## Model fingerprint: 0x39e2cde3
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [1e+00, 3e+00]
##   Bounds range     [0e+00, 0e+00]
##   RHS range        [1e+00, 1e+00]
## Presolve removed 2 rows and 3 columns
## Presolve time: 0.00s
## Presolve: All rows and columns removed
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    4.0000000e+00   0.000000e+00   0.000000e+00      0s
## 
## Solved in 0 iterations and 0.00 seconds
## Optimal objective  4.000000000e+00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(result$objval)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(result$x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 0 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Third option for A - as a sparse triplet matrix (using the slam package)...

model$A &amp;lt;- simple_triplet_matrix(c(1, 1, 2, 2), c(1, 2, 2, 3), c(1, 1, 1, 1))

params &amp;lt;- list(Method=3, TimeLimit=100)

result &amp;lt;- gurobi(model, params)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 2 rows, 3 columns and 4 nonzeros
## Model fingerprint: 0x39e2cde3
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [1e+00, 3e+00]
##   Bounds range     [0e+00, 0e+00]
##   RHS range        [1e+00, 1e+00]
## Presolve removed 2 rows and 3 columns
## Presolve time: 0.00s
## Presolve: All rows and columns removed
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    4.0000000e+00   0.000000e+00   0.000000e+00      0s
## 
## Solved in 0 iterations and 0.00 seconds
## Optimal objective  4.000000000e+00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(result$objval)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(result$x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 0 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Clear space
rm(result, params, model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This example formulates and solves the following simple MIP model:
&lt;span class=&#34;math inline&#34;&gt;\(max: x + y + 2 z\)&lt;/span&gt;
subject to
&lt;span class=&#34;math inline&#34;&gt;\(x + 2 y + 3 z \leq 4\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x + y \geq 1\)&lt;/span&gt;
x, y, z binary&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- list()

model$A          &amp;lt;- matrix(c(1,2,3,1,1,0), nrow=2, ncol=3, byrow=T)
model$obj        &amp;lt;- c(1,1,2)
model$modelsense &amp;lt;- &amp;#39;max&amp;#39;
model$rhs        &amp;lt;- c(4,1)
model$sense      &amp;lt;- c(&amp;#39;&amp;lt;&amp;#39;, &amp;#39;&amp;gt;&amp;#39;)
model$vtype      &amp;lt;- c(&amp;#39;B&amp;#39;,&amp;#39;B&amp;#39;,&amp;#39;B&amp;#39;)

params &amp;lt;- list(OutputFlag=0)

result &amp;lt;- gurobi(model, params)

print(&amp;#39;Solution:&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Solution:&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(result$objval)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(result$x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 0 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Clear space
rm(model, result, params)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Solve the classic diet model, showing how to add constraints
# to an existing model.


# define primitive data
Categories      &amp;lt;- c(&amp;#39;calories&amp;#39;, &amp;#39;protein&amp;#39;, &amp;#39;fat&amp;#39;, &amp;#39;sodium&amp;#39;)
nCategories     &amp;lt;- length(Categories)
minNutrition    &amp;lt;- c(     1800 ,       91 ,    0 ,       0 )
maxNutrition    &amp;lt;- c(     2200 ,      Inf ,   65 ,    1779 )

Foods           &amp;lt;- c(&amp;#39;hamburger&amp;#39;, &amp;#39;chicken&amp;#39;, &amp;#39;hot dog&amp;#39;, &amp;#39;fries&amp;#39;, &amp;#39;macaroni&amp;#39;,
                     &amp;#39;pizza&amp;#39;, &amp;#39;salad&amp;#39;, &amp;#39;milk&amp;#39;, &amp;#39;ice cream&amp;#39;)
nFoods          &amp;lt;- length(Foods)
cost            &amp;lt;- c(2.49, 2.89, 1.50, 1.89, 2.09, 1.99, 2.49, 0.89, 1.59)
nutritionValues &amp;lt;- c( 410, 24, 26 ,  730,
                      420, 32, 10 , 1190,
                      560, 20, 32 , 1800,
                      380,  4, 19 ,  270,
                      320, 12, 10 ,  930,
                      320, 15, 12 ,  820,
                      320, 31, 12 , 1230,
                      100,  8, 2.5,  125,
                      330,  8, 10 ,  180 )

#Each constraint is basically the Nutrion = sum(food*nut/food)
#Could have just made nutrition the RHS, but it works as a bounded variable because you need both upper and lower and it shrinks the amount of equations
#Objective min cost of food

# Build model
model     &amp;lt;- list()
#spMatrix tells you where to put the non zero values in matrix i,j is the location and x are teh values for each pair
model$A   &amp;lt;- spMatrix(nCategories, nCategories + nFoods,
               i = c(mapply(rep,1:4,1+nFoods)),
               j = c(1, (nCategories+1):(nCategories+nFoods),
                     2, (nCategories+1):(nCategories+nFoods),
                     3, (nCategories+1):(nCategories+nFoods),
                     4, (nCategories+1):(nCategories+nFoods) ),
               x = c(-1.0, nutritionValues[1 + nCategories*(0:(nFoods-1))],
                     -1.0, nutritionValues[2 + nCategories*(0:(nFoods-1))],
                     -1.0, nutritionValues[3 + nCategories*(0:(nFoods-1))],
                     -1.0, nutritionValues[4 + nCategories*(0:(nFoods-1))] ))
model$obj         &amp;lt;- c(rep(0, nCategories), cost)
model$lb          &amp;lt;- c(minNutrition, rep(0, nFoods))
model$ub          &amp;lt;- c(maxNutrition, rep(Inf, nFoods))
model$varnames    &amp;lt;- c(Categories, Foods)
model$rhs         &amp;lt;- rep(0,nCategories)
model$sense       &amp;lt;- rep(&amp;#39;=&amp;#39;,nCategories)
model$constrnames &amp;lt;- Categories
model$modelname   &amp;lt;- &amp;#39;diet&amp;#39;
model$modelsense  &amp;lt;- &amp;#39;min&amp;#39;

# display results
printSolution &amp;lt;- function(model, res, nCategories, nFoods) {
  if (res$status == &amp;#39;OPTIMAL&amp;#39;) {
    cat(&amp;#39;\nCost: &amp;#39;,res$objval,&amp;#39;\nBuy:\n&amp;#39;)
    for (j in nCategories + 1:nFoods) {
      if (res$x[j] &amp;gt; 1e-4) {
        cat(format(model$varnames[j],justify=&amp;#39;left&amp;#39;,width=10),&amp;#39;:&amp;#39;,
            format(res$x[j],justify=&amp;#39;right&amp;#39;,width=10,nsmall=2),&amp;#39;\n&amp;#39;)
      }
    }
    cat(&amp;#39;\nNutrition:\n&amp;#39;)
    for (j in 1:nCategories) {
      cat(format(model$varnames[j],justify=&amp;#39;left&amp;#39;,width=10),&amp;#39;:&amp;#39;,
          format(res$x[j],justify=&amp;#39;right&amp;#39;,width=10,nsmall=2),&amp;#39;\n&amp;#39;)
    }
  } else {
    cat(&amp;#39;No solution\n&amp;#39;)
  }
}

# Optimize
res &amp;lt;- gurobi(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 4 rows, 13 columns and 40 nonzeros
## Model fingerprint: 0xff20f824
## Coefficient statistics:
##   Matrix range     [1e+00, 2e+03]
##   Objective range  [9e-01, 3e+00]
##   Bounds range     [7e+01, 2e+03]
##   RHS range        [0e+00, 0e+00]
## Presolve removed 0 rows and 3 columns
## Presolve time: 0.00s
## Presolved: 4 rows, 10 columns, 37 nonzeros
## 
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    0.0000000e+00   1.472500e+02   0.000000e+00      0s
##        4    1.1828861e+01   0.000000e+00   0.000000e+00      0s
## 
## Solved in 4 iterations and 0.00 seconds
## Optimal objective  1.182886111e+01&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;printSolution(model, res, nCategories, nFoods)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Cost:  11.82886 
## Buy:
## hamburger  :  0.6045139 
## milk       :   6.970139 
## ice cream  :   2.591319 
## 
## Nutrition:
## calories   :    1800.00 
## protein    :      91.00 
## fat        :    59.0559 
## sodium     :    1779.00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Adding constraint: at most 6 servings of dairy
# this is the matrix part of the constraint
B &amp;lt;- spMatrix(1, nCategories + nFoods,
              i = rep(1,2),
              j = (nCategories+c(8,9)),
              x = rep(1,2))
# append B to A
model$A           &amp;lt;- rbind(model$A,       B)
# extend row-related vectors
model$constrnames &amp;lt;- c(model$constrnames, &amp;#39;limit_dairy&amp;#39;)
model$rhs         &amp;lt;- c(model$rhs,         10)
model$sense       &amp;lt;- c(model$sense,       &amp;#39;&amp;lt;&amp;#39;)

# Optimize
res &amp;lt;- gurobi(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 5 rows, 13 columns and 42 nonzeros
## Model fingerprint: 0xc012cadd
## Coefficient statistics:
##   Matrix range     [1e+00, 2e+03]
##   Objective range  [9e-01, 3e+00]
##   Bounds range     [7e+01, 2e+03]
##   RHS range        [1e+01, 1e+01]
## Presolve removed 0 rows and 3 columns
## Presolve time: 0.00s
## Presolved: 5 rows, 10 columns, 39 nonzeros
## 
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    0.0000000e+00   1.472500e+02   0.000000e+00      0s
##        4    1.1828861e+01   0.000000e+00   0.000000e+00      0s
## 
## Solved in 4 iterations and 0.00 seconds
## Optimal objective  1.182886111e+01&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;printSolution(model, res, nCategories, nFoods)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Cost:  11.82886 
## Buy:
## hamburger  :  0.6045139 
## milk       :   6.970139 
## ice cream  :   2.591319 
## 
## Nutrition:
## calories   :    1800.00 
## protein    :      91.00 
## fat        :    59.0559 
## sodium     :    1779.00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Clear space
#rm(res, model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Facility Location Problem (MIP)

# define primitive data
nPlants     &amp;lt;- 5
nWarehouses &amp;lt;- 4
# Warehouse demand in thousands of units
Demand      &amp;lt;- c(15, 18, 14, 20)
# Plant capacity in thousands of units 
Capacity    &amp;lt;- c(20, 22, 17, 19, 18)
# Fixed costs for each plant 
FixedCosts  &amp;lt;- c( 12000, 15000, 17000, 13000, 16000)
# Transportation costs per thousand units 
TransCosts  &amp;lt;- c(4000, 2000, 3000, 2500, 4500,
                 2500, 2600, 3400, 3000, 4000,
                 1200, 1800, 2600, 4100, 3000,
                 2200, 2600, 3100, 3700, 3200 )

flowidx &amp;lt;- function(w, p) {nPlants * (w-1) + p}

# Build model
model &amp;lt;- list()
model$modelname &amp;lt;- &amp;#39;facility&amp;#39;
model$modelsense &amp;lt;- &amp;#39;min&amp;#39;

# initialize data for variables
model$lb       &amp;lt;- 0
model$ub       &amp;lt;- c(rep(1, nPlants),   rep(Inf, nPlants * nWarehouses))
model$vtype    &amp;lt;- c(rep(&amp;#39;B&amp;#39;, nPlants), rep(&amp;#39;C&amp;#39;, nPlants * nWarehouses))
model$obj      &amp;lt;- c(FixedCosts, TransCosts)
model$varnames &amp;lt;- c(paste0(rep(&amp;#39;Open&amp;#39;,nPlants),1:nPlants),
                    sprintf(&amp;#39;Trans%d,%d&amp;#39;,
                            c(mapply(rep,1:nWarehouses,nPlants)),
                            1:nPlants))

# build production constraint matrix
#uses custom functions to fill out matrix, a bit out my wheelhouse
A1 &amp;lt;- spMatrix(nPlants, nPlants, i = c(1:nPlants), j = (1:nPlants), x = -Capacity)
A2 &amp;lt;- spMatrix(nPlants, nPlants * nWarehouses,
               i = c(mapply(rep, 1:nPlants, nWarehouses)),
               j = mapply(flowidx,1:nWarehouses,c(mapply(rep,1:nPlants,nWarehouses))),
               x = rep(1, nWarehouses * nPlants))
A3 &amp;lt;- spMatrix(nWarehouses, nPlants)
A4 &amp;lt;- spMatrix(nWarehouses, nPlants * nWarehouses,
               i = c(mapply(rep, 1:nWarehouses, nPlants)),
               j = mapply(flowidx,c(mapply(rep,1:nWarehouses,nPlants)),1:nPlants),
               x = rep(1, nPlants * nWarehouses))
model$A           &amp;lt;- rbind(cbind(A1, A2), cbind(A3, A4))
model$rhs         &amp;lt;- c(rep(0, nPlants),   Demand)
model$sense       &amp;lt;- c(rep(&amp;#39;&amp;lt;&amp;#39;, nPlants), rep(&amp;#39;=&amp;#39;, nWarehouses))
model$constrnames &amp;lt;- c(sprintf(&amp;#39;Capacity%d&amp;#39;,1:nPlants),
                       sprintf(&amp;#39;Demand%d&amp;#39;,1:nWarehouses))

# Save model
gurobi_write(model,&amp;#39;facilityR.lp&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Guess at the starting point: close the plant with the highest fixed
# costs; open all others first open all plants
model$start &amp;lt;- c(rep(1,nPlants),rep(NA, nPlants * nWarehouses))

# find most expensive plant, and close it in mipstart
cat(&amp;#39;Initial guess:\n&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Initial guess:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;worstidx &amp;lt;- which.max(FixedCosts)
model$start[worstidx] &amp;lt;- 0
cat(&amp;#39;Closing plant&amp;#39;,worstidx,&amp;#39;\n&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Closing plant 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set parameters
params &amp;lt;- list()
params$method &amp;lt;- 2

# Optimize
res &amp;lt;- gurobi(model, params)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 9 rows, 25 columns and 45 nonzeros
## Model fingerprint: 0x36b45dc0
## Variable types: 20 continuous, 5 integer (5 binary)
## Coefficient statistics:
##   Matrix range     [1e+00, 2e+01]
##   Objective range  [1e+03, 2e+04]
##   Bounds range     [1e+00, 1e+00]
##   RHS range        [1e+01, 2e+01]
## 
## User MIP start produced solution with objective 210500 (0.01s)
## Loaded user MIP start with objective 210500
## 
## Presolve time: 0.00s
## Presolved: 9 rows, 25 columns, 45 nonzeros
## Variable types: 20 continuous, 5 integer (5 binary)
## Root barrier log...
## 
## Ordering time: 0.00s
## 
## Barrier statistics:
##  AA&amp;#39; NZ     : 2.000e+01
##  Factor NZ  : 4.500e+01
##  Factor Ops : 2.850e+02 (less than 1 second per iteration)
##  Threads    : 1
## 
##                   Objective                Residual
## Iter       Primal          Dual         Primal    Dual     Compl     Time
##    0   7.94290841e+05 -2.24842916e+05  7.25e+00 3.75e+03  2.69e+04     0s
##    1   2.34432856e+05  7.59319096e+04  1.78e-15 3.64e-12  3.17e+03     0s
##    2   2.10232015e+05  1.89880475e+05  8.88e-16 4.01e-12  4.07e+02     0s
##    3   2.00964341e+05  1.98582137e+05  9.77e-15 2.79e-12  4.76e+01     0s
##    4   1.99878036e+05  1.99804970e+05  2.46e-13 3.19e-12  1.46e+00     0s
##    5   1.99833638e+05  1.99832960e+05  3.14e-13 1.82e-12  1.36e-02     0s
##    6   1.99833333e+05  1.99833333e+05  1.47e-14 2.86e-12  1.39e-08     0s
##    7   1.99833333e+05  1.99833333e+05  7.10e-15 2.73e-12  1.39e-14     0s
## 
## Barrier solved model in 7 iterations and 0.01 seconds
## Optimal objective 1.99833333e+05
## 
## 
## Root relaxation: objective 1.998333e+05, 6 iterations, 0.00 seconds
## 
##     Nodes    |    Current Node    |     Objective Bounds      |     Work
##  Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time
## 
##      0     0 199833.333    0    1 210500.000 199833.333  5.07%     -    0s
##      0     0 200252.941    0    1 210500.000 200252.941  4.87%     -    0s
##      0     0 210500.000    0    1 210500.000 210500.000  0.00%     -    0s
## 
## Cutting planes:
##   Flow cover: 3
## 
## Explored 1 nodes (11 simplex iterations) in 0.01 seconds
## Thread count was 8 (of 8 available processors)
## 
## Solution count 1: 210500 
## 
## Optimal solution found (tolerance 1.00e-04)
## Best objective 2.105000000000e+05, best bound 2.105000000000e+05, gap 0.0000%&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Print solution
if (res$status == &amp;#39;OPTIMAL&amp;#39;) {
  cat(&amp;#39;\nTotal Costs:&amp;#39;,res$objval,&amp;#39;\nsolution:\n&amp;#39;)
  cat(&amp;#39;Facilities:&amp;#39;, model$varnames[which(res$x[1:nPlants]&amp;gt;1e-5)], &amp;#39;\n&amp;#39;)
  active &amp;lt;- nPlants + which(res$x[(nPlants+1):(nPlants*(nWarehouses+1))] &amp;gt; 1e-5)
  cat(&amp;#39;Flows: &amp;#39;)
  cat(sprintf(&amp;#39;%s=%g &amp;#39;,model$varnames[active], res$x[active]), &amp;#39;\n&amp;#39;)
  rm(active)
} else {
  cat(&amp;#39;No solution\n&amp;#39;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Total Costs: 210500 
## solution:
## Facilities: Open1 Open2 Open4 Open5 
## Flows: Trans1,2=14  Trans1,4=1  Trans2,4=18  Trans3,1=14  Trans4,1=6  Trans4,2=8  Trans4,5=6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Clear space
rm(res, model, params, A1, A2, A3, A4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assign workers to shifts; each worker may or may not be available on a
# particular day. If the problem cannot be solved, use IIS iteratively to
# find all conflicting constraints.


# Function to display results
printsolution &amp;lt;- function(result) {
  if(result$status == &amp;#39;OPTIMAL&amp;#39;) {
    cat(&amp;#39;The optimal objective is&amp;#39;,result$objval,&amp;#39;\n&amp;#39;)
    cat(&amp;#39;Schedule:\n&amp;#39;)
    for (s in 1:nShifts) {
      cat(&amp;#39;\t&amp;#39;,Shifts[s],&amp;#39;:&amp;#39;)
      for (w in 1:nWorkers) {
        if (result$x[varIdx(w,s)] &amp;gt; 0.9) cat(Workers[w],&amp;#39; &amp;#39;)
      }
      cat(&amp;#39;\n&amp;#39;)
    }
  }
}

# define data
nShifts  &amp;lt;- 14
nWorkers &amp;lt;-  7
nVars    &amp;lt;- nShifts * nWorkers
varIdx   &amp;lt;- function(w,s) {s+(w-1)*nShifts}

Shifts  &amp;lt;- c(&amp;#39;Mon1&amp;#39;, &amp;#39;Tue2&amp;#39;, &amp;#39;Wed3&amp;#39;, &amp;#39;Thu4&amp;#39;, &amp;#39;Fri5&amp;#39;, &amp;#39;Sat6&amp;#39;, &amp;#39;Sun7&amp;#39;,
             &amp;#39;Mon8&amp;#39;, &amp;#39;Tue9&amp;#39;, &amp;#39;Wed10&amp;#39;, &amp;#39;Thu11&amp;#39;, &amp;#39;Fri12&amp;#39;, &amp;#39;Sat13&amp;#39;, &amp;#39;Sun14&amp;#39;)
Workers &amp;lt;- c( &amp;#39;Amy&amp;#39;, &amp;#39;Bob&amp;#39;, &amp;#39;Cathy&amp;#39;, &amp;#39;Dan&amp;#39;, &amp;#39;Ed&amp;#39;, &amp;#39;Fred&amp;#39;, &amp;#39;Gu&amp;#39; )

pay     &amp;lt;- c(10, 12, 10, 8, 8, 9, 11 )

shiftRequirements &amp;lt;- c(3, 2, 4, 4, 5, 6, 5, 2, 2, 3, 4, 6, 7, 5 )

availability &amp;lt;- list( c( 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1 ),
                      c( 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0 ),
                      c( 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1 ),
                      c( 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1 ),
                      c( 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1 ),
                      c( 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1 ),
                      c( 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ) )

# Set-up environment
env &amp;lt;- list()
env$logfile &amp;lt;- &amp;#39;workforce2.log&amp;#39;

# Build model
model            &amp;lt;- list()
model$modelname  &amp;lt;- &amp;#39;workforce2&amp;#39;
model$modelsense &amp;lt;- &amp;#39;min&amp;#39;

# Initialize assignment decision variables:
#    x[w][s] == 1 if worker w is assigned
#    to shift s. Since an assignment model always produces integer
#    solutions, we use continuous variables and solve as an LP.
model$lb       &amp;lt;- 0
model$ub       &amp;lt;- rep(1, nVars)
model$obj      &amp;lt;- rep(0, nVars)
model$varnames &amp;lt;- rep(&amp;#39;&amp;#39;,nVars)
for (w in 1:nWorkers) {
  for (s in 1:nShifts) {
    model$varnames[varIdx(w,s)] = paste0(Workers[w],&amp;#39;.&amp;#39;,Shifts[s])
    model$obj[varIdx(w,s)]      = pay[w]
    if (availability[[w]][s] == 0) model$ub[varIdx(w,s)] = 0
  }
}

# Set-up shift-requirements constraints
model$A           &amp;lt;- spMatrix(nShifts,nVars,
                      i = c(mapply(rep,1:nShifts,nWorkers)),
                      j = mapply(varIdx,1:nWorkers,
                                 mapply(rep,1:nShifts,nWorkers)),
                      x = rep(1,nShifts * nWorkers))
model$sense       &amp;lt;- rep(&amp;#39;=&amp;#39;,nShifts)
model$rhs         &amp;lt;- shiftRequirements
model$constrnames &amp;lt;- Shifts

# Save model
gurobi_write(model,&amp;#39;workforce2.lp&amp;#39;, env)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Optimize
result &amp;lt;- gurobi(model, env = env)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 14 rows, 98 columns and 98 nonzeros
## Model fingerprint: 0xbddc1063
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [8e+00, 1e+01]
##   Bounds range     [1e+00, 1e+00]
##   RHS range        [2e+00, 7e+00]
## Presolve removed 1 rows and 60 columns
## Presolve time: 0.00s
## 
## Solved in 0 iterations and 0.00 seconds
## Infeasible model&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Display results
if (result$status == &amp;#39;OPTIMAL&amp;#39;) {
# The code may enter here if you change some of the data... otherwise
# this will never be executed.
  printsolution(result);
} else if (result$status == &amp;#39;INFEASIBLE&amp;#39;) {
# We will loop until we reduce a model that can be solved
  numremoved &amp;lt;- 0 
  while(result$status == &amp;#39;INFEASIBLE&amp;#39;) {
    iis               &amp;lt;- gurobi_iis(model, env = env)
    keep              &amp;lt;- (!iis$Arows)
    cat(&amp;#39;Removing rows&amp;#39;,model$constrnames[iis$Arows],&amp;#39;...\n&amp;#39;)
    model$A           &amp;lt;- model$A[keep,,drop = FALSE]
    model$sense       &amp;lt;- model$sense[keep]
    model$rhs         &amp;lt;- model$rhs[keep]
    model$constrnames &amp;lt;- model$constrnames[keep]
    numremoved        &amp;lt;- numremoved + 1
    gurobi_write(model, paste0(&amp;#39;workforce2-&amp;#39;,numremoved,&amp;#39;.lp&amp;#39;), env)
    result            &amp;lt;- gurobi(model, env = env)
  }
  printsolution(result)
  rm(iis)
} else {
# Just to handle user interruptions or other problems
  cat(&amp;#39;Unexpected status&amp;#39;,result$status,&amp;#39;\nEnding now\n&amp;#39;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## IIS computed: 1 constraints and 7 bounds
## IIS runtime: 0.00 seconds
## Removing rows Thu4 ...
## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 13 rows, 98 columns and 91 nonzeros
## Model fingerprint: 0x75a77c30
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [8e+00, 1e+01]
##   Bounds range     [1e+00, 1e+00]
##   RHS range        [2e+00, 7e+00]
## Presolve removed 1 rows and 61 columns
## Presolve time: 0.00s
## 
## Solved in 0 iterations and 0.00 seconds
## Infeasible model
## 
## IIS computed: 1 constraints and 7 bounds
## IIS runtime: 0.00 seconds
## Removing rows Sat6 ...
## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 12 rows, 98 columns and 84 nonzeros
## Model fingerprint: 0x529973cc
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [8e+00, 1e+01]
##   Bounds range     [1e+00, 1e+00]
##   RHS range        [2e+00, 7e+00]
## Presolve removed 1 rows and 62 columns
## Presolve time: 0.00s
## 
## Solved in 0 iterations and 0.00 seconds
## Infeasible model
## 
## IIS computed: 1 constraints and 7 bounds
## IIS runtime: 0.00 seconds
## Removing rows Sun7 ...
## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 11 rows, 98 columns and 77 nonzeros
## Model fingerprint: 0x0cbf4dba
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [8e+00, 1e+01]
##   Bounds range     [1e+00, 1e+00]
##   RHS range        [2e+00, 7e+00]
## Presolve removed 1 rows and 63 columns
## Presolve time: 0.00s
## 
## Solved in 0 iterations and 0.00 seconds
## Infeasible model
## 
## IIS computed: 1 constraints and 7 bounds
## IIS runtime: 0.00 seconds
## Removing rows Fri12 ...
## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 10 rows, 98 columns and 70 nonzeros
## Model fingerprint: 0x02f1ed80
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [8e+00, 1e+01]
##   Bounds range     [1e+00, 1e+00]
##   RHS range        [2e+00, 7e+00]
## Presolve removed 10 rows and 98 columns
## Presolve time: 0.00s
## Presolve: All rows and columns removed
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    3.3500000e+02   0.000000e+00   1.480000e+02      0s
## Extra 5 simplex iterations after uncrush
##        5    3.3500000e+02   0.000000e+00   0.000000e+00      0s
## 
## Solved in 5 iterations and 0.00 seconds
## Optimal objective  3.350000000e+02
## The optimal objective is 335 
## Schedule:
##   Mon1 :Ed  Fred  Gu  
##   Tue2 :Dan  Ed  
##   Wed3 :Amy  Dan  Ed  Fred  
##   Thu4 :
##   Fri5 :Amy  Cathy  Dan  Ed  Gu  
##   Sat6 :
##   Sun7 :
##   Mon8 :Dan  Ed  
##   Tue9 :Dan  Ed  
##   Wed10 :Amy  Cathy  Dan  
##   Thu11 :Amy  Cathy  Dan  Ed  
##   Fri12 :
##   Sat13 :Amy  Bob  Cathy  Dan  Ed  Fred  Gu  
##   Sun14 :Amy  Cathy  Dan  Ed  Fred&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Clear space
rm(model, env, availability, Shifts, Workers, pay, shiftRequirements, result)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assign workers to shifts; each worker may or may not be available on a
# particular day. If the problem cannot be solved, relax the model
# to determine which constraints cannot be satisfied, and how much
# they need to be relaxed.


# Function to display results
printsolution &amp;lt;- function(result) {
  if(result$status == &amp;#39;OPTIMAL&amp;#39;) {
    cat(&amp;#39;The optimal objective is&amp;#39;,result$objval,&amp;#39;\n&amp;#39;)
    cat(&amp;#39;Schedule:\n&amp;#39;)
    for (s in 1:nShifts) {
      cat(&amp;#39;\t&amp;#39;,Shifts[s],&amp;#39;:&amp;#39;)
      for (w in 1:nWorkers) {
        if (result$x[varIdx(w,s)] &amp;gt; 0.9) cat(Workers[w],&amp;#39; &amp;#39;)
      }
      cat(&amp;#39;\n&amp;#39;)
    }
  }
}

# define data
nShifts  &amp;lt;- 14
nWorkers &amp;lt;-  7
nVars    &amp;lt;- nShifts * nWorkers
varIdx   &amp;lt;- function(w,s) {s+(w-1)*nShifts}

Shifts  &amp;lt;- c(&amp;#39;Mon1&amp;#39;, &amp;#39;Tue2&amp;#39;, &amp;#39;Wed3&amp;#39;, &amp;#39;Thu4&amp;#39;, &amp;#39;Fri5&amp;#39;, &amp;#39;Sat6&amp;#39;, &amp;#39;Sun7&amp;#39;,
             &amp;#39;Mon8&amp;#39;, &amp;#39;Tue9&amp;#39;, &amp;#39;Wed10&amp;#39;, &amp;#39;Thu11&amp;#39;, &amp;#39;Fri12&amp;#39;, &amp;#39;Sat13&amp;#39;, &amp;#39;Sun14&amp;#39;)
Workers &amp;lt;- c( &amp;#39;Amy&amp;#39;, &amp;#39;Bob&amp;#39;, &amp;#39;Cathy&amp;#39;, &amp;#39;Dan&amp;#39;, &amp;#39;Ed&amp;#39;, &amp;#39;Fred&amp;#39;, &amp;#39;Gu&amp;#39; )

pay     &amp;lt;- c(10, 12, 10, 8, 8, 9, 11 )

shiftRequirements &amp;lt;- c(3, 2, 4, 4, 5, 6, 5, 2, 2, 3, 4, 6, 7, 5 )

availability &amp;lt;- list( c( 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1 ),
                      c( 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0 ),
                      c( 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1 ),
                      c( 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1 ),
                      c( 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1 ),
                      c( 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1 ),
                      c( 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ) )

# Set-up environment
env &amp;lt;- list()
env$logfile &amp;lt;- &amp;#39;workforce3.log&amp;#39;

# Build model
model            &amp;lt;- list()
model$modelname  &amp;lt;- &amp;#39;workforce3&amp;#39;
model$modelsense &amp;lt;- &amp;#39;min&amp;#39;

# Initialize assignment decision variables:
#    x[w][s] == 1 if worker w is assigned
#    to shift s. Since an assignment model always produces integer
#    solutions, we use continuous variables and solve as an LP.
model$lb       &amp;lt;- 0
model$ub       &amp;lt;- rep(1, nVars)
model$obj      &amp;lt;- rep(0, nVars)
model$varnames &amp;lt;- rep(&amp;#39;&amp;#39;,nVars)
for (w in 1:nWorkers) {
  for (s in 1:nShifts) {
    model$varnames[varIdx(w,s)] = paste0(Workers[w],&amp;#39;.&amp;#39;,Shifts[s])
    model$obj[varIdx(w,s)]      = pay[w]
    if (availability[[w]][s] == 0) model$ub[varIdx(w,s)] = 0
  }
}

# Set-up shift-requirements constraints
model$A           &amp;lt;- spMatrix(nShifts,nVars,
                      i = c(mapply(rep,1:nShifts,nWorkers)),
                      j = mapply(varIdx,1:nWorkers,
                                 mapply(rep,1:nShifts,nWorkers)),
                      x = rep(1,nShifts * nWorkers))
model$sense       &amp;lt;- rep(&amp;#39;=&amp;#39;,nShifts)
model$rhs         &amp;lt;- shiftRequirements
model$constrnames &amp;lt;- Shifts

# Save model
gurobi_write(model,&amp;#39;workforce3.lp&amp;#39;, env)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Optimize
result &amp;lt;- gurobi(model, env = env)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 14 rows, 98 columns and 98 nonzeros
## Model fingerprint: 0xbddc1063
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [8e+00, 1e+01]
##   Bounds range     [1e+00, 1e+00]
##   RHS range        [2e+00, 7e+00]
## Presolve removed 1 rows and 60 columns
## Presolve time: 0.00s
## 
## Solved in 0 iterations and 0.00 seconds
## Infeasible model&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Display results
if (result$status == &amp;#39;OPTIMAL&amp;#39;) {
# The code may enter here if you change some of the data... otherwise
# this will never be executed.
  printsolution(result);
} else if (result$status == &amp;#39;INFEASIBLE&amp;#39;) {
# Use gurobi_feasrelax to find out which copnstraints should be relaxed
# and by how much to make the problem feasible.
  penalties     &amp;lt;- list()
  penalties$lb  &amp;lt;- Inf
  penalties$ub  &amp;lt;- Inf
  penalties$rhs &amp;lt;- rep(1,length(model$rhs))
  feasrelax     &amp;lt;- gurobi_feasrelax(model, 0, FALSE, penalties, env = env)
  result        &amp;lt;- gurobi(feasrelax$model, env = env)
  if (result$status == &amp;#39;OPTIMAL&amp;#39;) {
    printsolution(result)
    cat(&amp;#39;Slack values:\n&amp;#39;)
    for (j in (nVars+1):length(result$x)) {
      if(result$x[j] &amp;gt; 0.1)
        cat(&amp;#39;\t&amp;#39;,feasrelax$model$varnames[j],result$x[j],&amp;#39;\n&amp;#39;)
    }
  } else {
    cat(&amp;#39;Unexpected status&amp;#39;,result$status,&amp;#39;\nEnding now\n&amp;#39;)
  }
  rm(penalties, feasrelax)
} else {
# Just to handle user interruptions or other problems
  cat(&amp;#39;Unexpected status&amp;#39;,result$status,&amp;#39;\nEnding now\n&amp;#39;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 14 rows, 126 columns and 126 nonzeros
## Model fingerprint: 0xa5484b98
## Coefficient statistics:
##   Matrix range     [1e+00, 1e+00]
##   Objective range  [1e+00, 1e+00]
##   Bounds range     [1e+00, 1e+00]
##   RHS range        [2e+00, 7e+00]
## Presolve removed 5 rows and 99 columns
## Presolve time: 0.00s
## Presolved: 9 rows, 27 columns, 27 nonzeros
## 
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    6.0000000e+00   0.000000e+00   0.000000e+00      0s
##        0    6.0000000e+00   0.000000e+00   0.000000e+00      0s
## 
## Solved in 0 iterations and 0.00 seconds
## Optimal objective  6.000000000e+00
## The optimal objective is 6 
## Schedule:
##   Mon1 :Ed  Fred  Gu  
##   Tue2 :Bob  Ed  
##   Wed3 :Amy  Cathy  Fred  Gu  
##   Thu4 :Cathy  Ed  
##   Fri5 :Amy  Cathy  Dan  Ed  Gu  
##   Sat6 :Bob  Dan  Fred  Gu  
##   Sun7 :Amy  Cathy  Ed  Gu  
##   Mon8 :Dan  Ed  
##   Tue9 :Dan  Gu  
##   Wed10 :Amy  Dan  Gu  
##   Thu11 :Amy  Bob  Ed  Gu  
##   Fri12 :Amy  Cathy  Dan  Fred  Gu  
##   Sat13 :Amy  Bob  Cathy  Dan  Ed  Fred  Gu  
##   Sun14 :Amy  Cathy  Ed  Fred  Gu  
## Slack values:
##   ArtP_Thu4 2 
##   ArtP_Sat6 2 
##   ArtP_Sun7 1 
##   ArtP_Fri12 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Clear space
rm(model, env, availability, Shifts, Workers, pay, shiftRequirements, result)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Basics of Markov Chains</title>
      <link>/post/orie/markovchains/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/orie/markovchains/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post explores how to markov chains work and how to visulaize them in R.
I use a R package specifically designed to visualize markov chains.
I also represent these markov chains using tables.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(markovchain)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;markovchain&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(diagram)
#Allows the use of exponential operators in matrix
library(expm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;expm&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#library(matlib)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A good article about Markov Chain Monte Carlo Methods https://towardsdatascience.com/a-zero-math-introduction-to-markov-chain-monte-carlo-methods-dcba889e0c50

# A Simple Example from https://www.analyticsvidhya.com/blog/2014/07/markov-chain-simplified/
# Creating a transition matrix
trans_mat &amp;lt;- matrix(c(0.7,0.3,0.1,0.9),nrow = 2, byrow = TRUE)
trans_mat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]  0.7  0.3
## [2,]  0.1  0.9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create the Discrete Time Markov Chain
disc_trans &amp;lt;- new(&amp;quot;markovchain&amp;quot;,transitionMatrix=trans_mat, states=c(&amp;quot;Pepsi&amp;quot;,&amp;quot;Coke&amp;quot;), name=&amp;quot;MC 1&amp;quot;) 
mcDF &amp;lt;- as(disc_trans,&amp;quot;data.frame&amp;quot;)
mcDF&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      t0    t1 prob
## 1 Pepsi Pepsi  0.7
## 2 Pepsi  Coke  0.3
## 3  Coke Pepsi  0.1
## 4  Coke  Coke  0.9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;disc_trans&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## MC 1 
##  A  2 - dimensional discrete Markov Chain defined by the following states: 
##  Pepsi, Coke 
##  The transition matrix  (by rows)  is defined as follows: 
##       Pepsi Coke
## Pepsi   0.7  0.3
## Coke    0.1  0.9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/markovchains_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Market Share after one month
Current_state &amp;lt;- c(0.55,0.45)
steps &amp;lt;- 1
finalState &amp;lt;- Current_state*disc_trans^steps #using power operator
finalState&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Pepsi Coke
## [1,]  0.43 0.57&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Market Share after two month
Current_state &amp;lt;- c(0.55,0.45)
steps &amp;lt;- 2
finalState &amp;lt;- Current_state*disc_trans^steps #using power operator
finalState&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Pepsi  Coke
## [1,] 0.358 0.642&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Markov Chain Statistical Operations
steadyStates(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Pepsi Coke
## [1,]  0.25 0.75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meanFirstPassageTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Pepsi     Coke
## Pepsi     0 3.333333
## Coke     10 0.000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meanRecurrenceTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Pepsi     Coke 
## 4.000000 1.333333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hittingProbabilities(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Pepsi Coke
## Pepsi     1    1
## Coke      1    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meanAbsorptionTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## named numeric(0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#absorptionProbabilities(disc_trans)
period(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## MC 1  Markov chain that is composed by: 
## Closed classes: 
## Pepsi Coke 
## Recurrent classes: 
## {Pepsi,Coke}
## Transient classes: 
## NONE 
## The Markov chain is irreducible 
## The absorbing states are: NONE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Manually Calculating Markov Chains
#https://www.probabilitycourse.com/chapter11/11_2_1_introduction.php

#Chapman-Kolmogorov Equation P^(n) = P^n
#p_ij^(m+n) = P(X_m+n = j | X_0 = i) = sum(p_ik^(m)*p_kj^(n))

#Probabilty Space after 5 steps
steps &amp;lt;- 5

Current_state%*%(trans_mat%^%steps)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          [,1]     [,2]
## [1,] 0.273328 0.726672&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Mean Return and Mean Hitting Times using Recursive Equations
#r_l = 1 + sum(t_k*p_lk)
#t_l = 0; t_k = 1 + sum(t_j*p_kj)

#Given X_0 = Coke time until pepsi first time, t_pepsi = 0
# t_coke = 1 + 1/10*t_pepsi + 9/10t_coke
t_coke &amp;lt;- solve(1/10,1)
#r_pepsi = 1 + 7/10*t_pepsi + 3/10*t_coke
r_pepsi &amp;lt;- 1 + 3/10*t_coke

meanFirstPassageTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Pepsi     Coke
## Pepsi     0 3.333333
## Coke     10 0.000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_coke&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meanRecurrenceTime(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Pepsi     Coke 
## 4.000000 1.333333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_pepsi&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Steady State
#Stationary Distribtution pi = pi*P, sum(pi) = 1 and if irreducible and aperiodic pi_j = lim(n&amp;gt;inf)P(X_n =j | X_0 = i)
#pi_p = 7/10pi_p+1/10pi_c; pi_c = 3/10pi_p + 9/10pi_c, pi_c+pi_p =1
A &amp;lt;- matrix(c(-3/10,1/10,3/10,-1/10,1,1), nrow =3, byrow = TRUE )
B &amp;lt;- c(0,0,1)
steadyStates(disc_trans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Pepsi Coke
## [1,]  0.25 0.75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Solve(A,B)




#rm(Current_state, disc_trans, finalState,steps,trans_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Continous Time Markov Chains

energyStates &amp;lt;- c(&amp;quot;sigma&amp;quot;, &amp;quot;sigma_star&amp;quot;)
#Must produce generator matrix from a transistion probablity matrix
Q &amp;lt;- expm::logm(disc_trans@transitionMatrix,method=&amp;#39;Eigen&amp;#39;)

gen &amp;lt;- matrix(data = c(-3, 3, 1, -1), nrow = 2, byrow = TRUE, dimnames = list(energyStates, energyStates))

molecularCTMC &amp;lt;- new(&amp;quot;ctmc&amp;quot;, states = energyStates, byrow = TRUE, generator = gen, name = &amp;quot;Molecular Transition Model&amp;quot;)

statesDist &amp;lt;- c(0.8, 0.2)
rctmc(n = 3, ctmc = molecularCTMC, initDist = statesDist, out.type = &amp;quot;df&amp;quot;, include.T0 = FALSE, T = 4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       states              time
## 1      sigma 0.490779113024473
## 2 sigma_star 0.893907884742721
## 3      sigma  1.83824493102602&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steadyStates(molecularCTMC)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      sigma sigma_star
## [1,]  0.25       0.75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Q-Learning with Liars Dice
#http://gradientdescending.com/q-learning-example-with-liars-dice-in-r/

# play a round of liars dice
liars.dice.round &amp;lt;- function(players, control, player.dice.count, agents, game.states, reward, Q.mat, a = 1, verbose = 1){
  
  # set array for recording results
  y.ctrl = c(); y.state = c(); y.action = c()
  
  # roll the dice for each player
  if(verbose &amp;gt; 0) cat(&amp;quot;\n\n&amp;quot;)
  rolls &amp;lt;- lapply(1:players, function(x) sort(sample(1:6, player.dice.count[[x]], replace = TRUE)))
  if(verbose &amp;gt; 1) lapply(rolls, function(x) cat(&amp;quot;dice: &amp;quot;, x, &amp;quot;\n&amp;quot;))
  total.dice &amp;lt;- sum(unlist(player.dice.count))
  
  # set penalty
  penalty &amp;lt;- sapply(1:players, function(x) 0, simplify = FALSE)
  
  # print dice blocks
  if(verbose &amp;gt; 0) Dice(rolls[[1]])
  
  # set up roll table
  roll.table &amp;lt;- roll.table.fn(rolls)
  
  # initial bid
  if(verbose &amp;gt; 0) cat(&amp;quot;place first bid\nPlayer&amp;quot;, control, &amp;quot;has control\n&amp;quot;)
  if(control == a){
    
    dice.value &amp;lt;- set.dice.value(&amp;quot;dice value: &amp;quot;, 6)
    dice.quantity &amp;lt;- set.dice.value(&amp;quot;quantity; &amp;quot;, sum(roll.table))
    
  }else{
    
    # agent plays
    p1.state &amp;lt;- which(game.states$total == total.dice &amp;amp; game.states$p1 == player.dice.count[[1]] &amp;amp; game.states$prob_cat == total.dice)
    pars &amp;lt;- list(dice = rolls[[control]], total.dice = total.dice, dice.value = NULL, dice.quantity = 0, p1.state = p1.state)
    agent.action &amp;lt;- agents[[control]](pars = pars, Q.mat = Q.mat)
    dice.value &amp;lt;- agent.action$dice.value
    dice.quantity &amp;lt;- agent.action$dice.quantity
    
  }
  
  
  # calculate probability cat and determine the game state
  # action set to raise because you can&amp;#39;t call without an initial bid
  # this could be a 3rd action (initial bid) but it&amp;#39;s not really necessary
  player.dice.qty &amp;lt;- table(rolls[[1]])[as.character(dice.value)]
  player.dice.qty &amp;lt;- ifelse(is.na(player.dice.qty), 0, player.dice.qty) %&amp;gt;% unname
  prob.cat &amp;lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
  p1.state &amp;lt;- which(game.states$total == total.dice &amp;amp; game.states$p1 == player.dice.count[[1]] &amp;amp; game.states$prob_cat == prob.cat)
  p1.action &amp;lt;- &amp;quot;raise&amp;quot;
  
  # storing states for Q iteration
  y.ctrl = c(); y.state = c(); y.action = c()
  
  # moving control to the next player
  # storing the previous player since if the next player calls the previous player could lose a die
  prev &amp;lt;- control
  control &amp;lt;- control %% players + 1
  if(verbose &amp;gt; 0) cat(&amp;quot;dice value &amp;quot;, dice.value, &amp;quot;; dice quantity &amp;quot;, dice.quantity, &amp;quot;\n&amp;quot;)
  
  
  # loop through each player and continue until there is a winner and loser
  called &amp;lt;- FALSE
  while(!called){
    
    # check if the player with control is still in the game - if not skip
    if(player.dice.count[[control]] &amp;gt; 0){
      if(control == a){
        
        action &amp;lt;- readline(&amp;quot;raise or call (r/c)? &amp;quot;)
        
      }else{
        
        # the agent makes a decision
        pars &amp;lt;- list(dice = rolls[[control]], total.dice = total.dice, dice.value = dice.value, dice.quantity = dice.quantity, p1.state = p1.state)
        agent.action &amp;lt;- agents[[control]](pars = pars, Q.mat = Q.mat)
        action &amp;lt;- agent.action$action
        
      }
      
      
      # storing states for reward iteration
      if(control == 1 &amp;amp; !is.null(agent.action$action)){
        player.dice.qty &amp;lt;- table(rolls[[1]])[as.character(dice.value)]
        player.dice.qty &amp;lt;- ifelse(is.na(player.dice.qty), 0, player.dice.qty) %&amp;gt;% unname
        
        p1.action &amp;lt;- agent.action$action
        prob.cat &amp;lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &amp;lt;- which(game.states$total == total.dice &amp;amp; game.states$p1 == player.dice.count[[1]] &amp;amp; game.states$prob_cat == prob.cat)
      }
      
      
      # called
      if(action %in% c(&amp;quot;call&amp;quot;, &amp;quot;c&amp;quot;)){
        
        if(verbose &amp;gt; 0) {
          cat(&amp;quot;player&amp;quot;, control, &amp;quot;called\nRoll table\n&amp;quot;)
          print(roll.table)
        }
        
        # dice are reavealed
        
        # check if the quantity of dice value is less or more than the total in the pool
        # if more control loses otherwise control-1 win
        if(dice.quantity &amp;gt; roll.table[dice.value]){
          
          penalty[[prev]] &amp;lt;- penalty[[prev]] - 1
          if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, prev, &amp;quot;lost a die\n&amp;quot;)
          
        }else{
          
          penalty[[control]] &amp;lt;- penalty[[control]] - 1
          if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, control, &amp;quot;lost a die\n&amp;quot;)
          
        }
        
        # for Q iteration
        y.ctrl &amp;lt;- c(y.ctrl, control); y.state &amp;lt;- c(y.state, p1.state); y.action &amp;lt;- c(y.action, p1.action)
        
        # if called use the penalty array to change states
        prob.cat &amp;lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &amp;lt;- which(game.states$total == total.dice-1 &amp;amp; game.states$p1 == player.dice.count[[1]]+penalty[[1]] &amp;amp; game.states$prob_cat == prob.cat)
        
        # break the loop
        called &amp;lt;- TRUE
        
      }else{
        
        if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, control, &amp;quot;raised\n&amp;quot;)
        
        if(control == a){
          
          # player sets next dice value
          dice.value &amp;lt;- set.dice.value(&amp;quot;dice value: &amp;quot;, 6)
          dice.quantity &amp;lt;- set.dice.value(&amp;quot;quantity; &amp;quot;, sum(roll.table))
          
        }else{
          
          dice.value &amp;lt;- agent.action$dice.value
          dice.quantity &amp;lt;- agent.action$dice.quantity
        }
        
        # p1 state after the raise
        prob.cat &amp;lt;- calc.prob(c(total.dice, player.dice.count[[1]], dice.quantity, player.dice.qty))
        p1.state &amp;lt;- which(game.states$total == total.dice &amp;amp; game.states$p1 == player.dice.count[[1]] &amp;amp; game.states$prob_cat == prob.cat)
        if(verbose &amp;gt; 0) cat(&amp;quot;dice value&amp;quot;, dice.value, &amp;quot;; dice quantity&amp;quot;, dice.quantity, &amp;quot;\n&amp;quot;)
      }
      
      # store info for Q update
      y.ctrl &amp;lt;- c(y.ctrl, control); y.state &amp;lt;- c(y.state, p1.state); y.action &amp;lt;- c(y.action, p1.action)
      
      # set the control player to now be the previous player
      prev &amp;lt;- control
    }
    
    # next player has control
    control &amp;lt;- control %% players + 1
  }
  
  # play results and return
  play &amp;lt;- data.frame(y.ctrl, y.state, y.action)
  return(list(penalty = penalty, play = play))
}








# play a full game of liars dice
play.liars.dice &amp;lt;- function(players = 4, num.dice = 6, auto = FALSE, verbose = 1, agents, Q.mat = NULL, train = FALSE, print.trans = FALSE){
  
  # begin!
  if(verbose &amp;gt; 0) liars.dice.title()
  
  # setting the number of dice each player has
  ndice &amp;lt;- sapply(rep(num.dice, players), function(x) x, simplify = FALSE)
  players.left &amp;lt;- sum(unlist(ndice) &amp;gt; 0)
  
  # setting game states matrix
  game.states &amp;lt;- generate.game.states(players, num.dice)
  
  # set up reward matrix
  reward &amp;lt;- generate.reward.matrix(game.states)
  reward &amp;lt;- list(raise = reward, call = reward)
  
  # set Q matrix if null
  if(is.null(Q.mat)) Q.mat &amp;lt;- matrix(0, nrow = nrow(reward$raise), ncol = length(reward), dimnames = list(c(), names(reward)))
  
  # while there is at least 2 left in the game
  # who has control
  ctrl &amp;lt;- sample(1:players, 1)
  play.df &amp;lt;- data.frame()
  while(players.left &amp;gt; 1){
    
    # play a round
    results &amp;lt;- liars.dice.round(
      players = players, 
      control = ctrl,
      player.dice.count = ndice, 
      game.states = game.states,
      reward = reward,
      Q.mat = Q.mat,
      agents = agents,
      a = as.numeric(!auto),
      verbose = verbose
    )
    
    # update how many dice the players are left with given the 
    # outcomes of the round
    for(k in seq_along(ndice)){
      ndice[[k]] &amp;lt;- ndice[[k]] + results$penalty[[k]]
      if(ndice[[k]] == 0 &amp;amp; results$penalty[[k]] == -1){
        if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, k, &amp;quot;is out of the game\n&amp;quot;)
      }
      
      # update who has control so they can start the bidding
      if(results$penalty[[k]] == -1){
        ctrl &amp;lt;- k
        while(ndice[[ctrl]] == 0){
          ctrl &amp;lt;- ctrl %% players + 1
        }
      }
    }
    
    # checking how many are left and if anyone won the game
    players.left &amp;lt;- sum(unlist(ndice) &amp;gt; 0)
    if(players.left == 1){
      if(verbose &amp;gt; 0) cat(&amp;quot;player&amp;quot;, which(unlist(ndice) &amp;gt; 0), &amp;quot;won the game\n&amp;quot;)
    }
    
    # appending play
    play.df &amp;lt;- rbind(play.df, results$play)
  }
  
  if(print.trans) print(play.df)
  
  # update Q
  # rather than training after each action, training at the 
  # end of each game in bulk
  # just easier this way
  if(train) Q.mat &amp;lt;- update.Q(play.df, Q.mat, reward)
  
  # return the winner and Q matrix
  return(list(winner = which(unlist(ndice) &amp;gt; 0), Q.mat = Q.mat))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Other Stochastic Processes
#Martingales http://gradientdescending.com/martingale-strategies-dont-work-but-we-knew-that-simulation-analysis-in-r/
#https://github.com/doehm/martingale

#Bayesian Networks http://gradientdescending.com/simulating-data-with-bayesian-networks/

#Other Q Learning https://www.r-bloggers.com/a-simple-intro-to-q-learning-in-r-floor-plan-navigation/
#https://dataaspirant.com/2018/02/05/reinforcement-learning-r/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linear Programming Examples and Applications</title>
      <link>/post/orie/lp_algorithms/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/orie/lp_algorithms/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post explores how to use the fundamental algorithms to solve LPs.
I have written these using Gurobi as a solver and as the mathematical formulation software.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gurobi)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;gurobi&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tictoc)
library(Matrix)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;ggplot2&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(MASS)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;MASS&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(max: 2x_1 + 3x_2\)&lt;/span&gt;
s.t.
&lt;span class=&#34;math inline&#34;&gt;\(-x_1 + x_2 \leq 5\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1+3x_2 &amp;lt;= 35; x_1 \leq 20\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#library(matlib)
#https://cran.r-project.org/web/packages/matlib/vignettes/linear-equations.html
#another method using outer function https://stackoverflow.com/questions/10199547/plotting-curves-given-by-equations-in-r


A &amp;lt;- matrix(c(-1, 1, 1, 1, 3, 0), 3, 2)
b &amp;lt;- c(5,35, 20)
#showEqn(A, b)

#c( R(A), R(cbind(A,b)) )          # show ranks

#all.equal( R(A), R(cbind(A,b)) )  # consistent?

#plotEqn(A,b, xlim = c(0,60), ylim = c(0,60))

rm(A,b)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# linear program example from 
# http://lpsolve.sourceforge.net/5.5/formulate.htm
# in this script, we don&amp;#39;t solve the linear program but plot it in 2-d space
# for visualization purposes. 



### set up some functions to define the constraints and the profit
# money constraint

#-x_1 + x_2 &amp;lt;= 5;
constraint1 = function(x1){
  x2 = (5 + x1)
  return(x2)
}

# storage constraint

#x_1+3x_2 &amp;lt;= 35; 
constraint2 = function(x1){
  x2 = (35 - x1)/3
  return(x2)
}

# acreage constraint

#x_1 &amp;lt;= 20
#constraint3 = function(x1){
#  x2 = 20 - x1
#  return(x2)
#}

# profit contours - returns barley given wheat and profit. i.e. gives us the information needed to plot a line of (wheat, barley) combinations that yield a given amount of profit

#max z = 2x_1 + 3x_2

profitContour = function(x1Array, z){
  x2 &amp;lt;- numeric(length(x1Array))
  for (i in 0:length(x1)){
    x2[i] = (z - 2*x1[i]) / 3
  }
  return(x2)
}


### set up data frame for plotting. Data frame will put barley in terms of wheat. Wheat will be our x axis, and barley will be our y axis.
x1 = seq(0,20)
# add data for plotting the constraints. I.e. how much barley we can have in each constraint given an amount of wheat.
plotDF = data.frame(x1, constraint1(x1), constraint2(x1))
names(plotDF) = c(&amp;#39;x1&amp;#39;,&amp;#39;con1&amp;#39;,&amp;#39;con2&amp;#39;)
plotDF$zero = rep(0,length(x1))
# add data for plotting the profit contours. I.e. how much barlet do we need to make a certain profit given a certain amount of wheat.
for (z in c(25, 40, 55, 70, 85)){
  x2 &amp;lt;- data.frame(profitContour(x1, z))
  names(x2) = paste(&amp;#39;z&amp;#39;, z, sep=&amp;quot;&amp;quot;)
  plotDF &amp;lt;- cbind(plotDF, x2)
}
#set all negatives to zero, since you can&amp;#39;t have negative x2
plotDF &amp;lt;- replace(plotDF, plotDF&amp;lt;0, 0)


### set up and view the charts
# plot the constraint lines
p0 = ggplot(plotDF, aes(x = x1)) + 
  coord_cartesian(ylim=c(0,25),xlim = c(0,25))+                      
  geom_line(aes(y = con1), colour = &amp;#39;red&amp;#39;, linetype = 2) +
  geom_line(aes(y = con2), colour = &amp;#39;green&amp;#39;, linetype = 2) +
  xlab(&amp;#39;x1&amp;#39;) +
  ylab(&amp;#39;x2&amp;#39;) 



# add an area plot underneath the constraint lines. This is the feasible solution space.
p1 &amp;lt;- p0 +  geom_area(aes(y = pmin(con1,con2)), fill = &amp;#39;gray40&amp;#39;)
# view the constraints and feasible solution space


# add the profit contour lines
p2 &amp;lt;- p1 +                    
  geom_line(aes(y = z25), colour = &amp;#39;blue&amp;#39;, linetype = 1) +
  geom_line(aes(y = z40), colour = &amp;#39;blue&amp;#39;, linetype = 1) +
  geom_line(aes(y = z55), colour = &amp;#39;blue&amp;#39;, linetype = 1) +
  geom_line(aes(y = z70), colour = &amp;#39;blue&amp;#39;, linetype = 1) +
  geom_line(aes(y = z85), colour = &amp;#39;blue&amp;#39;, linetype = 1)
# view the whole chart
plotDF&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    x1 con1      con2 zero       z25        z40       z55      z70      z85
## 1   0    5 11.666667    0 8.3333333 13.3333333 18.333333 23.33333 28.33333
## 2   1    6 11.333333    0 7.6666667 12.6666667 17.666667 22.66667 27.66667
## 3   2    7 11.000000    0 7.0000000 12.0000000 17.000000 22.00000 27.00000
## 4   3    8 10.666667    0 6.3333333 11.3333333 16.333333 21.33333 26.33333
## 5   4    9 10.333333    0 5.6666667 10.6666667 15.666667 20.66667 25.66667
## 6   5   10 10.000000    0 5.0000000 10.0000000 15.000000 20.00000 25.00000
## 7   6   11  9.666667    0 4.3333333  9.3333333 14.333333 19.33333 24.33333
## 8   7   12  9.333333    0 3.6666667  8.6666667 13.666667 18.66667 23.66667
## 9   8   13  9.000000    0 3.0000000  8.0000000 13.000000 18.00000 23.00000
## 10  9   14  8.666667    0 2.3333333  7.3333333 12.333333 17.33333 22.33333
## 11 10   15  8.333333    0 1.6666667  6.6666667 11.666667 16.66667 21.66667
## 12 11   16  8.000000    0 1.0000000  6.0000000 11.000000 16.00000 21.00000
## 13 12   17  7.666667    0 0.3333333  5.3333333 10.333333 15.33333 20.33333
## 14 13   18  7.333333    0 0.0000000  4.6666667  9.666667 14.66667 19.66667
## 15 14   19  7.000000    0 0.0000000  4.0000000  9.000000 14.00000 19.00000
## 16 15   20  6.666667    0 0.0000000  3.3333333  8.333333 13.33333 18.33333
## 17 16   21  6.333333    0 0.0000000  2.6666667  7.666667 12.66667 17.66667
## 18 17   22  6.000000    0 0.0000000  2.0000000  7.000000 12.00000 17.00000
## 19 18   23  5.666667    0 0.0000000  1.3333333  6.333333 11.33333 16.33333
## 20 19   24  5.333333    0 0.0000000  0.6666667  5.666667 10.66667 15.66667
## 21 20   25  5.000000    0 0.0000000  0.0000000  5.000000 10.00000 15.00000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/LP_algorithms_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(x1,x2,p0,p1,p2, constraint1, constraint2, plotDF, profitContour,z )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;primal simplex tableu reformulation
&lt;span class=&#34;math inline&#34;&gt;\(max: z;\: z - 2x_1 - 3x_2 = 0\)&lt;/span&gt;
s.t.
&lt;span class=&#34;math inline&#34;&gt;\(-x_1 + x_2 + x_3 = 5\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1+ 3x_2 + x_4 = 35\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1 + x_5 = 20\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(x_3, x_4, \text{ and } x_5\)&lt;/span&gt; are slack variables. Giving 3 basic variables for 3 equations. The 4th constraint describes how z changes with the decision variables
For less than or equal constraints adding the slack variables define a basic feasible solution which we use to initialize the algorithm (note use &lt;span class=&#34;math inline&#34;&gt;\(x+1\)&lt;/span&gt; as basic variable instead of &lt;span class=&#34;math inline&#34;&gt;\(x_5\)&lt;/span&gt; for iteration reasons)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic(&amp;#39;Simplex&amp;#39;)
initial_tableau &amp;lt;- data.frame(row = c(0,1,2,3), basic = (c(&amp;#39;z&amp;#39;, &amp;#39;x3&amp;#39;, &amp;#39;x4&amp;#39;, &amp;#39;x5&amp;#39;)), z = c(1,0,0,0), x1 = c(-2,-1,1,1), x2 = c(-3,1,3,0), x3 = c(0,1,0,0), x4 = c(0,0,1,0), x5 = c(0,0,0,1),   RHS = c(0,5,35,20), ratio = c(0,0,0,0))

initial_tableau$basic &amp;lt;- as.character(initial_tableau$basic)

nvars &amp;lt;- 5
nrows &amp;lt;- 3



tableau &amp;lt;- initial_tableau

iters &amp;lt;- 1


#loop iterate until you have no negative coefficients in the first row of the tableau

maxiters &amp;lt;- 10
while(iters &amp;lt; maxiters){
  
  
  

#create a and RHS matrixes for easy calculations

ma &amp;lt;- as.matrix(tableau[,4:(4+nvars-1)])


#Run this only if there is a negative reduced cost
if(min(ma[1,]) &amp;lt; 0){
mrhs &amp;lt;- as.matrix(tableau[,(4+nvars)])
print(paste(&amp;#39;iteration:&amp;#39;,iters))
print(tableau)


#use steepest ascent to find the most negative reduced cost and that is the variable that enters the basis (sa) as seen in row 0, caluclate the rations, then determine the pivot row index (pri)
sa &amp;lt;- which.min(ma[1,])


ratios &amp;lt;- mrhs[2:(nrows+1)]/ma[2:(nrows+1),sa]
ratios[ratios&amp;lt;=0] &amp;lt;- 9999
pri &amp;lt;- which.min(ratios)+1





#change pivot row by pivot element (pe) using Gauss Jordan elimination (substition)
#by simply divide the row and rhs by the pe to get a new pivot row (npr) and new rhs (nrhs)
#https://www.coursera.org/lecture/solving-algorithms-discrete-optimization/3-3-1-linear-programming-rzHVE

pe &amp;lt;- ma[pri,sa]
npr &amp;lt;- ma[pri,]/pe

nrhs &amp;lt;- mrhs[pri]/pe

#take that row and muliply by the negative of the pivot variable&amp;#39;s coefficent in that row column and add the result to that row for both the rhs matrix and the A matrix

for(i in 1:(nrows+1)){
  mrhs[i] &amp;lt;- -ma[i,sa]*nrhs+mrhs[i]
  }
mrhs[pri] &amp;lt;- nrhs


for(i in 1:(nrows+1)){
  ma[i,] &amp;lt;- -ma[i,sa]*npr+ma[i,]
  }
ma[pri,] &amp;lt;- npr

#rewrite the new A and RHS matricies to the tableau 

tableau[,4:(4+nvars-1)] &amp;lt;- ma
tableau[,(4+nvars)] &amp;lt;- mrhs
tableau[2:(nrows+1),(4+nvars+1)] &amp;lt;- ratios
print(paste(&amp;#39;pivot row:&amp;#39;,(pri-1)))
print(paste(&amp;#39;new basis:&amp;#39;, sa))
tableau[pri,2] &amp;lt;- paste0(&amp;#39;x&amp;#39;,sa)

iters &amp;lt;- iters + 1
}
else{
  print(paste(&amp;#39;Final Tableau; iteration:&amp;#39;,iters))
  print(tableau[1:(length(tableau)-1)])
  print(paste0(&amp;#39;objective value:&amp;#39;, mrhs[1]))
  for(j in 1:nrows+1){
    print(paste(tableau[j,2], &amp;#39;=&amp;#39;, tableau[j,(4+nvars)]))}
  iters &amp;lt;- maxiters}
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;iteration: 1&amp;quot;
##   row basic z x1 x2 x3 x4 x5 RHS ratio
## 1   0     z 1 -2 -3  0  0  0   0     0
## 2   1    x3 0 -1  1  1  0  0   5     0
## 3   2    x4 0  1  3  0  1  0  35     0
## 4   3    x5 0  1  0  0  0  1  20     0
## [1] &amp;quot;pivot row: 1&amp;quot;
## [1] &amp;quot;new basis: 2&amp;quot;
## [1] &amp;quot;iteration: 2&amp;quot;
##   row basic z x1 x2 x3 x4 x5 RHS    ratio
## 1   0     z 1 -5  0  3  0  0  15  0.00000
## 2   1    x2 0 -1  1  1  0  0   5  5.00000
## 3   2    x4 0  4  0 -3  1  0  20 11.66667
## 4   3    x5 0  1  0  0  0  1  20      Inf
## [1] &amp;quot;pivot row: 2&amp;quot;
## [1] &amp;quot;new basis: 1&amp;quot;
## [1] &amp;quot;iteration: 3&amp;quot;
##   row basic z x1 x2    x3    x4 x5 RHS ratio
## 1   0     z 1  0  0 -0.75  1.25  0  40     0
## 2   1    x2 0  0  1  0.25  0.25  0  10  9999
## 3   2    x1 0  1  0 -0.75  0.25  0   5     5
## 4   3    x5 0  0  0  0.75 -0.25  1  15    20
## [1] &amp;quot;pivot row: 3&amp;quot;
## [1] &amp;quot;new basis: 3&amp;quot;
## [1] &amp;quot;Final Tableau; iteration: 4&amp;quot;
##   row basic z x1 x2 x3         x4         x5 RHS
## 1   0     z 1  0  0  0  1.0000000  1.0000000  55
## 2   1    x2 0  0  1  0  0.3333333 -0.3333333   5
## 3   2    x1 0  1  0  0  0.0000000  1.0000000  20
## 4   3    x3 0  0  0  1 -0.3333333  1.3333333  20
## [1] &amp;quot;objective value:55&amp;quot;
## [1] &amp;quot;x2 = 5&amp;quot;
## [1] &amp;quot;x1 = 20&amp;quot;
## [1] &amp;quot;x3 = 20&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simplex: 0.05 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(pri,sa,npr,iters,maxiters,ma,mrhs,nrhs,nrows,nvars,pe,ratios,i,j)
rm(initial_tableau, tableau)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dual Simplex
The dual of the previous problem is
&lt;span class=&#34;math inline&#34;&gt;\(min 5y_1+35y_2+20y_3\)&lt;/span&gt;
s.t.
&lt;span class=&#34;math inline&#34;&gt;\(-y_1+y_2+y_3 \geq 2\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(y_1+3y_2 \geq 3\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Switching to a max problem and adding slacks yields
&lt;span class=&#34;math inline&#34;&gt;\(z=-5y_1-35y_2-20y_3\)&lt;/span&gt;
s.t.
&lt;span class=&#34;math inline&#34;&gt;\(y_1-y_2-y_3+y_4 = -2\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(-y_1-3y_2+y_5 = -3\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic(&amp;#39;Dual Simplex&amp;#39;)
initial_tableau &amp;lt;- data.frame(row = c(0,1,2), basic = (c(&amp;#39;z&amp;#39;, &amp;#39;y4&amp;#39;, &amp;#39;y5&amp;#39;)), z = c(1,0,0), y1 = c(5,1,-1), y2 = c(35,-1,-3), y3 = c(20,-1,0), y4 = c(0,1,0), y5 = c(0,0,1),   RHS = c(0,-2,-3))

initial_tableau$basic &amp;lt;- as.character(initial_tableau$basic)

nvars &amp;lt;- 5
nrows &amp;lt;- 2



tableau &amp;lt;- initial_tableau

iters &amp;lt;- 1

maxiters &amp;lt;- 10

while(iters &amp;lt; maxiters){
  

#create a and RHS matrixes for easy calculations

ma &amp;lt;- as.matrix(tableau[,4:(4+nvars-1)])

#Check to see if a RHS value is negative
if(min(tableau[2:(nrows+1),(4+nvars)]) &amp;lt; 0){
mrhs &amp;lt;- as.matrix(tableau[,(4+nvars)])
print(paste(&amp;#39;iteration:&amp;#39;,iters))
print(tableau)


#use steepest ascent to find the most negative RHS and that is the pivot row index (pri)
#then caluclate the ratios to determine the entering variable (ev)

pri &amp;lt;- which.min(mrhs[2:(nrows+1),])+1

ratios &amp;lt;- -ma[1,]/ma[pri,]
ratios[ratios&amp;lt;=0] &amp;lt;- 9999
ev &amp;lt;- which.min(ratios)


#identify the new pivot element, do the same matrix operations to make the new pivot row and the new rhs for that row
#change pivot row by pivot element (pe) using Gauss Jordan elimination (substition)
#by simply divide the row and rhs by the pe to get a new pivot row (npr) and new rhs (nrhs)
#https://www.coursera.org/lecture/solving-algorithms-discrete-optimization/3-3-1-linear-programming-rzHVE

pe &amp;lt;- ma[pri,ev]
npr &amp;lt;- ma[pri,]/pe

nrhs &amp;lt;- mrhs[pri]/pe

#Do the matrix operations for the rest of the tableau


#take that row and muliply by the negative of the pivot variable&amp;#39;s coefficent in that row column and add the result to that row for both the rhs matrix and the A matrix

for(i in 1:(nrows+1)){
  mrhs[i] &amp;lt;- -ma[i,ev]*nrhs+mrhs[i]
  }
mrhs[pri] &amp;lt;- nrhs


for(i in 1:(nrows+1)){
  ma[i,] &amp;lt;- -ma[i,ev]*npr+ma[i,]
  }
ma[pri,] &amp;lt;- npr

#rewrite the new A and RHS matricies to the tableau 

tableau[,4:(3+nvars)] &amp;lt;- ma
tableau[,(4+nvars)] &amp;lt;- mrhs
print(paste(&amp;#39;pivot row:&amp;#39;,(pri-1)))
print(paste(&amp;#39;entering variable:&amp;#39;,ev))
tableau[pri,2] &amp;lt;- paste0(&amp;#39;y&amp;#39;,ev)




iters &amp;lt;- iters + 1
}
else{
  print(tableau)
  print(paste(&amp;#39;objective value:&amp;#39;, mrhs[1]))
  for(j in 1:nrows+1){
    print(paste(tableau[j,2], &amp;#39;=&amp;#39;, tableau[j,(4+nvars)]))}
  iters &amp;lt;- maxiters}

}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;iteration: 1&amp;quot;
##   row basic z y1 y2 y3 y4 y5 RHS
## 1   0     z 1  5 35 20  0  0   0
## 2   1    y4 0  1 -1 -1  1  0  -2
## 3   2    y5 0 -1 -3  0  0  1  -3
## [1] &amp;quot;pivot row: 2&amp;quot;
## [1] &amp;quot;entering variable: 1&amp;quot;
## [1] &amp;quot;iteration: 2&amp;quot;
##   row basic z y1 y2 y3 y4 y5 RHS
## 1   0     z 1  0 20 20  0  5 -15
## 2   1    y4 0  0 -4 -1  1  1  -5
## 3   2    y1 0  1  3  0  0 -1   3
## [1] &amp;quot;pivot row: 1&amp;quot;
## [1] &amp;quot;entering variable: 2&amp;quot;
## [1] &amp;quot;iteration: 3&amp;quot;
##   row basic z y1 y2    y3    y4    y5    RHS
## 1   0     z 1  0  0 15.00  5.00 10.00 -40.00
## 2   1    y2 0  0  1  0.25 -0.25 -0.25   1.25
## 3   2    y1 0  1  0 -0.75  0.75 -0.25  -0.75
## [1] &amp;quot;pivot row: 2&amp;quot;
## [1] &amp;quot;entering variable: 3&amp;quot;
##   row basic z         y1 y2 y3 y4         y5 RHS
## 1   0     z 1 20.0000000  0  0 20  5.0000000 -55
## 2   1    y2 0  0.3333333  1  0  0 -0.3333333   1
## 3   2    y3 0 -1.3333333  0  1 -1  0.3333333   1
## [1] &amp;quot;objective value: -55&amp;quot;
## [1] &amp;quot;y2 = 1&amp;quot;
## [1] &amp;quot;y3 = 1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Dual Simplex: 0.03 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(pri,npr,iters,maxiters,ma,mrhs,nrhs,nrows,nvars,pe,ev,ratios,i,j)
rm(initial_tableau, tableau)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interior Point
&lt;a href=&#34;http://fourier.eng.hmc.edu/e176/lectures/ch3/node19.html&#34; class=&#34;uri&#34;&gt;http://fourier.eng.hmc.edu/e176/lectures/ch3/node19.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;KKT (via interior points) vs Simplex
&lt;a href=&#34;https://math.stackexchange.com/questions/3422607/why-would-you-choose-simplex-over-lagrange-kkt-multipliers-methods&#34; class=&#34;uri&#34;&gt;https://math.stackexchange.com/questions/3422607/why-would-you-choose-simplex-over-lagrange-kkt-multipliers-methods&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Standard form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(max: z; z - 2x_1 - 3x_2 = 0\)&lt;/span&gt;
s.t.
&lt;span class=&#34;math inline&#34;&gt;\(-x_1 + x_2 + x_3 = 5\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1+ 3x_2 + x_4 = 35\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1 + x_5 = 20\)&lt;/span&gt;
Idea given A,b,c and intial value of x; find optimal x that minimizes c*x&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic(&amp;#39;Interior Point: Newton Raphson&amp;#39;)
constr1 &amp;lt;- c(-1,1,1,0,0)
constr2 &amp;lt;- c(1,3,0,1,0)
constr3 &amp;lt;- c(1,0,0,0,1)

A &amp;lt;- rbind(constr1,constr2, constr3)

b &amp;lt;- matrix(c(5,35,20),nrow =3)
c &amp;lt;- matrix(c(-2,-3,0,0,0), nrow = 5)
#inital x values (xi) just has to be a feasible solution, but give every x variable a value or there will be numerical instablity problems in the matricies
xi &amp;lt;- matrix(c(1,1,5,31,19), nrow =5)

m &amp;lt;- nrow(A)
n &amp;lt;- ncol(A)

I &amp;lt;- diag(n)
z1 &amp;lt;- matrix(rep(0,n*n), nrow = n)
z2 &amp;lt;- matrix(rep(0,m*m), nrow = m)
z3 &amp;lt;- matrix(rep(0,m*n), nrow = m)
y &amp;lt;- matrix(rep(1,5), nrow = 5)

#The complimentary slackness modifier 1/t eventually goes to 0 as t &amp;gt;&amp;gt;&amp;gt;&amp;gt; inf
t &amp;lt;- 9
#Step size pretty much make it up the higher the more the step changes, but it might be too quick.
#if its too quick it converges on negative values of x which is bad, 
#for an example change this to 0.3 to see a slower convergance and then to 1 to see a divergence
alpha &amp;lt;- .5
#mu*x = 0 in complemntariy slackness condition , mu &amp;gt;0 is dual condition mu correspond to dual variables, 
#using fancy vectors this gives Xd*mu = XM1 = 1/t where t &amp;gt;&amp;gt;&amp;gt;&amp;gt; inf 
x &amp;lt;- xi
mu &amp;lt;- x/t
mu_minus_c &amp;lt;- mu - c
#Gives lagrangian multipliers for constraints
#Solving c+A*lamda-mu = 0 gives initial lambda
lambda &amp;lt;- ginv(t(A))%*%(mu_minus_c)


#combined vector having values of x, lambda, and mu useful when adding the search direction
w &amp;lt;- rbind(x, lambda, mu)


#This is the KKT condition stationarity, at optimality this derivative should  be 0,
#Using the lagrangian cx+lambda*Ax-mu &amp;gt;&amp;gt; c+A*lambda-mu
c_plus_tA &amp;lt;- c+t(A)%*%lambda-mu

#This is the KKT condition primal feasiblity, this should always be 0 Ax-b=0 
A_times_x_minus_b &amp;lt;- A%*%x-b

#This is the modfied complimentary condtion XM1 -1/t = 0 X is the diag(x) and M is diag(mu) 1/t &amp;gt;&amp;gt;&amp;gt; 0 as t gets larger
x_times_mu_minus_y_over_t &amp;lt;- x*mu-y/t

#The right hand side of the search direction iteration given from the Newton-Raphson Method
#Combines the vectors above
B &amp;lt;- rbind(c_plus_tA,A_times_x_minus_b,x_times_mu_minus_y_over_t)

objective &amp;lt;- t(c)%*%x
error &amp;lt;- norm(B,&amp;#39;2&amp;#39;)

iteration_list &amp;lt;- data.frame(&amp;#39;x1&amp;#39; = x[1], &amp;#39;x2&amp;#39; = x[2], &amp;#39;x3&amp;#39; = x[3], &amp;#39;x4&amp;#39; = x[4], &amp;#39;x5&amp;#39; = x[5], &amp;#39;objective&amp;#39; = objective, &amp;#39;error&amp;#39; = error)

#loop



while(error &amp;gt; 10^-7){
t &amp;lt;- t*9

Xd = Diagonal(n = n, x)

Mud = Diagonal(n = n, mu) 


#The left hand side matrix of the search direction iteration, it containtes information from the A, x, and mu vectors and matricies of 1s or 0s to make the math make sense

C &amp;lt;- rbind(cbind(z1,t(A),-I),cbind(A,z2,z3), cbind(Mud,t(z3), Xd))

#The right hand side of the search direction iteration given from the Newton-Raphson Method
#This contains the objective function costs, the RHS values, as well as the A, x, and mu vectors. 
#It also has the complimentary condition represented by t
B &amp;lt;- rbind(c+t(A)%*%lambda-mu,A%*%x-b,x*mu-y/t)


#solving the systems of equations with C and B gives the search direction as you move closer and closer to solving the complimentary condition in the KKT conditions
dw = solve(-C,B)


#update your w vector which is just a list of the x, mu, and lambda vectors using the search direction
w &amp;lt;- w + alpha*dw

x &amp;lt;- w[1:n]

lambda &amp;lt;- w[(n+1):(n+m)]

mu &amp;lt;- w[(n+m+1):length(w)]

#calculate the objective function from the x values and the error. Remember if this satisifies all the KKT conditions then the B vector will be 0.
objective &amp;lt;- t(c)%*%x
error &amp;lt;- norm(B,&amp;#39;2&amp;#39;)
iteration_list &amp;lt;- rbind(iteration_list,c(x,objective,error))

}

toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Interior Point: Newton Raphson: 0.22 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(iteration_list)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          x1       x2        x3        x4        x5 objective     error
## 1  1.000000 1.000000  5.000000 31.000000 19.000000  -5.00000 113.97801
## 2  2.815083 1.900809  5.914274 26.482489 17.184917 -11.33259 114.10755
## 3 10.549002 1.617924 13.931079 19.597227  9.450998 -25.95178  62.76629
## 4 13.970331 2.387418 16.582913 13.867413  6.029669 -35.10292  35.22695
## 5 16.877593 3.136894 18.740699  8.711726  3.122407 -43.16587  19.61963
## 6 18.419517 3.865645 19.553873  4.983549  1.580483 -48.43597  10.66207&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tail(iteration_list)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    x1 x2 x3           x4           x5 objective        error
## 28 20  5 20 1.386952e-06 3.808029e-07       -55 2.878188e-06
## 29 20  5 20 6.934761e-07 1.904014e-07       -55 1.439094e-06
## 30 20  5 20 3.467381e-07 9.520072e-08       -55 7.195471e-07
## 31 20  5 20 1.733690e-07 4.760036e-08       -55 3.597735e-07
## 32 20  5 20 8.668451e-08 2.380018e-08       -55 1.798868e-07
## 33 20  5 20 4.334226e-08 1.190009e-08       -55 8.994339e-08&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(x,lambda,mu,z1,z2,z3,y,xi,Xd,Mud,t,n,I,alpha,b,c,constr1,constr2,constr3,m)
rm(c_plus_tA,mu_minus_c,A_times_x_minus_b,x_times_mu_minus_y_over_t, A,B,C,dw)
rm(iteration_list,objective,error,w)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(max: z = 2x_1 + 3x_2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;s.t.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(-x_1 + x_2 \leq 5\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1+3x_2 \leq 35\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1 \leq 20\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This solver runs all the techniques above in paralel.
The Simplex, Dual Simplex, and 3 versions of the interior point method (barrier method).
This requires 5 cores. Whichever one solves the fastest produces the output.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic(&amp;#39;Gurobi Solver&amp;#39;)
model &amp;lt;- list()
model$A     &amp;lt;- matrix(c(-1,1,
                        1,3,
                        1,0), nrow=3, byrow=T)
model$obj   &amp;lt;- c(2,3)
model$rhs   &amp;lt;- c(5,
                 35,
                 20)
model$sense &amp;lt;- c(&amp;#39;&amp;lt;&amp;#39;,
                 &amp;#39;&amp;lt;&amp;#39;,
                 &amp;#39;&amp;lt;&amp;#39;)
model$modelsense &amp;lt;- &amp;#39;max&amp;#39;
result &amp;lt;- gurobi(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (win64)
## Optimize a model with 3 rows, 2 columns and 5 nonzeros
## Model fingerprint: 0x1b1ba9b3
## Coefficient statistics:
##   Matrix range     [1e+00, 3e+00]
##   Objective range  [2e+00, 3e+00]
##   Bounds range     [0e+00, 0e+00]
##   RHS range        [5e+00, 4e+01]
## Presolve removed 1 rows and 0 columns
## Presolve time: 0.00s
## Presolved: 2 rows, 2 columns, 4 nonzeros
## 
## Iteration    Objective       Primal Inf.    Dual Inf.      Time
##        0    7.0000000e+01   1.875000e+00   0.000000e+00      0s
##        1    5.5000000e+01   0.000000e+00   0.000000e+00      0s
## 
## Solved in 1 iterations and 0.00 seconds
## Optimal objective  5.500000000e+01&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#print(result$objval)
#print(result$x)



# Clear space
rm(model, result)

toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gurobi Solver: 0 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Basics of Simulation</title>
      <link>/post/orie/simulation_basics/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/orie/simulation_basics/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post explores some of the basic concepts of simulation.
I mostly explore these concepts using basic probablity and the built in distribution functions.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Ideas from Probablity Course https://www.probabilitycourse.com/chapter13/chapter13.php


set.seed(123)
p &amp;lt;- 0.5
n &amp;lt;- 1000
U &amp;lt;- runif(n)

toss &amp;lt;- as.integer(U &amp;lt; p)

#cumalative number of heads 
a &amp;lt;- numeric(n+1)
#running average of heads
avg &amp;lt;- numeric(n)

for(i in 2:n+1){
  a[i] &amp;lt;- a[i-1] + toss[i-1]
  avg[i-1] &amp;lt;- a[i]/(i-1)
}

plot(1:n, avg, type = &amp;quot;l&amp;quot;, lwd = 5, col = &amp;quot;blue&amp;quot;, ylab = &amp;quot;ProportionofHeads&amp;quot;,
xlab = &amp;quot;CoinTossNumber&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(p,n,U,toss,a,avg, i)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
p &amp;lt;- 0.2
n &amp;lt;- 1000
U &amp;lt;- runif(n)
#The function U &amp;lt; p creates Bernouli Random variables with probablity p, 1 if U &amp;lt; p 0 otherwise
#the sum of Bernouli variables is a Binomial of (n,p) so X is a Binomial(1000,0.2)

X &amp;lt;- sum(as.integer(U &amp;lt; p))
X&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 198&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#The built in function for binomial (number of observations, number of trials, probablity)
rbinom(1,n,p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 196&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Arbitrary Distribution
#P(X =1) = 0.35, P(X = 2) = 0.15, P(X=3) = 0.4, P(X=4) = 0.1
#P(X=xi) = P(U element Ai) = pi
P &amp;lt;- c(0.35,0.5,0.9,1)
X &amp;lt;- c(1,2,3,4)
i &amp;lt;- 1
r &amp;lt;- runif(1)

while(r &amp;gt; P[i]){
  i &amp;lt;- i + 1
}

X[i]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Create RV with density f(x) = 2.5*x*sqrt(x) = x^5/2
#Using inverse X^5/2 = U &amp;gt;&amp;gt; X = U^2/5

U &amp;lt;- runif(1)
X &amp;lt;- U^(2/5)
print(paste(&amp;#39;Distrubution with density f(x) = X^(5/2):&amp;#39;,X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Distrubution with density f(x) = X^(5/2): 0.938571171721709&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Generate RV with density function Beta(2,4), g(x) =1 0&amp;lt;x&amp;lt;1
#f(x) = 20x(1-x)^3, g(x) = 1, f(x)/g(x) = 20x(1-x)^3
#Find smallest c such that f(x)/g(x) &amp;lt;= c
#Using differention d(f(x)/g(x))/dx &amp;gt;&amp;gt;&amp;gt; x = 1/4 &amp;gt;&amp;gt;&amp;gt; f(x)/g(x) &amp;lt;= 135/64 &amp;gt;&amp;gt;&amp;gt; f(x)/(c*g(x)) = 256x(1-x)^3

#This code keeps looping until U2 (which is f(x)/c*g(x)) dips below its bound. Hence it rejects higher values

n &amp;lt;- 1
rejects &amp;lt;- 0
while(n == 1){
  U1 &amp;lt;- runif(1)
  U2 &amp;lt;- runif(1)
  rejects &amp;lt;- rejects + 1
  if(U2 &amp;lt;= 256/27*U1*(1-U1)^3){
    X &amp;lt;- U1
    n &amp;lt;- 0
  }
}

print(paste(&amp;#39;Total Number of Rejections:&amp;#39;, rejects))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Total Number of Rejections: 3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;Beta RV:&amp;#39;, X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Beta RV: 0.0656281118281186&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Beta:&amp;#39;, rbeta(1,2,4, ncp = 0)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Beta: 0.281731495984851&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(i,n,p,P,r,U,X, rejects)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Transformations of Uniform Distribution to other distrubtions

set.seed(123)
#Inverse Transformation to Exponential
#F(x) = 1 - e^-x
#X = F-1(U) = - ln(1-U) &amp;gt;&amp;gt;&amp;gt; - ln(U)

lambda &amp;lt;- 1
U &amp;lt;- runif(1)
X &amp;lt;- (-1/lambda)*log(U)
print(paste(&amp;#39;Exponential RV:&amp;#39;,X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Exponential RV: 1.24626281987372&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Exponential RV:&amp;#39;,rexp(1,lambda)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Exponential RV: 0.576610270887613&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Using sums to create Gamma(n,lambda) from exp(lambda) Gamma(n,lambda) = sum_n(Exponential(lambda))
n &amp;lt;- 20
X &amp;lt;- (-1/lambda)*sum(log(U))
print(paste(&amp;#39;Gamma RV:&amp;#39;,X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Gamma RV: 1.24626281987372&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Gamma RV:&amp;#39;, rgamma(1,n,lambda)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Gamma RV: 18.4968091472022&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(n,lambda,X)

#Create Poisson Distribution which is the number of exponential arrivals in a given time period
#Ti = 1/lambdaln(Ui)

set.seed(123)

lambda &amp;lt;- 2
i &amp;lt;- 0
U &amp;lt;- runif(1)
Y &amp;lt;- -1/lambda*log(U)
sum &amp;lt;- Y
while(sum &amp;lt; 1){
  U &amp;lt;- runif(1)
  Y &amp;lt;- -1/lambda*log(U)
  sum &amp;lt;- sum + Y
  i &amp;lt;- i+1
}
X &amp;lt;- i
print(paste(&amp;#39;Poisson RV:&amp;#39;,X))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Poisson RV: 2&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Poisson RV:&amp;#39;, rpois(1,lambda)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Poisson RV: 4&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Creating Normals with the Box Mueller Method (inefficient because of the sqrt, cos, and sine functions)
#Z1 = sqrt(-2ln(U1)cos(2*pi*U2))
#Z2 = sqrt(-2ln(U1)sin(2*pi*U2))

n &amp;lt;- 5000
U1 &amp;lt;- runif(n)
U2 &amp;lt;- runif(n)

Z1 &amp;lt;- sqrt(-2*log(U1))*cos(2*pi*U2)
Z2 &amp;lt;- sqrt(-2*log(U1))*sin(2*pi*U2)

#Created Via R Function
Z3 &amp;lt;- rnorm(5000)
hist(Z1,col = &amp;#39;wheat&amp;#39;, label = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(Z3,col = &amp;#39;wheat&amp;#39;, label = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Geometric Function - Loops Bernoulis until first success
# K &amp;lt;- number of failures plust 1 success 

K &amp;lt;- 1
p &amp;lt;- 0.2

while(runif(1) &amp;gt; p){
  K &amp;lt;- K +1
}
print(paste(&amp;#39;Geometric RV:&amp;#39;, K))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Geometric RV: 8&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Geometric RV:&amp;#39;,rgeom(1,p)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Geometric RV: 1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Negative Binomial Method - Number of Geometric trials needed to get r success NegBin(1,r,p)

K &amp;lt;- 1
p &amp;lt;- 0.2
r &amp;lt;- 2
success &amp;lt;- 0

while(success &amp;lt; r){
  if(runif(1) &amp;gt; p){
    K &amp;lt;- K + 1
    #failure
  }else{
    success &amp;lt;- success + 1
  }
}

print(paste(&amp;#39;Negative Binomial RV:&amp;#39;, K+r-1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Negative Binomial RV: 6&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste(&amp;#39;R produced Negative Binomial:&amp;#39;, rnbinom(1,r,p)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;R produced Negative Binomial: 6&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rt(1,1,1) #number of variables, df, ncp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.06314223&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Typical metrics for Queueing that can be extended to all types of simulations:&lt;/p&gt;
&lt;p&gt; L: average number of jobs in the system
 W: average time spent in the system (cycle time)
 Q: average number of jobs in queue
 d: average time in queue
 system utilization
 system throughput
 distribution of waiting time
 distribution of system size
 distribution of queue size&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#M/M/1 Queue Simulation

#Source for this code http://web02.gonzaga.edu/faculty/burchn/R_files/Miscellaneous/queueing_theory_MM1.html

#variable saying how many arrivals per time period
lambda = .3
#saying the average departures per time period
mu = 1
#How long the simulation runs note not a number of events
time = 500
t = 0
#the length of a queue after a number of events. Aka Q_history[500] = 5 says the queue is 5 people long after 500 events it isn&amp;#39;t a sum.
#It updates after for n during event n
Q_hist = 0
#Think this is the sum of all the queues 
s = 0
#exponential distb with mean 1/rate T1 is time uuntil next event rate lamba + mu if there is something in queue otherwise just an arrival
T1 = rexp(1,rate=lambda)
#Initializing parameter
Q = 1
#Time until first event is T1
event_times = T1
#The time of the first event is T1
t = T1
#Same reasoning
num_event = 1

i &amp;lt;- 1
sims &amp;lt;- 10
#Busy time simulation 1:10
B &amp;lt;- c(1:10)
BT &amp;lt;- c(1:10)
#Average length of queue for simulation 1:10
L &amp;lt;- c(1:10)
#Average time customer spends in line
W &amp;lt;- c(1:10)

while (i &amp;lt;= sims){
  print(i)
  while (t&amp;lt;time) {
  num_event = num_event+1
  if(Q&amp;gt;0) {
    # we checked to make sure queue was not empty
    #odds someone arrives or leaves the queue
    T1 = rexp(1,rate=lambda+mu)
    #use p as random number to determine if next even is an arrival or a departure
    p = runif(1,0,1)
    Q_hist[num_event] = Q
    #if p is less than lambda/(lamda+mu) it is an arrival otherwise it is a departure
    Q = ifelse(p&amp;lt;lambda/(lambda+mu),Q+1,Q-1)
    } else {
      # here, the queue was empty, so only arrivals are possible
      T1 = rexp(1,rate=lambda)
      Q_hist[num_event] = Q
      Q = 1
          }
  #new time is the original t plus the time to the next event
  t = t+T1
  #A vector that shows how long it is to the next event
  event_times[num_event] = T1
  s = s+T1*Q_hist[num_event]
  }
#Time system is busy
BT[i] &amp;lt;- sum(event_times)-sum(event_times[which(Q_hist %in% 0)])
num_cust &amp;lt;- lambda*time
B[i] &amp;lt;- BT[i]/length(which(Q_hist %in% 0))

#Average queue length in the system
L[i] &amp;lt;- s/t

#Average time customer spends in line
W[i] &amp;lt;- L[i] / lambda

time = 500
t = 0
Q_hist = 0
s = 0
T1 = rexp(1,rate=lambda)
Q = 1
event_times = T1
t = T1
num_event = 1

i &amp;lt;- i + 1
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1
## [1] 2
## [1] 3
## [1] 4
## [1] 5
## [1] 6
## [1] 7
## [1] 8
## [1] 9
## [1] 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#rho/(1-rho) [.4285, 9, -11]
avg_num &amp;lt;- mean(L) 

#rho/(1-rho)^2 [.6122, 90, 110]
variance &amp;lt;- var(L) 

Sd2 &amp;lt;- sum((L-avg_num)^2 / (sims - 1))

# 1/(mu-lambda) [1.42, 10, -10]
busy_time &amp;lt;- mean(B)

avg_num&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4417826&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;variance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.003876663&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Sd2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.003876663&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;busy_time&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.452299&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A quick Monte Carlo Simulation to estimate the value of the integral &lt;span class=&#34;math inline&#34;&gt;\(\int_{0.01}^1x^{-0.5}\,dx\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;#&lt;a href=&#34;https://stackoverflow.com/questions/22001977/monte-carlo-integration-in-r-getting-the-wrong-answer-using-hit-or-miss&#34; class=&#34;uri&#34;&gt;https://stackoverflow.com/questions/22001977/monte-carlo-integration-in-r-getting-the-wrong-answer-using-hit-or-miss&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s &amp;lt;- NULL

m &amp;lt;- 1000
a &amp;lt;- 0.01
b &amp;lt;- 1
set.seed(5)
x &amp;lt;- runif(m,a,b)
y &amp;lt;- 10*runif(m,0,1)

for (i in 1:m){
    if(y[i]&amp;lt;(x[i]^(-0.5))){
        s[i] &amp;lt;- 1
    }
    else{
        s[i] &amp;lt;-0
    }
}

nn&amp;lt;- sum(s)*(b-a)/m*10 #note that the addition of the area of the rectangle
print(nn)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.683&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(x,y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f2 &amp;lt;- function(x)   sqrt(1-x^2)

s &amp;lt;- seq(-1 , 1 ,by=0.001)
plot(s,f2(s))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Simulation_basics_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get the max value of function within the range
c &amp;lt;- ceiling(max(f2(s)))
# [1] 1

n &amp;lt;- 1000000
a &amp;lt;- -1
b &amp;lt;- 1

set.seed(5)
x &amp;lt;- runif(n,a,b)
y &amp;lt;- c*runif(n,0,1)
R &amp;lt;- sum(y &amp;lt; f2(x))/n

(b-a)*c*R&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.57063&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#[1] 1.57063 # multiply it by 2 to get full area

pi/2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.570796&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#[1] 1.570796&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sim HW2 does a good job showing confidence intervals and convergence of normals, exponentials, and lognormals.&lt;/p&gt;
&lt;p&gt;Sim HW4 shows how to run 5 tests for independance (Runs, Autocorrelation), uniformity (Chi-Squared and KS), or both (Serial)&lt;/p&gt;
&lt;p&gt;Sim HW5 shows how to generate RVs recurseively until they drop below a certain variance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#CLT Basics https://stats.stackexchange.com/questions/22557/central-limit-theorem-versus-law-of-large-numbers
#https://www.probabilitycourse.com/chapter7/7_2_4_convergence_in_distribution.php
#https://www.analyticsvidhya.com/blog/2019/05/statistics-101-introduction-central-limit-theorem/

#LLN (WLLN - convergence in prob) (SLLN - almost sure convergence) (CLT - convergence in distribution)
#WLLN https://www.probabilitycourse.com/chapter7/7_2_5_convergence_in_probability.php
#SLLN and continous mapping theroem https://www.probabilitycourse.com/chapter7/7_2_7_almost_sure_convergence.php

#Probability Basics
#https://daviddalpiaz.github.io/r4sl/probability-review.html&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Statistic Basics and Linear Regression</title>
      <link>/post/orie/stat_basics/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/orie/stat_basics/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post explores some of the basic concepts of statistics.
I mostly explore these concepts using linear regression.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#http://r-statistics.co/Linear-Regression.html
#https://www.statmethods.net/stats/regression.html
#http://r-statistics.co/Statistical-Tests-in-R.html
#http://www.sthda.com/english/articles/40-regression-analysis/166-predict-in-r-model-predictions-and-confidence-intervals/


#Dr. Sager Utexas datasets

data &amp;lt;- read.table(&amp;#39;AustinApartmentRents1.txt&amp;#39;, header = TRUE)
summary(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Rent             Area     
##  Min.   : 399.0   Min.   : 474  
##  1st Qu.: 470.0   1st Qu.: 666  
##  Median : 535.0   Median : 755  
##  Mean   : 572.3   Mean   : 816  
##  3rd Qu.: 638.8   3rd Qu.: 925  
##  Max.   :1050.0   Max.   :1864&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(data$Rent, data$Area)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8740597&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- lm(Rent ~ Area, data = data)

summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Rent ~ Area, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -154.659  -50.882    8.189   54.874  148.207 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 160.18706   31.36081   5.108  3.8e-06 ***
## Area          0.50497    0.03685  13.702  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 68.86 on 58 degrees of freedom
## Multiple R-squared:  0.764,  Adjusted R-squared:  0.7599 
## F-statistic: 187.7 on 1 and 58 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test.Areas &amp;lt;- data.frame(Area = c (500,1000))
predict(model, newdata = test.Areas)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2 
## 412.6713 665.1556&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data1 &amp;lt;- read.table(&amp;#39;AustinApartmentRents2.txt&amp;#39;, header = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#A convient tool to see a lot of the initial data exploration
#https://towardsdatascience.com/simple-fast-exploratory-data-analysis-in-r-with-dataexplorer-package-e055348d9619

library(DataExplorer)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;DataExplorer&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_str(data1)
plot_missing(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_histogram(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_density(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_correlation(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_bar(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-2-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#create_report(data1) #This creates an HTML report of all the above information and more&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Confidence intervals around indivudual values
pred.int &amp;lt;- predict(model, interval = &amp;#39;prediction&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in predict.lm(model, interval = &amp;quot;prediction&amp;quot;): predictions on current data refer to _future_ responses&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Confidence intervals around means
pred.conf &amp;lt;- predict(model, interval = &amp;#39;confidence&amp;#39;)

cbind(data,pred.int,pred.conf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Rent Area       fit      lwr       upr       fit       lwr       upr
## 1   519  725  526.2893 387.1539  665.4247  526.2893  507.2700  545.3085
## 2   765  995  662.6308 523.0320  802.2296  662.6308  640.4747  684.7868
## 3   475  481  403.0769 261.9228  544.2310  403.0769  372.6213  433.5326
## 4   575  925  627.2830 488.0776  766.4884  627.2830  607.7583  646.8077
## 5   415  600  463.1682 323.2840  603.0524  463.1682  439.2801  487.0563
## 6   530  668  497.5061 358.1044  636.9078  497.5061  476.6278  518.3843
## 7   580  725  526.2893 387.1539  665.4247  526.2893  507.2700  545.3085
## 8   995 1421  877.7474 731.7844 1023.7104  877.7474  829.7031  925.7917
## 9   565  672  499.5259 360.1470  638.9048  499.5259  478.8005  520.2514
## 10  620 1025  677.7799 537.9544  817.6053  677.7799  654.2379  701.3218
## 11  450  781  554.5675 415.5703  693.5648  554.5675  536.5869  572.5481
## 12  520  800  564.1619 425.1837  703.1402  564.1619  546.3289  581.9950
## 13  495  870  599.5097 460.4795  738.5399  599.5097  581.2764  617.7431
## 14  420  700  513.6651 374.4284  652.9017  513.6651  493.9190  533.4112
## 15  575  800  564.1619 425.1837  703.1402  564.1619  546.3289  581.9950
## 16  425  620  473.2676 333.5438  612.9913  473.2676  450.3375  496.1977
## 17  770 1040  685.3544 545.4026  825.3061  685.3544  661.0735  709.6352
## 18  445  520  422.7707 282.0919  563.4495  422.7707  394.5998  450.9416
## 19  510  880  604.5594 465.5062  743.6127  604.5594  586.1509  622.9679
## 20  635  832  580.3209 441.3427  719.2991  580.3209  562.4884  598.1535
## 21  470  545  435.3949 294.9906  575.7993  435.3949  408.6285  462.1614
## 22  700  921  625.2631 486.0744  764.4518  625.2631  605.8580  644.6682
## 23  450  577  451.5539 311.4663  591.6416  451.5539  426.5018  476.6060
## 24  785 1080  705.5531 565.2224  845.8838  705.5531  679.1757  731.9306
## 25  485  710  518.7147 379.5215  657.9080  518.7147  499.2771  538.1524
## 26  415  605  465.6930 325.8504  605.5357  465.6930  442.0494  489.3367
## 27  399  680  503.5657 364.2305  642.9008  503.5657  483.1366  523.9948
## 28  585  730  528.8141 389.6960  667.9322  528.8141  509.9220  547.7063
## 29  525  687  507.1005 367.8016  646.3994  507.1005  486.9201  527.2809
## 30  495  703  515.1800 375.9568  654.4032  515.1800  495.5288  534.8311
## 31  505  672  499.5259 360.1470  638.9048  499.5259  478.8005  520.2514
## 32  445  660  493.4663 354.0171  632.9155  493.4663  472.2734  514.6593
## 33  565  755  541.4383 402.3922  680.4845  541.4383  523.0835  559.7931
## 34  650  810  569.2116 430.2377  708.1855  569.2116  551.4123  587.0109
## 35  515  611  468.7229 328.9288  608.5169  468.7229  445.3683  492.0774
## 36  470  705  516.1899 376.9755  655.4044  516.1899  496.6009  535.7789
## 37  470  564  444.9893 304.7778  585.2009  444.9893  419.2531  470.7255
## 38  700 1250  791.3978 648.7851  934.0105  791.3978  754.7720  828.0235
## 39  455  512  418.7310 277.9593  559.5026  418.7310  390.1001  447.3618
## 40  550  630  478.3173 338.6680  617.9666  478.3173  455.8452  500.7893
## 41  625  850  589.4103 450.4146  728.4061  589.4103  571.4413  607.3794
## 42  745 1156  743.9307 602.7129  885.1486  743.9307  713.1810  774.6805
## 43  540  932  630.8178 491.5816  770.0540  630.8178  611.0749  650.5607
## 44  650  755  541.4383 402.3922  680.4845  541.4383  523.0835  559.7931
## 45  595 1093  712.1177 571.6507  852.5847  712.1177  685.0246  739.2108
## 46  470  751  539.4185 400.3624  678.4745  539.4185  520.9890  557.8479
## 47  480  608  467.2080 327.3898  607.0261  467.2080  443.7095  490.7064
## 48  460  900  614.6588 475.5477  753.7699  614.6588  595.8181  633.4994
## 49  600  860  594.4600 455.4490  733.4711  594.4600  576.3734  612.5467
## 50  575  925  627.2830 488.0776  766.4884  627.2830  607.7583  646.8077
## 51  659  944  636.8774 497.5840  776.1708  636.8774  616.7351  657.0197
## 52  650  940  634.8575 495.5838  774.1312  634.8575  614.8518  654.8632
## 53  750 1048  689.3941 549.3715  829.4168  689.3941  664.7079  714.0803
## 54  455  474  399.5422 258.2967  540.7876  399.5422  368.6660  430.4184
## 55  430  700  513.6651 374.4284  652.9017  513.6651  493.9190  533.4112
## 56  605  921  625.2631 486.0744  764.4518  625.2631  605.8580  644.6682
## 57  929 1229  780.7934 638.5205  923.0664  780.7934  745.5138  816.0731
## 58  695  896  612.6389 473.5406  751.7372  612.6389  593.8932  631.3846
## 59  455  630  478.3173 338.6680  617.9666  478.3173  455.8452  500.7893
## 60 1050 1864 1101.4485 942.4198 1260.4772 1101.4485 1022.1188 1180.7782&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 2. Regression line + confidence intervals
library(&amp;quot;ggplot2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;ggplot2&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mydata &amp;lt;- cbind(data, pred.int)
p &amp;lt;- ggplot(mydata, aes(Area, Rent)) +
  geom_point() +
  stat_smooth(method = lm)
# 3. Add prediction intervals
p + geom_line(aes(y = lwr), color = &amp;quot;red&amp;quot;, linetype = &amp;quot;dashed&amp;quot;)+
    geom_line(aes(y = upr), color = &amp;quot;red&amp;quot;, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#T Test for samples
library(dplyr)

sample1 &amp;lt;- sample_n(data,40)

model1 &amp;lt;- lm(Rent ~ Area, data = data)

p1 &amp;lt;- predict(model1, interval = &amp;#39;confidence&amp;#39;, level = 0.95)

summary(p1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       fit              lwr              upr        
##  Min.   : 399.5   Min.   : 368.7   Min.   : 430.4  
##  1st Qu.: 496.5   1st Qu.: 475.5   1st Qu.: 517.5  
##  Median : 541.4   Median : 523.1   Median : 559.8  
##  Mean   : 572.3   Mean   : 548.8   Mean   : 595.7  
##  3rd Qu.: 627.3   3rd Qu.: 607.8   3rd Qu.: 646.8  
##  Max.   :1101.4   Max.   :1022.1   Max.   :1180.8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(p1, mu = 550)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  One Sample t-test
## 
## data:  p1
## t = 2.4118, df = 179, p-value = 0.01688
## alternative hypothesis: true mean is not equal to 550
## 95 percent confidence interval:
##  554.0485 590.4849
## sample estimates:
## mean of x 
##  572.2667&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#MultiVariable Linear Regression


summary(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Rent             Area         Bedrooms       Bathrooms   
##  Min.   : 399.0   Min.   : 474   Min.   :1.000   Min.   :1.00  
##  1st Qu.: 470.0   1st Qu.: 666   1st Qu.:1.000   1st Qu.:1.00  
##  Median : 535.0   Median : 755   Median :1.000   Median :1.00  
##  Mean   : 572.3   Mean   : 816   Mean   :1.517   Mean   :1.25  
##  3rd Qu.: 638.8   3rd Qu.: 925   3rd Qu.:2.000   3rd Qu.:1.25  
##  Max.   :1050.0   Max.   :1864   Max.   :5.000   Max.   :2.00  
##     Security         Parking          Distance         Shuttle      
##  Min.   :0.0000   Min.   :0.0000   Min.   : 1.100   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 5.000   1st Qu.:1.0000  
##  Median :0.0000   Median :0.0000   Median : 6.000   Median :1.0000  
##  Mean   :0.1667   Mean   :0.1333   Mean   : 5.935   Mean   :0.8667  
##  3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.: 7.000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :10.500   Max.   :1.0000  
##       Age       
##  Min.   : 1.00  
##  1st Qu.:10.00  
##  Median :16.50  
##  Mean   :16.33  
##  3rd Qu.:22.25  
##  Max.   :32.00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model2 &amp;lt;- lm(Rent ~ Area + Bathrooms, data = data1)
summary(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Rent ~ Area + Bathrooms, data = data1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -152.02  -45.45   10.38   39.91  129.28 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 143.66927   29.51345   4.868 9.31e-06 ***
## Area          0.38746    0.04982   7.777 1.61e-10 ***
## Bathrooms    89.92902   27.75071   3.241  0.00199 ** 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 63.83 on 57 degrees of freedom
## Multiple R-squared:  0.8007, Adjusted R-squared:  0.7937 
## F-statistic: 114.5 on 2 and 57 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test.bathrooms &amp;lt;- data.frame(Area = c(500,1000), Bathrooms = c(1,2))

p2a &amp;lt;- predict(model2, newdata = test.bathrooms, interval =  &amp;#39;confidence&amp;#39;)


p2 &amp;lt;- as.data.frame(predict(model2, interval = &amp;#39;confidence&amp;#39;, level = 0.95))

cbind(p2, data1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          fit      lwr       upr Rent Area Bedrooms Bathrooms Security Parking
## 1   514.5062 495.4259  533.5866  519  725        1         1        0       0
## 2   709.0493 673.7669  744.3316  765  995        2         2        0       0
## 3   419.9662 389.8581  450.0743  475  481        1         1        0       0
## 4   681.9271 643.6132  720.2411  575  925        2         2        0       1
## 5   466.0738 443.8498  488.2979  415  600        1         1        0       0
## 6   492.4211 472.8074  512.0348  530  668        1         1        0       0
## 7   514.5062 495.4259  533.5866  580  725        1         1        0       0
## 8   874.1069 829.4987  918.7151  995 1421        2         2        0       1
## 9   493.9709 474.4481  513.4937  565  672        1         1        0       0
## 10  630.7440 594.3939  667.0941  620 1025        2         1        1       0
## 11  536.2040 516.0356  556.3724  450  781        1         1        1       0
## 12  543.5657 522.6986  564.4328  520  800        2         1        0       0
## 13  570.6878 546.1304  595.2452  495  870        2         1        0       0
## 14  504.8198 485.7109  523.9287  420  700        1         1        0       0
## 15  543.5657 522.6986  564.4328  575  800        1         1        0       0
## 16  473.8230 452.5572  495.0888  425  620        1         1        0       0
## 17  726.4849 692.5303  760.4395  770 1040        2         2        0       1
## 18  435.0771 407.8700  462.2843  445  520        1         1        0       0
## 19  574.5624 549.3637  599.7611  510  880        2         1        0       1
## 20  555.9644 533.6045  578.3243  635  832        1         1        0       0
## 21  444.7636 419.2769  470.2502  470  545        1         1        0       0
## 22  680.3773 641.8590  718.8955  700  921        2         2        0       0
## 23  457.1623 433.6744  480.6501  450  577        1         1        0       0
## 24  741.9833 708.7412  775.2254  785 1080        2         2        0       0
## 25  508.6944 489.6360  527.7527  485  710        1         1        0       0
## 26  468.0111 446.0397  489.9826  415  605        1         1        0       0
## 27  497.0706 477.7062  516.4349  399  680        1         1        0       1
## 28  516.4435 497.3298  535.5573  585  730        2         1        0       0
## 29  499.7828 480.5310  519.0346  525  687        1         1        0       0
## 30  505.9821 486.8939  525.0704  495  703        1         1        0       0
## 31  493.9709 474.4481  513.4937  505  672        1         1        1       0
## 32  489.3214 469.5030  509.1398  445  660        1         1        0       0
## 33  526.1300 506.6576  545.6024  565  755        2         1        0       0
## 34  547.4403 526.1468  568.7337  650  810        2         1        0       0
## 35  470.3359 448.6563  492.0154  515  611        1         1        0       0
## 36  506.7571 487.6799  525.8342  470  705        1         1        0       0
## 37  452.1253 427.8562  476.3944  470  564        1         1        0       0
## 38  807.8514 772.3992  843.3035  700 1250        3         2        0       1
## 39  431.9774 404.1949  459.7599  455  512        1         1        1       0
## 40  477.6976 456.8558  498.5395  550  630        1         1        0       0
## 41  562.9387 539.5887  586.2886  625  850        2         1        1       0
## 42  771.4302 738.2367  804.6237  745 1156        3         2        0       0
## 43  594.7103 565.8488  623.5718  540  932        2         1        0       0
## 44  526.1300 506.6576  545.6024  650  755        1         1        1       1
## 45  747.0203 713.9093  780.1312  595 1093        2         2        1       0
## 46  524.5802 505.1862  543.9741  470  751        1         1        1       0
## 47  469.1735 447.3496  490.9974  480  608        1         1        0       0
## 48  582.3116 555.7642  608.8590  460  900        1         1        0       1
## 49  566.8132 542.8728  590.7537  600  860        2         1        0       0
## 50  591.9981 563.6574  620.3388  575  925        2         1        0       0
## 51  689.2888 651.9023  726.6754  659  944        2         2        0       0
## 52  687.7390 650.1632  725.3148  650  940        2         2        0       0
## 53  729.5846 695.8090  763.3602  750 1048        2         2        0       0
## 54  417.2540 386.6020  447.9060  455  474        1         1        0       0
## 55  504.8198 485.7109  523.9287  430  700        1         1        0       0
## 56  590.4483 562.4017  618.4949  605  921        1         1        0       0
## 57  799.7147 764.9734  834.4561  929 1229        2         2        1       0
## 58  670.6908 630.8290  710.5526  695  896        2         2        0       0
## 59  477.6976 456.8558  498.5395  455  630        1         1        1       0
## 60 1045.7513 964.5360 1126.9667 1050 1864        5         2        0       0
##    Distance Shuttle Age
## 1      10.5       1   9
## 2       6.5       1  17
## 3       6.5       1  17
## 4       4.0       1   9
## 5       5.0       1  30
## 6       6.5       1  19
## 7       7.0       1  17
## 8       6.5       1  16
## 9       7.0       1  17
## 10      5.0       1   3
## 11      5.5       1   3
## 12      6.0       1  20
## 13      5.0       1  27
## 14      6.0       1  22
## 15      7.0       1  10
## 16      8.0       0  27
## 17      6.5       1  16
## 18      3.0       1  12
## 19      7.0       0  25
## 20      6.0       1  13
## 21      6.5       1   9
## 22      3.0       1  26
## 23      8.0       1  18
## 24      5.0       1  10
## 25      6.0       1  25
## 26      6.0       1  22
## 27      7.0       0  25
## 28      6.5       1  19
## 29      7.0       1  15
## 30      6.5       1  14
## 31      6.5       1   9
## 32      6.0       1  25
## 33      3.0       1  12
## 34      2.0       1  32
## 35      6.5       1  17
## 36      7.5       0  13
## 37      5.0       1  10
## 38      4.0       1   9
## 39     10.0       0  10
## 40      2.0       1  32
## 41      7.0       1   1
## 42      7.5       0  13
## 43      6.0       1  22
## 44      1.1       1  26
## 45      5.5       1   3
## 46      5.0       1   3
## 47      6.0       1  15
## 48      4.0       1   9
## 49      6.0       1  25
## 50      6.0       1  23
## 51      7.0       1  25
## 52      8.0       0  27
## 53      7.0       1   3
## 54      5.0       1  10
## 55      6.0       1  20
## 56      7.5       0  13
## 57      5.0       1  11
## 58      6.5       1  19
## 59      5.5       1   9
## 60      6.0       1  22&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        fit      lwr      upr
## 1 427.3279 398.6624 455.9935
## 2 710.9866 675.8776 746.0955&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model3 &amp;lt;- lm(Rent ~ Area + Bathrooms + Security + Parking + Distance, data = data1)
summary(model3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Rent ~ Area + Bathrooms + Security + Parking + Distance, 
##     data = data1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -163.199  -37.278    4.548   38.345  149.276 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 167.45045   43.12346   3.883 0.000283 ***
## Area          0.39647    0.05084   7.798 2.09e-10 ***
## Bathrooms    92.60040   28.01804   3.305 0.001691 ** 
## Security     -0.67875   22.42818  -0.030 0.975969    
## Parking     -38.26531   25.89638  -1.478 0.145316    
## Distance     -4.92937    5.05014  -0.976 0.333374    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 64.02 on 54 degrees of freedom
## Multiple R-squared:   0.81,  Adjusted R-squared:  0.7925 
## F-statistic: 46.06 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model4 &amp;lt;- lm(Rent ~ Distance + Parking + Security + Bathrooms + Area, data = data1)
summary(model4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Rent ~ Distance + Parking + Security + Bathrooms + 
##     Area, data = data1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -163.199  -37.278    4.548   38.345  149.276 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 167.45045   43.12346   3.883 0.000283 ***
## Distance     -4.92937    5.05014  -0.976 0.333374    
## Parking     -38.26531   25.89638  -1.478 0.145316    
## Security     -0.67875   22.42818  -0.030 0.975969    
## Bathrooms    92.60040   28.01804   3.305 0.001691 ** 
## Area          0.39647    0.05084   7.798 2.09e-10 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 64.02 on 54 degrees of freedom
## Multiple R-squared:   0.81,  Adjusted R-squared:  0.7925 
## F-statistic: 46.06 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Multicollinearity
#http://www.sthda.com/english/articles/39-regression-model-diagnostics/160-multicollinearity-essentials-and-vif-in-r/
library(caret)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;caret&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)

y &amp;lt;- runif(50,min=0, max =100)
x1 &amp;lt;- runif(50, min = 0, max = 100)
x2 &amp;lt;- runif(50, min = 0, max = 100)
z1 &amp;lt;- x1+x2
z2 &amp;lt;- x1 + x2 + 0.005*runif(50,min=0, max =100)



list &amp;lt;- cbind(y,x1,x2,z1,z2)
list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                y        x1        x2        z1        z2
##  [1,] 11.3703411  7.377988  3.545673  10.92366  11.14318
##  [2,] 62.2299405 30.968660 56.507611  87.47627  87.59057
##  [3,] 60.9274733 71.727174 28.025778  99.75295  99.79403
##  [4,] 62.3379442 50.454591 20.419632  70.87422  71.29936
##  [5,] 86.0915384 15.299896 13.373890  28.67379  28.79112
##  [6,] 64.0310605 50.393349 32.568192  82.96154  83.45562
##  [7,]  0.9495756 49.396092 15.506197  64.90229  65.20324
##  [8,] 23.2550506 75.120020 12.996214  88.11623  88.61560
##  [9,] 66.6083758 17.464982 43.553106  61.01809  61.20589
## [10,] 51.4251141 84.839241  3.864265  88.70351  88.98107
## [11,] 69.3591292 86.483383 71.330156 157.81354 158.02826
## [12,] 54.4974836  4.185728 10.076904  14.26263  14.55057
## [13,] 28.2733584 31.718216 95.030494 126.74871 126.96496
## [14,] 92.3433484  1.374994 12.181776  13.55677  13.66919
## [15,] 29.2315840 23.902573 21.965662  45.86823  45.91073
## [16,] 83.7295628 70.649462 91.308777 161.95824 162.27689
## [17,] 28.6223285 30.809476 94.585312 125.39479 125.61030
## [18,] 26.6820780 50.854757 27.915622  78.77038  78.80674
## [19,] 18.6722790  5.164662 12.347109  17.51177  17.91297
## [20,] 23.2225911 56.456984 79.716046 136.17303 136.33567
## [21,] 31.6612455 12.148019 74.427722  86.57574  86.95438
## [22,] 30.2693371 89.283638 91.597422 180.88106 181.17320
## [23,] 15.9046003  1.462726 99.459825 100.92255 101.27697
## [24,]  3.9995918 78.312110 94.236072 172.54818 172.76167
## [25,] 21.8799541  8.996133 48.613541  57.60967  57.78146
## [26,] 81.0598552 51.918998 28.345954  80.26495  80.64451
## [27,] 52.5697547 38.426669 25.154570  63.58124  63.79325
## [28,] 91.4658166  7.005250 50.325517  57.33077  57.61121
## [29,] 83.1345047 32.064442 49.696617  81.76106  81.81913
## [30,]  4.5770263 66.849540 31.844581  98.69412  98.84563
## [31,] 45.6091482 92.640048 96.222283 188.86233 189.10173
## [32,] 26.5186672 47.190972 63.409937 110.60091 110.77332
## [33,] 30.4672203 14.261534 12.743340  27.00487  27.30523
## [34,] 50.7306870 54.426976 42.304699  96.73167  96.76972
## [35,] 18.1096208 19.617465 91.431691 111.04916 111.52715
## [36,] 75.9670635 89.858049 46.779233 136.63728 136.64839
## [37,] 20.1248038 38.949978 90.816915 129.76689 130.18775
## [38,] 25.8809819 31.087078 59.774328  90.86141  91.17763
## [39,] 99.2150418 16.002866 63.174282  79.17715  79.33219
## [40,] 80.7352340 89.618585 86.915832 176.53442 176.90570
## [41,] 55.3333591 16.639378 50.274982  66.91436  67.23382
## [42,] 64.6406094 90.042460 98.363511 188.40597 188.90223
## [43,] 31.1824307 13.407820 32.438603  45.84642  45.91056
## [44,] 62.1819198 13.161413 48.137495  61.29891  61.74053
## [45,] 32.9770176 10.528750 35.698708  46.22746  46.63250
## [46,] 50.1997473 51.158358 62.747768 113.90613 114.31705
## [47,] 67.7094527 30.019905 74.160019 104.17992 104.59728
## [48,] 48.4991239  2.671690 56.596682  59.26837  59.63474
## [49,] 24.3928827 30.964743 98.078651 129.04339 129.53492
## [50,] 76.5459788 74.211966 57.681274 131.89324 132.21284&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(list)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                y         x1          x2            z1            z2
## y   1.0000000000 0.07758827 -0.07522322 -0.0005374415 -0.0008533985
## x1  0.0775882672 1.00000000  0.25313221  0.7815275201  0.7811302343
## x2 -0.0752232228 0.25313221  1.00000000  0.8013821453  0.8017562132
## z1 -0.0005374415 0.78152752  0.80138215  1.0000000000  0.9999955888
## z2 -0.0008533985 0.78113023  0.80175621  0.9999955888  1.0000000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#model catches exact multicollinearity easily
mcmodel1 &amp;lt;- lm(y ~ x1+x2+z1+z2)
summary(mcmodel1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x1 + x2 + z1 + z2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -48.767 -21.484  -2.126  19.999  53.375 
## 
## Coefficients: (1 not defined because of singularities)
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)    51.22      10.53   4.865 1.38e-05 ***
## x1             15.81      28.05   0.563    0.576    
## x2             15.65      28.09   0.557    0.580    
## z1                NA         NA      NA       NA    
## z2            -15.72      28.06  -0.560    0.578    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 26.93 on 46 degrees of freedom
## Multiple R-squared:  0.0223, Adjusted R-squared:  -0.04146 
## F-statistic: 0.3498 on 3 and 46 DF,  p-value: 0.7895&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#has a harder time catching near multicollinearity useful to use VIF or tolerance
mcmodel2 &amp;lt;- lm(y ~ x1+x2+z2)
summary(mcmodel2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x1 + x2 + z2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -48.767 -21.484  -2.126  19.999  53.375 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)    51.22      10.53   4.865 1.38e-05 ***
## x1             15.81      28.05   0.563    0.576    
## x2             15.65      28.09   0.557    0.580    
## z2            -15.72      28.06  -0.560    0.578    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 26.93 on 46 degrees of freedom
## Multiple R-squared:  0.0223, Adjusted R-squared:  -0.04146 
## F-statistic: 0.3498 on 3 and 46 DF,  p-value: 0.7895&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;car::vif(mcmodel2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        x1        x2        z2 
##  45305.13  49446.24 118711.40&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Can drop the collinear term
mcmodel3 &amp;lt;- lm(y ~ x1+x2)
summary(mcmodel3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -50.044 -19.925  -0.354  19.215  55.525 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 47.74591    8.44508   5.654 8.96e-07 ***
## x1           0.09332    0.13522   0.690    0.493    
## x2          -0.08784    0.12964  -0.678    0.501    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 26.73 on 47 degrees of freedom
## Multiple R-squared:  0.01564,    Adjusted R-squared:  -0.02625 
## F-statistic: 0.3733 on 2 and 47 DF,  p-value: 0.6905&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;car::vif(mcmodel3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       x1       x2 
## 1.068463 1.068463&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Or drop the other one
mcmodel4 &amp;lt;- lm(y ~ x1+z2)
summary(mcmodel4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x1 + z2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -50.050 -19.928  -0.363  19.217  55.519 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 47.77939    8.46296   5.646 9.21e-07 ***
## x1           0.18145    0.20950   0.866    0.391    
## z2          -0.08807    0.12948  -0.680    0.500    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 26.73 on 47 degrees of freedom
## Multiple R-squared:  0.01571,    Adjusted R-squared:  -0.02618 
## F-statistic: 0.3751 on 2 and 47 DF,  p-value: 0.6893&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;car::vif(mcmodel4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       x1       z2 
## 2.565184 2.565184&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#normality check
#https://www.statmethods.net/stats/regression.html


nmodel &amp;lt;- summary(model2)
nmodel$residuals&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           1           2           3           4           5           6 
##    4.493754   55.950733   55.033809 -106.927120  -51.073841   37.578930 
##           7           8           9          10          11          12 
##   65.493754  120.893095   71.029094  -10.744020  -86.203964  -23.565690 
##          13          14          15          16          17          18 
##  -75.687837  -84.819765   31.434310  -48.823026   43.515067    9.922899 
##          19          20          21          22          23          24 
##  -64.562429   79.035614   25.236418   19.622717   -7.162278   43.016698 
##          25          26          27          28          29          30 
##  -23.694358  -53.011137  -98.070580   68.556457   25.217205  -10.982143 
##          31          32          33          34          35          36 
##   11.029094  -44.321396   38.869976  102.559718   44.664107  -36.757062 
##          37          38          39          40          41          42 
##   17.874692 -107.851374   23.022573   72.302382   62.061348  -26.430205 
##          43          44          45          46          47          48 
##  -54.710310  123.869976 -152.020273  -54.580187   10.826485 -122.311614 
##          49          50          51          52          53          54 
##   33.186756  -16.998095  -30.288845  -37.739008   20.415393   37.746024 
##          55          56          57          58          59          60 
##  -74.819765   14.551742  129.285270   24.309199  -22.697618    4.248650&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(model2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(nmodel$residuals)

#Runs different tests for normality run from the predicted values for rent

p3 &amp;lt;- predict(model2)
summary(p3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   417.3   491.6   526.1   572.3   640.7  1045.8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(p3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 125.7441&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#H0: from normal distribution p &amp;lt; 0.05 reject
shapiro.test(p3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Shapiro-Wilk normality test
## 
## data:  p3
## W = 0.86842, p-value = 1.114e-05&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#compares if two samples are from same distribution so comparing to a normal distribution H0: from different distributions p &amp;lt; 0.05 reject
ks.test(p3, rnorm(60,572.3,125.7441))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in ks.test(p3, rnorm(60, 572.3, 125.7441)): cannot compute exact p-value
## with ties&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  p3 and rnorm(60, 572.3, 125.7441)
## D = 0.18333, p-value = 0.2656
## alternative hypothesis: two-sided&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ORIE/Stat_basics_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Linearity Test
#https://bookdown.org/ccolonescu/RPoE4/further-inference-in-multiple-regression.html
#http://r-statistics.co/Statistical-Tests-in-R.html

library(lmtest)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;lmtest&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Ramsey RESET test test whether higher order polynomials are necessary H0: no higher order polynomials are necssary
resettest(model3, power = 2:3, type = &amp;#39;fitted&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  RESET test
## 
## data:  model3
## RESET = 1.3333, df1 = 2, df2 = 52, p-value = 0.2725&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resettest(model3, power = 2:3, type = &amp;#39;regressor&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  RESET test
## 
## data:  model3
## RESET = 2.0443, df1 = 10, df2 = 44, p-value = 0.05111&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Heteroscedasticity
#Put simply, heteroscedasticity (also spelled heteroskedasticity) refers to the circumstance in which the variability of a variable is unequal across the range of values of a second variable that predicts it.
#http://www.statsmakemecry.com/smmctheblog/confusing-stats-terms-explained-heteroscedasticity-heteroske.html

#Fisher Test can be used to tell if two samples have the same variance H0: ratio of variances is 1 aka they are the same p &amp;lt; 0.05 reject H0
var.test(sample(35,p3, replace = TRUE),sample(35,p3, replace = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  F test to compare two variances
## 
## data:  sample(35, p3, replace = TRUE) and sample(35, p3, replace = TRUE)
## F = 0.91901, num df = 513, denom df = 513, p-value = 0.3391
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.7728094 1.0928623
## sample estimates:
## ratio of variances 
##          0.9190072&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Independance 

#Chi square tests if two caterogical variables are dependant on each other H0: variables are independant p &amp;lt; 0.05 reject H0
chisq.test(table(data1$Bedrooms,data1$Bathrooms))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in chisq.test(table(data1$Bedrooms, data1$Bathrooms)): Chi-squared
## approximation may be incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s Chi-squared test
## 
## data:  table(data1$Bedrooms, data1$Bathrooms)
## X-squared = 29.391, df = 3, p-value = 1.853e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(table(data1$Bedrooms,data1$Bathrooms))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Number of cases in table: 60 
## Number of factors: 2 
## Test for independence of all factors:
##  Chisq = 29.391, df = 3, p-value = 1.853e-06
##  Chi-squared approximation may be incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Correlation test between two continuous variables H0: correlation is 0 aka they are independant p &amp;lt; 0.05 reject H0

#All show some correlation
cor.test(data1$Rent, data1$Area)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Rent and data1$Area
## t = 13.702, df = 58, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7970327 0.9231055
## sample estimates:
##       cor 
## 0.8740597&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor.test(data1$Bedrooms, data1$Area)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Bedrooms and data1$Area
## t = 12.811, df = 58, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7747757 0.9140118
## sample estimates:
##       cor 
## 0.8595894&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor.test(data1$Bedrooms, data1$Bathrooms)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Bedrooms and data1$Bathrooms
## t = 6.6217, df = 58, p-value = 1.262e-08
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.4826241 0.7800925
## sample estimates:
##       cor 
## 0.6561389&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor.test(data1$Bedrooms, data1$Bathrooms)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Bedrooms and data1$Bathrooms
## t = 6.6217, df = 58, p-value = 1.262e-08
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.4826241 0.7800925
## sample estimates:
##       cor 
## 0.6561389&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Are uncorrelated
cor.test(data1$Area, data1$Distance)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  data1$Area and data1$Distance
## t = -0.4492, df = 58, p-value = 0.655
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.3081967  0.1980052
## sample estimates:
##         cor 
## -0.05887988&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Both of these tests use log parameters as well as lag and leads to determine if the variance changes or if the predictors are truly independant of each other&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Other helpful Stat and R learning
#http://faculty.marshall.usc.edu/gareth-james/ISL/index.html
#https://web.stanford.edu/~hastie/ElemStatLearn/

#Essentials of Machine Learning https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/

#CLT and Stat Basics https://www.analyticsvidhya.com/blog/2019/05/statistics-101-introduction-central-limit-theorem/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add a new chunk by clicking the &lt;em&gt;Insert Chunk&lt;/em&gt; button on the toolbar or by pressing &lt;em&gt;Ctrl+Alt+I&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the &lt;em&gt;Preview&lt;/em&gt; button or press &lt;em&gt;Ctrl+Shift+K&lt;/em&gt; to preview the HTML file).&lt;/p&gt;
&lt;p&gt;The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike &lt;em&gt;Knit&lt;/em&gt;, &lt;em&gt;Preview&lt;/em&gt; does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
